

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>One Dimensional Kalman Filters &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/vnd.jupyter.widget-state+json">{"state": {"0358e78f6f36480cb5ebf0f89f49934b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "041e9d6f999b4c2e8dd8006923b45a57": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "0c66f10d9a2a4902b04094b62e5e154d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "0cb91a73b33441158fce28138d0636c7": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "16191c7bd4294856ae6f7d7ab9e2bef9": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1ba4c1d94f65462192ffcb9f0a22b848": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1e6ed0bbc3af4016ac96e8084f2a2bef": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "2a4208cd088b4882a8d5a592f610a41a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2a738977ecb549a993d47244d6ac50fd": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "2b5d38d7b2774008a7eeb84c37bcfb1a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "sensor_noise", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_c14c7c9853874ef0a496e114210eae6f", "max": 100, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_5d214435449b45529e6a52291dcc1866", "value": 5}}, "3109e908fc98419d806699d7a2880531": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "38e20eaaa9024a7092c43257bf6e5a68": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_0cb91a73b33441158fce28138d0636c7", "msg_id": "", "outputs": []}}, "3984603d140f4245ae402c3abf88710a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "39b233342714416aa2a0a329dc931641": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3e977b7cfed94243a71c70bcb8c918a2": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_41f1078f32254aa7b820bdd425d0896e", "IPY_MODEL_62808e56615d416491559e92ff34d5f1", "IPY_MODEL_82fb3c28b0f74a83becd6d65cbfa313a", "IPY_MODEL_618b63b1caa54ba99541fbae4f78d2dc", "IPY_MODEL_ba41ac9b29af49329e1ef8680bebbdf9"], "layout": "IPY_MODEL_962322a3acc94c34a4845d91e7097787"}}, "40cea4dd9a854916b0a7036a2a961e3d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "start_pos", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_a588d2a1208542fcbd5eba235f75ef56", "max": 10, "min": -10, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_8dfce204eadc41ea87d489d85bb563a7", "value": 0}}, "41592f65aa444b6689cee2940b11c9e9": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "41f1078f32254aa7b820bdd425d0896e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "start_pos", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_b250bfdd55e34b608edb8d2e14a17081", "max": 10, "min": -10, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_ea5aed6a83894ad0a4568fa111331625", "value": 0}}, "4201a1f5e7e24c68b9d8e54e47d28aad": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4392b29d01ba46ce8e8dd84d04fa326a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "4b951bc3ddb24e2f975b6c8f168285a3": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "5328932ead3145c2884c7a9eb24f5e62": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "v1", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_6fc9d6a25d424100be095b70f12b9ccb", "max": 2, "min": 0.1, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_041e9d6f999b4c2e8dd8006923b45a57", "value": 1}}, "5d214435449b45529e6a52291dcc1866": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "5f42b0854cd24b25a613131fa6af4a63": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "m2", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_41592f65aa444b6689cee2940b11c9e9", "max": 15, "min": 10, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.5, "style": "IPY_MODEL_1e6ed0bbc3af4016ac96e8084f2a2bef", "value": 12}}, "618b63b1caa54ba99541fbae4f78d2dc": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "process_noise", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_a5a5eff11fd5487cb1b87e15a4af8a80", "max": 100, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_6a64998029a04ff3bd5d93a2d1fba2f8", "value": 5}}, "61b17c1656c6477693ff3ec0db2c5844": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "velocity", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_ee15c3b7c9e84f62b4e1faab168a87b6", "max": 2, "min": -2, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_0358e78f6f36480cb5ebf0f89f49934b", "value": 1}}, "62808e56615d416491559e92ff34d5f1": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "sensor_noise", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_2a738977ecb549a993d47244d6ac50fd", "max": 100, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_b85af9dfbd9042faa46d1a49a5f303ed", "value": 5}}, "63d0e481df73436bb8cbe263dac07a3d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "process_noise", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_2a4208cd088b4882a8d5a592f610a41a", "max": 40, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_3109e908fc98419d806699d7a2880531", "value": 0.1}}, "672aead129ee424398d8038aa1a35bec": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6a64998029a04ff3bd5d93a2d1fba2f8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "6a9da3a29b25419eb33c946c4347212f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "v2", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_39b233342714416aa2a0a329dc931641", "max": 2, "min": 0.1, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_0c66f10d9a2a4902b04094b62e5e154d", "value": 1}}, "6e8ff778989f4724a96bc66efc9dc29d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "step", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_ee9177e774d7450f863ecaca7c8c150a", "max": 30, "min": 1, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_4392b29d01ba46ce8e8dd84d04fa326a", "value": 1}}, "6fc9d6a25d424100be095b70f12b9ccb": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "82fb3c28b0f74a83becd6d65cbfa313a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": false, "description": "velocity", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_b4ae3832588c476aa88f2895267337e5", "max": 2, "min": -2, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_4b951bc3ddb24e2f975b6c8f168285a3", "value": 1}}, "8dfce204eadc41ea87d489d85bb563a7": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "962322a3acc94c34a4845d91e7097787": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9941654d582e4a399135e4e2630ef016": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a588d2a1208542fcbd5eba235f75ef56": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a5a5eff11fd5487cb1b87e15a4af8a80": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "aea352b1772c4625aae4c2793d43295c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "b250bfdd55e34b608edb8d2e14a17081": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b4ae3832588c476aa88f2895267337e5": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b85af9dfbd9042faa46d1a49a5f303ed": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "ba41ac9b29af49329e1ef8680bebbdf9": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_672aead129ee424398d8038aa1a35bec", "msg_id": "", "outputs": []}}, "c14c7c9853874ef0a496e114210eae6f": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c24c7036e2ce430b98dd992307a8aa92": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_6e8ff778989f4724a96bc66efc9dc29d", "IPY_MODEL_fae8fbc196054b0da7e7a76ec1106272"], "layout": "IPY_MODEL_3984603d140f4245ae402c3abf88710a"}}, "c41a34711a5f4f5c84895d51d23607e6": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_40cea4dd9a854916b0a7036a2a961e3d", "IPY_MODEL_2b5d38d7b2774008a7eeb84c37bcfb1a", "IPY_MODEL_61b17c1656c6477693ff3ec0db2c5844", "IPY_MODEL_63d0e481df73436bb8cbe263dac07a3d", "IPY_MODEL_f0171695805543d0b868ef4dc1e86052"], "layout": "IPY_MODEL_ecb024e32052401db633017aa0511550"}}, "dfdbe538295c49f9ab55220d1d4c0de2": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "FloatSliderView", "continuous_update": true, "description": "m1", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_4201a1f5e7e24c68b9d8e54e47d28aad", "max": 10, "min": 5, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.5, "style": "IPY_MODEL_aea352b1772c4625aae4c2793d43295c", "value": 7.5}}, "e6bd73b7f70147228df681be89a514dc": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_dfdbe538295c49f9ab55220d1d4c0de2", "IPY_MODEL_5f42b0854cd24b25a613131fa6af4a63", "IPY_MODEL_5328932ead3145c2884c7a9eb24f5e62", "IPY_MODEL_6a9da3a29b25419eb33c946c4347212f", "IPY_MODEL_38e20eaaa9024a7092c43257bf6e5a68"], "layout": "IPY_MODEL_9941654d582e4a399135e4e2630ef016"}}, "ea5aed6a83894ad0a4568fa111331625": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "ecb024e32052401db633017aa0511550": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ee15c3b7c9e84f62b4e1faab168a87b6": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ee9177e774d7450f863ecaca7c8c150a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f0171695805543d0b868ef4dc1e86052": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_16191c7bd4294856ae6f7d7ab9e2bef9", "msg_id": "", "outputs": []}}, "fae8fbc196054b0da7e7a76ec1106272": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_1ba4c1d94f65462192ffcb9f0a22b848", "msg_id": "", "outputs": []}}}, "version_major": 2, "version_minor": 0}</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.html" />
    <link rel="shortcut icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Automated Reasoning" href="../../logical-reasoning/automated-reasoning/_index.html" />
    <link rel="prev" title="Localization and Tracking" href="../hmm-localization/_index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="list-caption"><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="label-parts" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../syllabus/_index.html">Syllabus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to AI</span></p><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="label-parts" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/data-science-360/_index.html">Data Science 360</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/systems-approach/_index.html">The four approaches towards AI</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/agents/_index.html">Agent-Environment Interface</a></li>



</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">The Learning Problem - Regression</span></p><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="label-parts" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../entropy/_index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">The Learning Problem - Classification</span></p><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="label-parts" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Inference</span></p><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="label-parts" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../bayesian-inference/_index.html">Bayesian Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bayesian-inference/bayesian_regression.html">Bayesian Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bayesian-coin/bayesian_update_coin_flip.html">Posterior updates in a coin flipping experiment</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="label-parts" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/dnn-intro/_index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/regularization-workshop-1.html">Regularization Workshop</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="label-parts" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">Visualizing what convnets learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-explainers/gradcam.html">CNN Explainers</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="label-parts" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="label-parts" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/index.html">Object Det. &amp; Semantic Segm. Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">Mask R-CNN Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">Mask R-CNN Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">Mask R-CNN - Inspect Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">Mask R-CNN - Inspect Trained Model</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">Mask R-CNN - Inspect Weights of a Trained Model</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">Detectron2 Beginners Tutorial</a></li>





</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Probabilistic Reasoning</span></p><input checked="" class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="label-parts" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../pgm-intro/_index.html">Introduction to Probabilistic Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../recursive-state-estimation/_index.html">Recursive State Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../discrete-bayesian-filter/discrete-bayesian-filter.html">Discrete Bayes Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm-localization/_index.html">Localization and Tracking</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">One Dimensional Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Logical Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="label-parts" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/automated-reasoning/_index.html">Automated Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/propositional-logic/_index.html">World Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/logical-agents/_index.html">Logical Agents</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Planning without Interactions</span></p><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="label-parts" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../planning/_index.html">Planning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autonomous-cars/_index.html">Autonomous Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autonomous-cars/imitation-learning/_index.html">Imitation Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../planning/classical-planning/_index.html">Classical Planning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../planning/search/_index.html">Planning with Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../planning/search/forward-search/_index.html">Forward Search Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../planning/search/a-star/_index.html">The A* Algorithm</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Markov Decision Processes</span></p><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="label-parts" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mdp/_index.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/mdp-intro/_index.html">Introduction to MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-expectation-backup/_index.html">Bellman Expectation Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-optimality-backup/_index.html">Bellman Optimality Backup</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mdp/mdp-dp-algorithms/index.html">MDP Dynamic Programming Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-iteration/_index.html">Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-evaluation/_index.html">Policy Evaluation (Prediction)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-dp-algorithms/policy-improvement/_index.html">Policy Improvement (Control)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-dp-algorithms/value-iteration/_index.html">Value Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-lab/recycling-robot/_index.html">Finding the optimal policy of a recycling robot.</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="label-parts" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/_index.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/monte-carlo.html">Monte-Carlo Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/temporal-difference.html">Temporal Difference (TD) Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/control/_index.html">Model-free Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/generalized-policy-iteration/_index.html">Generalized Policy Iteration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/control/sarsa/_index.html">The SARSA Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/reinforce/_index.html">The REINFORCE Algorithm</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="label-parts" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="label-parts" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../nlp/nlp-introduction/nlp-pipelines/_index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp/nlp-introduction/tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/_index.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/language-models/_index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/simple-rnn-language-model/index.html">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/rnn-attention-workshop/seq2seq_and_attention.html">Attention in RNN NMT Workshop</a></li>




</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/transformers/transformers-intro.html">Transformers</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/transformers/annotated_transformer.html">The Annotated Transformer</a></li>











</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="label-parts" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/calculus/index.html">Calculus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="label-parts" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Common Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="label-parts" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/probability/probability-assignment-5/index.html">Probability Assignment</a></li>

</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments CS-UY-4613</span></p><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="label-parts" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/mle/mle-gaussian.html">Gaussian Maximum Likelihood</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/mle/poisson-regression-1/index.html">Bike Rides and the Poisson Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-tracking-kalman/balls.html">Multiple Object Tracking</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Project CS-UY-4613</span></p><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="label-parts" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/nlp/finetuning-language-models-tweets/index.html">Finetuning Language Models - Toxic Tweets</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Assignments CS-GY-6613</span></p><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="label-parts" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/logistic-regression-1/index.html">Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-tracking-kalman/soccer.html">Sports Analytics - Object Tracking and Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Project CS-GY-6613</span></p><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="label-parts" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../projects/nlp/finetuning-language-models-patents/index.html">Finetuning Language Models - Can I Patent This?</a></li>
</ul></li></ul>
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pantelis/artificial-intelligence/master?urlpath=tree/artificial_intelligence/aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pantelis/artificial-intelligence/blob/master/artificial_intelligence/aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/edit/master/artificial_intelligence/aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/aiml-common/lectures/pgm/kalman-filters/one-dimensional-kalman-filters.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>One Dimensional Kalman Filters</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-description">Problem Description</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beliefs-as-gaussians">Beliefs as Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-with-gaussian-probabilities">Tracking with Gaussian Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions-with-gaussians">Predictions with Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#updates-with-gaussians">Updates with Gaussians</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-gaussian-multiplication">Understanding Gaussian Multiplication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-example">Interactive Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-kalman-filter">First Kalman Filter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-walkthrough">Code Walkthrough</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-modify-variance-values">Exercise: Modify Variance Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kf-animation">KF Animation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kalman-gain">Kalman Gain</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#full-description-of-the-algorithm">Full Description of the Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-with-g-h-and-discrete-bayes-filters">Comparison with g-h and discrete Bayes Filters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-designing-a-filter">Introduction to Designing a Filter</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#animation">Animation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-extreme-amounts-of-noise">Example: Extreme Amounts of Noise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-incorrect-process-variance">Example: Incorrect Process Variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-bad-initial-estimate">Example: Bad Initial Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-large-noise-and-bad-initial-estimate">Example: Large Noise and Bad Initial Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-interactive-plots">Exercise: Interactive Plots</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-nonlinear-systems">Exercise - Nonlinear Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixed-gain-filters">Fixed Gain Filters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#filterpys-implementation">FilterPys Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <p><span class="xref myst">Table of Contents</span></p>
<section class="tex2jax_ignore mathjax_ignore" id="one-dimensional-kalman-filters">
<h1>One Dimensional Kalman Filters<a class="headerlink" href="#one-dimensional-kalman-filters" title="Permalink to this headline">#</a></h1>
<p>This notebook was copied from the excellent book <a class="github reference external" href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python">rlabbe/Kalman-and-Bayesian-Filters-in-Python</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#format the book</span>
<span class="kn">import</span> <span class="nn">book_format</span>
<span class="n">book_format</span><span class="o">.</span><span class="n">set_style</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <style>
        .output_wrapper, .output {
            height:auto !important;
            max-height:100000px;
        }
        .output_scroll {
            box-shadow:none !important;
            webkit-box-shadow:none !important;
        }
        </style>
    </div></div>
</div>
<p>Now that we understand the discrete Bayes filter and Gaussians we are prepared to implement a Kalman filter. We will do this exactly as we did the discrete Bayes filter - rather than starting with equations we will develop the code step by step based on reasoning about the problem.</p>
<p>One dimensional means that the filter only tracks one state variable, such as position on the x-axis. In subsequent chapters we will learn a more general multidimensional form of the filter that can track many state variables simultaneously, such as position, velocity, and acceleration. Recall that we used velocity in the g-h filter to get better estimates than by tracking position alone. The same is true for the Kalman filter.</p>
<p>So why not just jump into the multidimensional form of the filter? To be honest, the math is difficult, and my intuitive approach to developing the filter starts to break down. This math obscures the rather simple principles that allow the Kalman filter to work.</p>
<p>So, in this chapter we learn how to use Gaussians to implement a Bayesian filter. Thats all the Kalman filter is - a Bayesian filter that uses Gaussians. In the next chapter we will switch to a multidimensional form and the full power of the Kalman filter will be unleashed!</p>
<section id="problem-description">
<h2>Problem Description<a class="headerlink" href="#problem-description" title="Permalink to this headline">#</a></h2>
<p>As in the <strong>Discrete Bayes Filter</strong> chapter we will be tracking a moving object in a long hallway at work. Assume that in our latest hackathon someone created an RFID tracker that provides a reasonably accurate position of the dog. The sensor returns the distance of the dog from the left end of the hallway in meters. So, 23.4 would mean the dog is 23.4 meters from the left end of the hallway.</p>
<p>The sensor is not perfect. A reading of 23.4 could correspond to the dog being at 23.7, or 23.0. However, it is very unlikely to correspond to a position of 47.6. Testing during the hackathon confirmed this result - the sensor is reasonably accurate, and while it had errors, the errors are small. Furthermore, the errors seemed to be evenly distributed on both sides of the true position; a position of 23 m would equally likely be measured as 22.9 or 23.1. Perhaps we can model this with a Gaussian.</p>
<p>We predict that the dog is moving. This prediction is not perfect. Sometimes our prediction will overshoot, sometimes it will undershoot. We are more likely to undershoot or overshoot by a little than a lot. Perhaps we can also model this with a Gaussian.</p>
</section>
<section id="beliefs-as-gaussians">
<h2>Beliefs as Gaussians<a class="headerlink" href="#beliefs-as-gaussians" title="Permalink to this headline">#</a></h2>
<p>We can express our belief in the dogs position with a Gaussian. Say we believe that our dog is at 10 meters, and the variance in that belief is 1 m<span class="math notranslate nohighlight">\(^2\)</span>, or <span class="math notranslate nohighlight">\(\mathcal{N}(10,\, 1)\)</span>. A plot of the pdf follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">filterpy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="n">stats</span><span class="o">.</span><span class="n">plot_gaussian_pdf</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">variance</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> 
                        <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.5</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/125f448f0f385ef1bcb6827ddec15a4aef0a53e63320d14b5b84a19a82018327.png" src="../../../../_images/125f448f0f385ef1bcb6827ddec15a4aef0a53e63320d14b5b84a19a82018327.png" />
</div>
</div>
<p>This plot depicts our uncertainty about the dogs position. It represents a fairly inexact belief. While we believe that it is most likely that the dog is at 10 m, any position from 9 m to 11 m or so are quite likely as well. Assume the dog is standing still, and we query the sensor again. This time it returns 10.2 m. Can we use this additional information to improve our estimate?</p>
<p>Intuition suggests we can. Consider: if we read the sensor 500 times and each time it returned a value between 8 and 12, all centered around 10, we should be very confident that the dog is near 10. Of course, a different interpretation is possible. Perhaps our dog was randomly wandering back and forth in a way that exactly emulated random draws from a normal distribution. But that seems extremely unlikely - Ive never seen a dog do that. Lets look at 500 draws from <span class="math notranslate nohighlight">\(\mathcal N(10, 1)\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">randn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">xs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">randn</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span><span class="o">*</span><span class="mf">1.</span> <span class="o">+</span> <span class="mf">10.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Mean of readings is </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean of readings is 10.021
</pre></div>
</div>
<img alt="../../../../_images/0e40f03124c7586d7d2afb07873982b01a2adbd0f5c92279045564b48aee254b.png" src="../../../../_images/0e40f03124c7586d7d2afb07873982b01a2adbd0f5c92279045564b48aee254b.png" />
</div>
</div>
<p>Eyeballing this confirms our intuition - no dog moves like this. However, noisy sensor data certainly looks this way.  The computed mean of the readings is almost exactly 10. Assuming the dog is standing still, we say the dog is at position 10 with a variance of 1.</p>
</section>
<section id="tracking-with-gaussian-probabilities">
<h2>Tracking with Gaussian Probabilities<a class="headerlink" href="#tracking-with-gaussian-probabilities" title="Permalink to this headline">#</a></h2>
<p>The discrete Bayes filter used a histogram of probabilities to track the dog. Each bin in the histogram represents a position, and the value is the probability of the dog being in that position.</p>
<p>Tracking was performed with a cycle of predictions and updates. We used the equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} 
\bar {\mathbf x} &amp;= \mathbf x \ast f_{\mathbf x}(\bullet)\, \, &amp;\text{Predict} \\
\mathbf x &amp;= \mathcal L \cdot \bar{\mathbf x}\, \, &amp;\text{Update}
\end{aligned}\end{split}\]</div>
<p>to compute the new probability distributions. Recall that <span class="math notranslate nohighlight">\(\bar{\mathbf x}\)</span> is the <em>prior</em>, <span class="math notranslate nohighlight">\(\mathcal L\)</span> is the <em>likelihood</em> of a measurement given the prior <span class="math notranslate nohighlight">\(\bar{\mathbf x}\)</span>, <span class="math notranslate nohighlight">\(f_{\mathbf x}(\bullet)\)</span> is the <em>process model</em>, and <span class="math notranslate nohighlight">\(\ast\)</span> denotes <em>convolution</em>. <span class="math notranslate nohighlight">\(\mathbf x\)</span> is bold to denote that it is a histogram of numbers, or a vector.</p>
<p>This method works, but led to histograms that implied the dog could be in multiple places at once. Also, the computations are very slow for large problems.</p>
<p>Can we replace <span class="math notranslate nohighlight">\(\mathbf x\)</span>, the histogram, with a Gaussian <span class="math notranslate nohighlight">\(\mathcal N(x, \sigma^2)\)</span>? Absolutely! Weve learned how to express belief as a Gaussian. A Gaussian, which is a single number pair <span class="math notranslate nohighlight">\(\mathcal N(\mu, \sigma^2),\)</span> can replace an entire histogram of probabilities:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">kf_book.kf_internal</span> <span class="k">as</span> <span class="nn">kf_internal</span>
<span class="n">kf_internal</span><span class="o">.</span><span class="n">gaussian_vs_histogram</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/6228fa7eaaab6624c004ce5112ba4fdfd197543980da2651da7ed5884cddae5a.png" src="../../../../_images/6228fa7eaaab6624c004ce5112ba4fdfd197543980da2651da7ed5884cddae5a.png" />
</div>
</div>
<p>I hope you see the power of this. We can replace hundreds to thousands of numbers with a single pair of numbers: <span class="math notranslate nohighlight">\(x = \mathcal N(\mu, \sigma^2)\)</span>.</p>
<p>The tails of the Gaussian extend to infinity on both sides, so it incorporates arbitrarily many bars in the histogram. If this represents our belief in the position of the dog in the hallway, this one Gaussian covers the entire hallway (and the entire universe on that axis). We think that it is likely the dog is at 10, but he could be at 8, 14, or, with infinitesimally small probability, at 10<span class="math notranslate nohighlight">\(^{80}\)</span>.</p>
<p>In this chapter we replace histograms with Gaussians:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{array}{l|l|c}
\text{discrete Bayes} &amp; \text{Gaussian} &amp; \text{Step}\\
\hline
\bar {\mathbf x} = \mathbf x \ast f(\mathbf x) &amp; 
\bar {x}_\mathcal{N} =  x_\mathcal{N} \, \oplus \, f_{x_\mathcal{N}}(\bullet) &amp;
\text{Predict} \\
\mathbf x = \|\mathcal L \bar{\mathbf x}\| &amp; x_\mathcal{N} = L \, \otimes \, \bar{x}_\mathcal{N} &amp; \text{Update} 
\end{array}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\oplus\)</span> and <span class="math notranslate nohighlight">\(\otimes\)</span> is meant to express some unknown operator on Gaussians. I wont do it in the rest of the book, but the subscript indicates that <span class="math notranslate nohighlight">\(x_\mathcal{N}\)</span> is a Gaussian.</p>
<p>The discrete Bayes filter used convolution for the prediction. We showed that it used the <em>total probabability theorem</em>, computed as a sum, so maybe we can add the Gaussians. It used multiplications to incorporate the measurement into the prior, so maybe we can multiply the Gaussians. Could it be this easy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} 
\bar x &amp;\stackrel{?}{=} x + f_x(\bullet) \\
x &amp;\stackrel{?}{=} \mathcal L \cdot \bar x
\end{aligned}\end{split}\]</div>
<p>This will only work if the sum and product of two Gaussians is another Gaussian. Otherwise after the first epoch <span class="math notranslate nohighlight">\(x\)</span> would not be Gaussian, and this scheme falls apart.</p>
</section>
<section id="predictions-with-gaussians">
<h2>Predictions with Gaussians<a class="headerlink" href="#predictions-with-gaussians" title="Permalink to this headline">#</a></h2>
<p>We use Newtons equation of motion to compute current position based on the current velocity and previous position:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}\bar{x}_k &amp;= x_{k-1} + v_k \Delta t \\
 &amp;= x_{k-1} + f_x\end{aligned}\end{split}\]</div>
<p>Ive dropped the notation <span class="math notranslate nohighlight">\(f_x(\bullet)\)</span> in favor of <span class="math notranslate nohighlight">\(f_x\)</span> to keep the equations uncluttered.</p>
<p>If the dog is at 10 m, his velocity is 15 m/s, and the epoch is 2 seconds long, we have</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned} f_x &amp;= v\Delta t = 15\cdot 2\\
\bar{x}_k &amp;= 10 + (15\cdot 2) = 40 \end{aligned}\end{split}\]</div>
<p>We are uncertain about his current position and velocity, so this will not do. We need to express the uncertainty with a Gaussian.</p>
<p>Position is easy. We define <span class="math notranslate nohighlight">\(x\)</span> as a Gaussian. If we think the dog is at 10 m, and the standard deviation of our uncertainty is 0.2 m, we get <span class="math notranslate nohighlight">\(x=\mathcal N(10, 0.2^2)\)</span>.</p>
<p>What about our uncertainty in his movement? We define <span class="math notranslate nohighlight">\(f_x\)</span> as a Gaussian. If the dogs velocity is 15 m/s, the epoch is 1 second, and the standard deviation of our uncertainty is 0.7 m/s, we get <span class="math notranslate nohighlight">\(f_x = \mathcal N (15, 0.7^2)\)</span>.</p>
<p>The equation for the prior is</p>
<div class="math notranslate nohighlight">
\[\bar x = x + f_x\]</div>
<p>What is the sum of two Gaussians? In the last chapter I proved that:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gathered}
\mu = \mu_1 + \mu_2 \\
\sigma^2 = \sigma^2_1 + \sigma^2_2
\end{gathered}\end{split}\]</div>
<p>This is fantastic news; the sum of two Gaussians is another Gaussian!</p>
<p>The math works, but does this make intuitive sense?  Think of the physical representation of this abstract equation. We have</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gathered}
x=\mathcal N(10, 0.2^2)\\
f_x = \mathcal N (15, 0.7^2)
\end{gathered}\end{split}\]</div>
<p>If we add these we get:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}\bar x &amp;= \mu_x + \mu_{f_x} = 10 + 15 &amp;&amp;= 25 \\
\bar\sigma^2 &amp;= \sigma_x^2 + \sigma_{f_x}^2 = 0.2^2 + 0.7^2 &amp;&amp;= 0.53\end{aligned}\end{split}\]</div>
<p>It makes sense that the predicted position is the previous position plus the movement. What about the variance? It is harder to form an intuition about this. However, recall that with the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function for the discrete Bayes filter we always lost information. We dont really know where the dog is moving, so the confidence should get smaller (variance gets larger). <span class="math notranslate nohighlight">\(\sigma_{f_x}^2\)</span> is the amount of uncertainty added to the system due to the imperfect prediction about the movement, and so we would add that to the existing uncertainty.</p>
<p>Lets take advantage of the <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> class in Pythons <code class="docutils literal notranslate"><span class="pre">collection</span></code> module to implement a Gaussian object. We could implement a Gaussian using a tuple, where <span class="math notranslate nohighlight">\(\mathcal N(10, 0.04)\)</span> is implemented in Python as <code class="docutils literal notranslate"><span class="pre">g</span> <span class="pre">=</span> <span class="pre">(10.,</span> <span class="pre">0.04)</span></code>. We would access the mean with <code class="docutils literal notranslate"><span class="pre">g[0]</span></code> and the variance with <code class="docutils literal notranslate"><span class="pre">g[1]</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> works the same as a tuple, except you provide it with a type name and field names. Its not important to understand, but I modified the <code class="docutils literal notranslate"><span class="pre">__repr__</span></code> method to display its value using the notation in this chapter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="n">gaussian</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Gaussian&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;var&#39;</span><span class="p">])</span>
<span class="n">gaussian</span><span class="o">.</span><span class="fm">__repr__</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="s1">&#39;(=</span><span class="si">{:.3f}</span><span class="s1">, =</span><span class="si">{:.3f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can create a print a Gaussian with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g1</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">3.4</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">)</span>
<span class="n">g2</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">4.5</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="mf">0.2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">g2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(=3.400, =10.100)
(=4.500, =0.040)
</pre></div>
</div>
</div>
</div>
<p>We can access the mean and variance with either subscripts or field names:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">g1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">g1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">g1</span><span class="o">.</span><span class="n">var</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3.4, 3.4, 10.1, 10.1)
</pre></div>
</div>
</div>
</div>
<p>Here is our implementation of the predict function, where <code class="docutils literal notranslate"><span class="pre">pos</span></code> and <code class="docutils literal notranslate"><span class="pre">movement</span></code> are Gaussian tuples in the form (<span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\sigma^2\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">movement</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="n">movement</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">pos</span><span class="o">.</span><span class="n">var</span> <span class="o">+</span> <span class="n">movement</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lets test it. What is the prior if the intitial position is the Gaussian <span class="math notranslate nohighlight">\(\mathcal N(10, 0.2^2)\)</span> and the movement is the Gaussian <span class="math notranslate nohighlight">\(\mathcal N (15, 0.7^2)\)</span>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">.2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">move</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">15.</span><span class="p">,</span> <span class="mf">.7</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">move</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(=25.000, =0.530)
</pre></div>
</div>
</div>
</div>
<p>The prior states that the dog is at 25 m with a variance of 0.53 m<span class="math notranslate nohighlight">\(^2\)</span>, which is what we computed by hand.</p>
</section>
<section id="updates-with-gaussians">
<h2>Updates with Gaussians<a class="headerlink" href="#updates-with-gaussians" title="Permalink to this headline">#</a></h2>
<p>The discrete Bayes filter encodes our belief about the position of our dog in a histogram of probabilities. The distribution is discrete and multimodal. It can express strong belief that the dog is in two positions at once, and the positions are discrete.</p>
<p>We are proposing that we replace the histogram with a Gaussian. The discrete Bayes filter used this code to compute the posterior:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">):</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">*</span> <span class="n">prior</span>
    <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
</pre></div>
</div>
<p>which is an implementation of the equation:</p>
<div class="math notranslate nohighlight">
\[x = \| \mathcal L\bar x \|\]</div>
<p>Weve just shown that we can represent the prior with a Gaussian. What about the likelihood? The likelihood is the probability of the measurement given the current state. Weve learned how to represent measurements as Gaussians. For example, maybe our sensor states that the dog is at 23 m, with a standard deviation of 0.4 meters. Our measurement, expressed as a likelihood, is <span class="math notranslate nohighlight">\(z = \mathcal N (23, 0.16)\)</span>.</p>
<p>Both the likelihood and prior are modeled with Gaussians. Can we multiply Gaussians? Is the product of two Gaussians another Gaussian?</p>
<p>Yes to the former, and almost to the latter! In the last chapter I proved that the product of two Gaussians is proportional to another Gausian.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mu &amp;= \frac{\sigma_1^2 \mu_2 + \sigma_2^2 \mu_1} {\sigma_1^2 + \sigma_2^2}, \\
\sigma^2 &amp;= \frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}
\end{aligned}\end{split}\]</div>
<p>We can immediately infer several things. If we normalize the result, the product is another Gaussian. If one Gaussian is the likelihood, and the second is the prior, then the mean is a scaled sum of the prior and the measurement. The variance is a combination of the variances of the prior and measurement. Finally, the variances are completely unaffected by the values of the mean!</p>
<p>We put this in Bayesian terms like so:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal N(\mu, \sigma^2) &amp;= \| prior \cdot likelihood \|\\
&amp;= \| \mathcal{N}(\bar\mu, \bar\sigma^2)\cdot \mathcal{N}(\mu_z, \sigma_z^2) \|\\
&amp;= \mathcal N(\frac{\bar\sigma^2 \mu_z + \sigma_z^2 \bar\mu}{\bar\sigma^2 + \sigma_z^2},\frac{\bar\sigma^2\sigma_z^2}{\bar\sigma^2 + \sigma_z^2})
\end{aligned}\end{split}\]</div>
<p>If we implemented that in a function <code class="docutils literal notranslate"><span class="pre">gaussian_multiply()</span></code> we could implement our filters update step as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_multiply</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">var</span> <span class="o">*</span> <span class="n">g2</span><span class="o">.</span><span class="n">mean</span> <span class="o">+</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span> <span class="o">*</span> <span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">var</span> <span class="o">+</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">var</span> <span class="o">*</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">var</span> <span class="o">+</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">):</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">gaussian_multiply</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">posterior</span>

<span class="c1"># test the update function</span>
<span class="n">predicted_pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">.2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">measured_pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">11.</span><span class="p">,</span> <span class="mf">.1</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">estimated_pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">predicted_pos</span><span class="p">,</span> <span class="n">measured_pos</span><span class="p">)</span>
<span class="n">estimated_pos</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(=10.800, =0.008)
</pre></div>
</div>
</div>
</div>
<p>Perhaps this would be clearer if we used more specific names:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_dog</span><span class="p">(</span><span class="n">dog_pos</span><span class="p">,</span> <span class="n">measurement</span><span class="p">):</span>
    <span class="n">estimated_pos</span> <span class="o">=</span> <span class="n">gaussian_multiply</span><span class="p">(</span><span class="n">measurement</span><span class="p">,</span> <span class="n">dog_pos</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">estimated_pos</span>  
</pre></div>
</div>
<p>That is less abstract, which perhaps helps with comprehension, but it is poor coding practice. We are writing a Kalman filter that works for any problem, not just tracking dogs in a hallway, so we wont use variable names with dog in them. Also, this form obscures the fact that we are multiplying the likelihood by the prior.</p>
<p>We have the majority of our filter implemented, but I fear this step is still a bit confusing. Ive asserted that we can multiply Gaussians and that it correctly performs the update step, but why is this true? Lets take a detour and spend some time multiplying Gaussians.</p>
<section id="understanding-gaussian-multiplication">
<h3>Understanding Gaussian Multiplication<a class="headerlink" href="#understanding-gaussian-multiplication" title="Permalink to this headline">#</a></h3>
<p>Lets plot the pdf of <span class="math notranslate nohighlight">\(\mathcal{N}(10,\, 1) \times \mathcal{N}(10,\, 1)\)</span>. Can you determine its shape without looking at the result? What should the new mean be? Will the curve be wider, narrower, or the same as <span class="math notranslate nohighlight">\(\mathcal{N}(10,\, 1)\)</span>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>  <span class="c1"># Gaussian N(10, 1)</span>

<span class="n">product</span> <span class="o">=</span> <span class="n">gaussian_multiply</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal</span><span class="si">{N}</span><span class="s1">(10,1)$&#39;</span><span class="p">)</span>

<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">product</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">product</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal</span><span class="si">{N}</span><span class="s1">(10,1) </span><span class="se">\\</span><span class="s1">times \mathcal</span><span class="si">{N}</span><span class="s1">(10,1)$&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">product</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(=10.000, =0.500)
</pre></div>
</div>
<img alt="../../../../_images/ba50508d45a41e912f2845052d4a9a05b0497cb3f7ee11ad2d41c0339c068f81.png" src="../../../../_images/ba50508d45a41e912f2845052d4a9a05b0497cb3f7ee11ad2d41c0339c068f81.png" />
</div>
</div>
<p>The result of the multiplication is taller and narrow than the original Gaussian but the mean is unchanged. Does this match your intuition?</p>
<p>Think of the Gaussians as two measurements. If I measure twice and get 10 meters each time, I should conclude that the length is close to 10 meters. Thus the mean should be 10. It would make no sense to conclude the length is actually 11, or 9.5. Also, I am more confident with two measurements than with one, so the variance of the result should be smaller.</p>
<p>Measure twice, cut once is a well known saying. Gaussian multiplication is a mathematical model of this physical fact.</p>
<p>Im unlikely to get the same measurement twice in a row. Now lets plot the pdf of <span class="math notranslate nohighlight">\(\mathcal{N}(10.2,\, 1) \times \mathcal{N}(9.7,\, 1)\)</span>. What do you think the result will be? Think about it, and then look at the graph.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_products</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">):</span> 
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">product</span> <span class="o">=</span> <span class="n">gaussian_multiply</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>

    <span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">g1</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal</span><span class="si">{N}</span><span class="s1">$&#39;</span><span class="o">+</span><span class="s1">&#39;$(</span><span class="si">{}</span><span class="s1">,</span><span class="si">{}</span><span class="s1">)$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">g1</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">g1</span><span class="o">.</span><span class="n">var</span><span class="p">))</span>

    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g2</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathcal</span><span class="si">{N}</span><span class="s1">$&#39;</span><span class="o">+</span><span class="s1">&#39;$(</span><span class="si">{}</span><span class="s1">,</span><span class="si">{}</span><span class="s1">)$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">g2</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">g2</span><span class="o">.</span><span class="n">var</span><span class="p">))</span>

    <span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">product</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">product</span><span class="o">.</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;product&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
    
<span class="n">z1</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">z2</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">9.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
 
<span class="n">plot_products</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/089a4c0c89c5975399461116f4675dcbab63fd442ec092ecb0318e429254c836.png" src="../../../../_images/089a4c0c89c5975399461116f4675dcbab63fd442ec092ecb0318e429254c836.png" />
</div>
</div>
<p>If you ask two people to measure the distance of a table from a wall, and one gets 10.2 meters, and the other got 9.7 meters, your best guess must be the average, 9.95 meters if you trust the skills of both equally.</p>
<p>Recall the g-h filter. We agreed that if I weighed myself on two scales, and the first read 160 lbs while the second read 170 lbs, and both were equally accurate, the best estimate was 165 lbs. Furthermore I should be a bit more confident about 165 lbs vs 160 lbs or 170 lbs because I now have two readings, both near this estimate, increasing my confidence that neither is wildly wrong.</p>
<p>This becomes counter-intuitive in more complicated situations, so lets consider it further. Perhaps a more reasonable assumption would be that one person made a mistake, and the true distance is either 10.2 or 9.7, but certainly not 9.95. Surely that is possible. But we know we have noisy measurements, so we have no reason to think one of the measurements has no noise, or that one person made a gross error that allows us to discard their measurement. Given all available information, the best estimate must be 9.95.</p>
<p>In the update step of the Kalman filter we are not combining two measurements, but one measurement and the prior, our estimate before incorporating the measurement. We went through this logic for the g-h filter. It doesnt matter if we are incorporating information from two measurements, or a measurement and a prediction, the math is the same.</p>
<p>Lets look at that. Ill create a fairly inaccurate prior of <span class="math notranslate nohighlight">\(\mathcal N(8.5, 1.5)\)</span> and a more accurate measurement of <span class="math notranslate nohighlight">\(\mathcal N(10.2, 0.5).\)</span> By accurate I mean the sensor variance is smaller than the priors variance, not that I somehow know that the dog is closer to 10.2 than 8.5. Next Ill plot the reverse relationship: an accurate prior of <span class="math notranslate nohighlight">\(\mathcal N(8.5, 0.5)\)</span> and a inaccurate measurement of <span class="math notranslate nohighlight">\(\mathcal N(10.2, 1.5)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">8.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">plot_products</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="n">prior</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">8.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">10.2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="n">plot_products</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/ecd3a7b07dfc53c5d0aabd160cf39412dc34648ed7312cd1a4c0b0272cace3d4.png" src="../../../../_images/ecd3a7b07dfc53c5d0aabd160cf39412dc34648ed7312cd1a4c0b0272cace3d4.png" />
<img alt="../../../../_images/84f2993e440cc82536871ddd62a652e6433c79b636f36e0b18e4da2b57463b94.png" src="../../../../_images/84f2993e440cc82536871ddd62a652e6433c79b636f36e0b18e4da2b57463b94.png" />
</div>
</div>
<p>The result is a Gaussian that is taller than either input. This makes sense - we have incorporated information, so our variance should have been reduced. And notice how the result is far closer to the the input with the smaller variance. We have more confidence in that value, so it makes sense to weight it more heavily.</p>
<p>It <em>seems</em> to work, but is it really correct? There is more to say about this, but I want to get a working filter going so you can it experience it in concrete terms. After that we will revisit Gaussian multiplication and determine why it is correct.</p>
</section>
<section id="interactive-example">
<h3>Interactive Example<a class="headerlink" href="#interactive-example" title="Permalink to this headline">#</a></h3>
<p>This interactive code provides sliders to alter the mean and variance of two Gaussians that are being multiplied together. As you move the sliders the plot is redrawn. Place your cursor inside the code cell and press CTRL+Enter to execute it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="k">def</span> <span class="nf">interactive_gaussian</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">):</span>
    <span class="n">g1</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">m1</span><span class="p">,</span> <span class="n">v1</span><span class="p">)</span>
    <span class="n">g2</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">m2</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>
    <span class="n">plot_products</span><span class="p">(</span><span class="n">g1</span><span class="p">,</span> <span class="n">g2</span><span class="p">)</span>
    
<span class="n">interact</span><span class="p">(</span><span class="n">interactive_gaussian</span><span class="p">,</span>
         <span class="n">m1</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">10.</span><span class="p">,</span> <span class="mf">.5</span><span class="p">),</span> <span class="n">m2</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mf">.5</span><span class="p">),</span> 
         <span class="n">v1</span><span class="o">=</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">.1</span><span class="p">),</span> <span class="n">v2</span><span class="o">=</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">.1</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/39708ed8914def7799c6a1cc0440d8c1791da35ed60a32ff28c3754212d7d304.png" src="../../../../_images/39708ed8914def7799c6a1cc0440d8c1791da35ed60a32ff28c3754212d7d304.png" />
</div>
</div>
</section>
</section>
<section id="first-kalman-filter">
<h2>First Kalman Filter<a class="headerlink" href="#first-kalman-filter" title="Permalink to this headline">#</a></h2>
<p>Lets get back to concrete terms and implement a Kalman filter. Weve implemented the <code class="docutils literal notranslate"><span class="pre">update()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> functions. We just need to write some boilerplate code to simulate a dog and create the measurements. Ive put a <code class="docutils literal notranslate"><span class="pre">DogSimulation</span></code> class in <code class="docutils literal notranslate"><span class="pre">kf_internal</span></code> to avoid getting distracted with that task.</p>
<p>This boilerplate code sets up the problem by definine the means, variances, and generating the simulated dog movement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">kf_book.kf_internal</span> <span class="k">as</span> <span class="nn">kf_internal</span>
<span class="kn">from</span> <span class="nn">kf_book.kf_internal</span> <span class="kn">import</span> <span class="n">DogSimulation</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>

<span class="n">process_var</span> <span class="o">=</span> <span class="mf">1.</span> <span class="c1"># variance in the dog&#39;s movement</span>
<span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">2.</span> <span class="c1"># variance in the sensor</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">20.</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># dog&#39;s position, N(0, 20**2)</span>
<span class="n">velocity</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">1.</span> <span class="c1"># time step in seconds</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">velocity</span><span class="o">*</span><span class="n">dt</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span> <span class="c1"># displacement to add to x</span>
  
<span class="c1"># simulate dog and get measurements</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span>
    <span class="n">x0</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> 
    <span class="n">velocity</span><span class="o">=</span><span class="n">process_model</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> 
    <span class="n">measurement_var</span><span class="o">=</span><span class="n">sensor_var</span><span class="p">,</span> 
    <span class="n">process_var</span><span class="o">=</span><span class="n">process_model</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>

<span class="c1"># create list of measurements</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>And here is the Kalman filter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;PREDICT</span><span class="se">\t\t\t</span><span class="s1">UPDATE&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;     x      var</span><span class="se">\t\t</span><span class="s1">  z</span><span class="se">\t</span><span class="s1">    x      var&#39;</span><span class="p">)</span>

<span class="c1"># perform Kalman filter on measurement z</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>    
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>

    <span class="n">kf_internal</span><span class="o">.</span><span class="n">print_gh</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;final estimate:        </span><span class="si">{:10.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;actual final position: </span><span class="si">{:10.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dog</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PREDICT			UPDATE
     x      var		  z	    x      var
  1.000  401.000	1.354	  1.352   1.990
  2.352    2.990	1.882	  2.070   1.198
  3.070    2.198	4.341	  3.736   1.047
  4.736    2.047	7.156	  5.960   1.012
  6.960    2.012	6.939	  6.949   1.003
  7.949    2.003	6.844	  7.396   1.001
  8.396    2.001	9.847	  9.122   1.000
 10.122    2.000	12.553	 11.338   1.000
 12.338    2.000	16.273	 14.305   1.000
 15.305    2.000	14.800	 15.053   1.000

final estimate:            15.053
actual final position:     14.838
</pre></div>
</div>
</div>
</div>
<p>Here is an animation of the filter. Predictions are plotted with a red triangle. After the prediction, the filter receives the next measurement, plotted as a black circle. The filter then forms an estimate part way between the two.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">kf_book</span> <span class="kn">import</span> <span class="n">book_plots</span> <span class="k">as</span> <span class="n">book_plots</span>
<span class="kn">from</span> <span class="nn">ipywidgets.widgets</span> <span class="kn">import</span> <span class="n">IntSlider</span>

<span class="c1"># save output in these lists for plotting</span>
<span class="n">xs</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span> 

<span class="c1"># perform Kalman filter</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">20.</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>    
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>

    <span class="c1"># save results</span>
    <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
    <span class="n">xs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_filter</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">cla</span><span class="p">()</span>
    <span class="n">step</span> <span class="o">-=</span> <span class="mi">1</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">step</span> <span class="o">//</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">1</span>
 
    <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_predictions</span><span class="p">(</span><span class="n">predictions</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>    
    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">[:</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">xs</span><span class="p">[:</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">xs</span><span class="p">[:</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">xs</span><span class="p">[:</span><span class="n">i</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
<span class="n">interact</span><span class="p">(</span><span class="n">plot_filter</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span><span class="o">*</span><span class="mi">3</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/ee6b49704f77380a832e27116a492481444ca1897375242a6a37d8c1458d137b.png" src="../../../../_images/ee6b49704f77380a832e27116a492481444ca1897375242a6a37d8c1458d137b.png" />
</div>
</div>
<p>Ive plotted the prior (labeled <em>prediction</em>), the measurements, and the filter output. For each iteration of the loop we form a prior, take a measurement, form a likelihood from the measurement, and then incorporate the likelihood into the prior.</p>
<p>If you look at the plot you can see that the filter estimate is always between the measurement and prediction. Recall that for the g-h filter we argued that the estimate must always be between the measurement and prior. It makes no sense to choose a value outside of the two values. If I predict I am at 10, but measure that I am at 9, it would be foolish to decide that I must be at 8, or 11.</p>
</section>
<section id="code-walkthrough">
<h2>Code Walkthrough<a class="headerlink" href="#code-walkthrough" title="Permalink to this headline">#</a></h2>
<p>Now lets walk through the code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">process_var</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">2.</span>
</pre></div>
</div>
<p>These are the variances for the process model and sensor. The meaning of sensor variance should be clear - it is how much variance there is in each measurement. The process variance is how much error there is in the process model. We are predicting that at each time step the dog moves forward one meter. Dogs rarely do what we expect, and things like hills or the whiff of a squirrel will change his progress. If this was a robot responding to digital commands the performance would be much better, and perhaps the variance would be <span class="math notranslate nohighlight">\(\sigma^2=.05\)</span>. These are not magic numbers; the square root of the variance is the distance error in meters. It is easy to get a Kalman filter working by just plugging in numbers, but if the numbers do not reflect reality the performance of the filter will be poor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">20.</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>This is the dogs initial position expressed as a Gaussian. The position is 0 meters, and the variance to 400 m<span class="math notranslate nohighlight">\(^2\)</span>, which is a standard deviation of 20 meters. You can think of this as saying I believe with 99.7% accuracy the position is 0 plus or minus 60 meters. This is because with Gaussians ~99.7% of values fall within <span class="math notranslate nohighlight">\(\pm3\sigma\)</span> of the mean.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
</pre></div>
</div>
<p>This is the process model - the description of how we think the dog moves. How do I know the velocity? Magic? Consider it a prediction, or perhaps we have a secondary velocity sensor. If this is a robot then this would be a control input to the robot. In subsequent chapters we will learn how to handle situations where you dont have a velocity sensor or input, so please accept this simplification for now.</p>
<p>Next we initialize the simulation and create 10 measurements:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span>
    <span class="n">x0</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> 
    <span class="n">velocity</span><span class="o">=</span><span class="n">process_model</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> 
    <span class="n">measurement_var</span><span class="o">=</span><span class="n">sensor_var</span><span class="p">,</span> 
    <span class="n">process_var</span><span class="o">=</span><span class="n">process_model</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>

<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
</pre></div>
</div>
<p>Now we enter our <code class="docutils literal notranslate"><span class="pre">predict()</span> <span class="pre">...</span> <span class="pre">update()</span></code> loop.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</pre></div>
</div>
<p>The first time through the loop <code class="docutils literal notranslate"><span class="pre">prior</span></code> is <code class="docutils literal notranslate"><span class="pre">(1.0,</span> <span class="pre">401.0)</span></code>, as can be seen in the printed table. After the prediction, we believe that we are at 1.0, and the variance is now 401, up from 400. The variance got worse, which is what always happens during the prediction step because it involves a loss of information.</p>
<p>Then we call the update function using <code class="docutils literal notranslate"><span class="pre">prior</span></code> as the current position.</p>
<p>For this I get this as the result: <code class="docutils literal notranslate"><span class="pre">pos</span> <span class="pre">=</span> <span class="pre">(1.352,</span> <span class="pre">1.990),</span> <span class="pre">z</span> <span class="pre">=</span> <span class="pre">1.354</span></code>.</p>
<p>What is happening? The dog is actually at 1.0 but the measured position is 1.354 due to sensor noise. That is pretty far from the predicted value of 1. The variance of the prior is 401 m<span class="math notranslate nohighlight">\(^2\)</span>. A large variance implies that confidence is very low, so the filter estimates the position to be very close to the measurement: 1.352.</p>
<p>Now look at the variance: 1.99 m<span class="math notranslate nohighlight">\(^2\)</span>. It has dropped tremendously from 401 m<span class="math notranslate nohighlight">\(^2\)</span>. Why? Well, the RFID has a reasonably small variance of 2.0 m<span class="math notranslate nohighlight">\(^2\)</span>, so we trust it far more than the prior. However, the previous belief does contain a bit of useful information, so our variance is now slightly smaller than 2.0.</p>
<p>Now the software loops, calling <code class="docutils literal notranslate"><span class="pre">predict()</span></code> and <code class="docutils literal notranslate"><span class="pre">update()</span></code> in turn. By the end the final estimated position is 15.053 vs the actual position of 14.838. The variance has converged to 1.0 m<span class="math notranslate nohighlight">\(^2\)</span>.</p>
<p>Now look at the plot. The noisy measurements are plotted with black circles, and the filter results are drawn with a solid blue line. Both are quite noisy, but notice how much noisier the measurements are. I plotted the prediction (prior) with red triangles. The estimate always lies between the prior and the measurement. This is your first Kalman filter and it seems to work!</p>
<p>The filtering is implemented in only a few lines of code. Most of the code is either initialization, storing of data, simulating the dog movement, and printing results. The code that performs the filtering is very succinct:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</pre></div>
</div>
<p>If we didnt use the <code class="docutils literal notranslate"><span class="pre">predict</span></code> and <code class="docutils literal notranslate"><span class="pre">update</span></code> functions the code might be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="c1"># predict</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">velocity</span><span class="o">*</span><span class="n">dt</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">pos</span> <span class="o">+</span> <span class="n">dx</span>
    <span class="n">var</span> <span class="o">=</span> <span class="n">var</span> <span class="o">+</span> <span class="n">process_var</span>

    <span class="c1"># update</span>
    <span class="n">pos</span>  <span class="o">=</span> <span class="p">(</span><span class="n">var</span><span class="o">*</span><span class="n">z</span> <span class="o">+</span> <span class="n">sensor_var</span><span class="o">*</span><span class="n">pos</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">sensor_var</span><span class="p">)</span>
    <span class="n">var</span> <span class="o">=</span> <span class="p">(</span><span class="n">var</span> <span class="o">*</span> <span class="n">sensor_var</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="n">sensor_var</span><span class="p">)</span>
</pre></div>
</div>
<p>Just 5 lines of very simple math implements the entire filter!</p>
<p>In this example I only plotted 10 data points so the output from the print statements would not overwhelm us. Now lets look at the filters performance with more data. The variance is plotted as a lightly shaded yellow area between dotted lines. Ive increased the size of the process and sensor variance so they are easier to see on the chart - for a real Kalman filter of course you will not be randomly changing these values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">4.5</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">400.</span><span class="p">)</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">process_model</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>

<span class="n">xs</span><span class="p">,</span> <span class="n">priors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">zs</span><span class="p">):</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>    
    <span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">priors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">prior</span>
    
    <span class="n">xs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">xs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">var</span><span class="o">=</span><span class="n">priors</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_predictions</span><span class="p">(</span><span class="n">priors</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">show_legend</span><span class="p">()</span>
<span class="n">kf_internal</span><span class="o">.</span><span class="n">print_variance</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>	4.4502 2.6507 2.2871 2.1955 2.1712
	2.1647 2.1629 2.1625 2.1623 2.1623
	2.1623 2.1623 2.1623 2.1623 2.1623
	2.1623 2.1623 2.1623 2.1623 2.1623
	2.1623 2.1623 2.1623 2.1623 2.1623
</pre></div>
</div>
<img alt="../../../../_images/c984adac9c3ec4117fe4b96bd3b5e4d1b56782637cbd89a525fd32b9a8c59969.png" src="../../../../_images/c984adac9c3ec4117fe4b96bd3b5e4d1b56782637cbd89a525fd32b9a8c59969.png" />
</div>
</div>
<p>Here we can see that the variance converges to 2.1623 in 9 steps. This means that we have become very confident in our position estimate. It is equal to <span class="math notranslate nohighlight">\(\sigma=1.47\)</span> meters. Contrast this to the sensors <span class="math notranslate nohighlight">\(\sigma=2.12\)</span> meters. The first few measurements are unsure due to our uncertainty of the initial position, but the filter quickly converges to an estimate with lower variance than the sensor!</p>
<p>This code fully implements a Kalman filter. If you have tried to read the literature you are perhaps surprised, because this looks nothing like the endless pages of math in those books.  So long as we worry about <em>using</em> the equations rather than <em>deriving</em> them the topic is approachable. Moreover, I hope youll agree that you have a decent intuitive grasp of what is happening. We represent beliefs with Gaussians, and they get better over time because more measurements means we have more data to work with.</p>
<section id="exercise-modify-variance-values">
<h3>Exercise: Modify Variance Values<a class="headerlink" href="#exercise-modify-variance-values" title="Permalink to this headline">#</a></h3>
<p>Modify the values of <code class="docutils literal notranslate"><span class="pre">process_var</span></code> and <code class="docutils literal notranslate"><span class="pre">sensor_var</span></code> and note the effect on the filter and on the variance. Which has a larger effect on the variance convergence? For example, which results in a smaller variance:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">process_var</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">sensor_var</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<p>or:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">process_var</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">sensor_var</span> <span class="o">=</span> <span class="mi">40</span>
</pre></div>
</div>
</section>
<section id="kf-animation">
<h3>KF Animation<a class="headerlink" href="#kf-animation" title="Permalink to this headline">#</a></h3>
<p>If you are reading this in a browser you will be able to see an animation of the filter tracking the dog directly below this sentence.
<img alt="aiml-common/lectures/pgm/kalman-filters/animations/05_dog_track.gif" src="aiml-common/lectures/pgm/kalman-filters/animations/05_dog_track.gif" /></p>
<p>The top plot shows the output of the filter in green, and the measurements with a dashed red line. The bottom plot shows the Gaussian at each step.</p>
<p>When the track first starts you can see that the measurements varies quite a bit from the initial prediction. At this point the Gaussian probability is small (the curve is low and wide) so the filter does not trust its prediction. As a result, the filter adjusts its estimate a large amount. As the filter innovates you can see that as the Gaussian becomes taller, indicating greater certainty in the estimate, the filters output becomes very close to a straight line. At <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">15</span></code> and greater you can see that there is a large amount of noise in the measurement, but the filter does not react much to it compared to how much it changed for the first noisy measurement.</p>
</section>
</section>
<section id="kalman-gain">
<h2>Kalman Gain<a class="headerlink" href="#kalman-gain" title="Permalink to this headline">#</a></h2>
<p>We see that the filter works. Now lets go back to the math to understand what is happening. The posterior <span class="math notranslate nohighlight">\(x\)</span> is computed as the likelihood times the prior (<span class="math notranslate nohighlight">\(\mathcal L \bar x\)</span>), where both are Gaussians.</p>
<p>Therefore the mean of the posterior is given by:</p>
<div class="math notranslate nohighlight">
\[
\mu=\frac{\bar\sigma^2\, \mu_z + \sigma_z^2 \, \bar\mu} {\bar\sigma^2 + \sigma_z^2}
\]</div>
<p>I use the subscript <span class="math notranslate nohighlight">\(z\)</span> to denote the measurement. We can rewrite this as:</p>
<div class="math notranslate nohighlight">
\[\mu = \left( \frac{\bar\sigma^2}{\bar\sigma^2 + \sigma_z^2}\right) \mu_z + \left(\frac{\sigma_z^2}{\bar\sigma^2 + \sigma_z^2}\right)\bar\mu\]</div>
<p>In this form it is easy to see that we are scaling the measurement and the prior by weights:</p>
<div class="math notranslate nohighlight">
\[\mu = W_1 \mu_z + W_2 \bar\mu\]</div>
<p>The weights sum to one because the denominator is a normalization term. We introduce a new term, <span class="math notranslate nohighlight">\(K=W_1\)</span>, giving us:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mu &amp;= K \mu_z + (1-K) \bar\mu\\
&amp;= \bar\mu + K(\mu_z - \bar\mu)
\end{aligned}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[K = \frac {\bar\sigma^2}{\bar\sigma^2 + \sigma_z^2}\]</div>
<p><span class="math notranslate nohighlight">\(K\)</span> is the <em>Kalman gain</em>. Its the crux of the Kalman filter. It is a scaling term that chooses a value partway between <span class="math notranslate nohighlight">\(\mu_z\)</span> and <span class="math notranslate nohighlight">\(\bar\mu\)</span>.</p>
<p>Lets work a few examples. If the measurement is nine times more accurate than the prior, then <span class="math notranslate nohighlight">\(\bar\sigma^2 = 9\sigma_z^2\)</span>, and</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mu&amp;=\frac{9 \sigma_z^2 \mu_z + \sigma_z^2\, \bar\mu} {9 \sigma_z^2 + \sigma_\mathtt{z}^2} \\
&amp;= \left(\frac{9}{10}\right) \mu_z + \left(\frac{1}{10}\right) \bar\mu
\end{aligned}
\end{split}\]</div>
<p>Hence <span class="math notranslate nohighlight">\(K = \frac 9 {10}\)</span>, and to form the posterior we take nine tenths of the measurement and one tenth of the prior.</p>
<p>If the measurement and prior are equally accurate, then <span class="math notranslate nohighlight">\(\bar\sigma^2 = \sigma_z^2\)</span> and</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{gathered}
\mu=\frac{\sigma_z^2\,  (\bar\mu + \mu_z)}{2\sigma_\mathtt{z}^2} \\
= \left(\frac{1}{2}\right)\bar\mu + \left(\frac{1}{2}\right)\mu_z
\end{gathered}\end{split}\]</div>
<p>which is the average of the two means. It makes intuitive sense to take the average of two equally accurate values.</p>
<p>We can also express the variance in terms of the Kalman gain:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\sigma^2 &amp;= \frac{\bar\sigma^2 \sigma_z^2 } {\bar\sigma^2 + \sigma_z^2} \\
&amp;= K\sigma_z^2 \\
&amp;= (1-K)\bar\sigma^2 
\end{aligned}\end{split}\]</div>
<p>We can understand this by looking at this chart:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">kf_book.book_plots</span> <span class="k">as</span> <span class="nn">book_plots</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">show_residual_chart</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/2568ed49ea5d8bfdd754b7fcac28676ee3ea282f9e7acd244168d57cb96e9d00.png" src="../../../../_images/2568ed49ea5d8bfdd754b7fcac28676ee3ea282f9e7acd244168d57cb96e9d00.png" />
</div>
</div>
<p>The Kalman gain <span class="math notranslate nohighlight">\(K\)</span> is a scale factor that chooses a value along the residual. This leads to an alternative but equivalent implementation for <code class="docutils literal notranslate"><span class="pre">update()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">measurement</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">prior</span>        <span class="c1"># mean and variance of prior</span>
    <span class="n">z</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">measurement</span>  <span class="c1"># mean and variance of measurement</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">x</span>        <span class="c1"># residual</span>
    <span class="n">K</span> <span class="o">=</span> <span class="n">P</span> <span class="o">/</span> <span class="p">(</span><span class="n">P</span> <span class="o">+</span> <span class="n">R</span><span class="p">)</span>  <span class="c1"># Kalman gain</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">K</span><span class="o">*</span><span class="n">y</span>      <span class="c1"># posterior</span>
    <span class="n">P</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">K</span><span class="p">)</span> <span class="o">*</span> <span class="n">P</span>  <span class="c1"># posterior variance</span>
    <span class="k">return</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">movement</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">posterior</span> <span class="c1"># mean and variance of posterior</span>
    <span class="n">dx</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">movement</span> <span class="c1"># mean and variance of movement</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">dx</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">+</span> <span class="n">Q</span>
    <span class="k">return</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Why have I written it in this form, and why have I chosen these terrible variable names? A few related reasons. A majority of books and papers present the Kalman filter in this form. My derivation of the filter from Bayesian principles is not unknown, but it is not used nearly as often. Alternative derivations naturally lead to this form of the equations. Also, the equations for the multivariate Kalman filter look almost exactly like these equations. So, you need to learn and understand them.</p>
<p>Where do the names <code class="docutils literal notranslate"><span class="pre">z</span></code>, <code class="docutils literal notranslate"><span class="pre">P</span></code>, <code class="docutils literal notranslate"><span class="pre">Q</span></code>, and <code class="docutils literal notranslate"><span class="pre">R</span></code> come from? You will see them used in the rest of this book. In the literature <span class="math notranslate nohighlight">\(R\)</span> is nearly universally used for the measurement noise, <span class="math notranslate nohighlight">\(Q\)</span> for the process noise and <span class="math notranslate nohighlight">\(P\)</span> for the variance of the state. Using <span class="math notranslate nohighlight">\(z\)</span> for the measurement is common, albeit not universal. Almost every book and paper you read will use these variable names. Get used to them.</p>
<p>This is also a powerful way to think about filtering. This is the way we reasoned about the g-h filter. It emphasizes taking the residual <span class="math notranslate nohighlight">\(y = \mu_z - \bar\mu\)</span>, finding the Kalman gain as a ratio of our uncertainty in the prior and measurement <span class="math notranslate nohighlight">\(K = P/(P+R)\)</span>, and computing the posterior by adding <span class="math notranslate nohighlight">\(Ky\)</span> to the prior.</p>
<p>The Bayesian aspect is obscured in this form, as is the fact that we are multiplying the likelihood by the prior. Both viewpoints are equivalent because the math is identical. I chose the Bayesian approach because I think it give a much more intuitive yet deep understanding of the probabilistic reasoning. This alternative form using <span class="math notranslate nohighlight">\(K\)</span> gives a deep understanding of what is known as the <em>orthogonal projection</em> approach. Dr. Kalman used that derivation, not Bayesian reasoning, when he invented this filter. You will understand more about this in the next few chapters.</p>
</section>
<section id="full-description-of-the-algorithm">
<h2>Full Description of the Algorithm<a class="headerlink" href="#full-description-of-the-algorithm" title="Permalink to this headline">#</a></h2>
<p>Recall the diagram we used for the g-h filter:
<img alt="aiml-common/lectures/pgm/kalman-filters/figs/residual_chart.png" src="aiml-common/lectures/pgm/kalman-filters/figs/residual_chart.png" /></p>
<p>Weve been doing the same thing in this chapter. The Kalman filter makes a prediction, takes a measurement, and then forms a new estimate somewhere between the two.</p>
<p><strong>This is extremely important to understand</strong>: Every filter in this book implements the same algorithm, just with different mathematical details. The math can become challenging in later chapters, but the idea is easy to understand.</p>
<p>It is important to see past the details of the equations of a specific filter and understand <em>what</em> the equations are calculating and <em>why</em>. There are a tremendous number of filters. They all use different math to implement the same algorithm. The choice of math affects the quality of results and what problems can be represented, but not the underlying ideas.</p>
<p>Here is the generic algorithm:</p>
<p><strong>Initialization</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Initialize the state of the filter
2. Initialize our belief in the state
</pre></div>
</div>
<p><strong>Predict</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Use system behavior to predict state at the next time step
2. Adjust belief to account for the uncertainty in prediction
</pre></div>
</div>
<p><strong>Update</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Get a measurement and associated belief about its accuracy
2. Compute residual between estimated state and measurement
3. Compute scaling factor based on whether the measurement
or prediction is more accurate
4. set state between the prediction and measurement based 
on scaling factor
5. update belief in the state based on how certain we are 
in the measurement
</pre></div>
</div>
<p>You will be hard pressed to find a Bayesian filter algorithm that does not fit into this form. Some filters will not include some aspects, such as error in the prediction, and others will have very complicated methods of computation, but this is what they all do.</p>
<p>The equations for the univariate Kalman filter are:</p>
<p><u>Predict</u></p>
<p><span class="math notranslate nohighlight">\(\begin{array}{|l|l|l|}
\hline
\text{Equation} &amp; \text{Implementation} &amp; \text{Kalman Form}\\
\hline
 \bar x = x + f_x &amp; \bar\mu = \mu + \mu_{f_x} &amp; \bar x = x + dx\\
&amp; \bar\sigma^2 = \sigma^2 + \sigma_{f_x}^2 &amp; \bar P = P + Q\\
\hline
\end{array}\)</span></p>
<p><u>Update</u></p>
<p><span class="math notranslate nohighlight">\(\begin{array}{|l|l|l|}
\hline
\text{Equation} &amp; \text{Implementation}&amp; \text{Kalman Form}\\
\hline
 x = \| \mathcal L\bar x\| &amp; y = z - \bar\mu &amp; y = z - \bar x\\
 &amp; K = \frac {\bar\sigma^2} {\bar\sigma^2 + \sigma_z^2} &amp; K = \frac {\bar P}{\bar P+R}\\
 &amp; \mu = \bar \mu + Ky &amp; x = \bar x + Ky\\
 &amp; \sigma^2 = \frac {\bar\sigma^2 \sigma_z^2} {\bar\sigma^2 + \sigma_z^2} &amp; P = (1-K)\bar P\\
\hline
\end{array}\)</span></p>
</section>
<section id="comparison-with-g-h-and-discrete-bayes-filters">
<h2>Comparison with g-h and discrete Bayes Filters<a class="headerlink" href="#comparison-with-g-h-and-discrete-bayes-filters" title="Permalink to this headline">#</a></h2>
<p>Now is a good time to understand the differences between these three filters in terms of how we model errors. For the g-h filter we modeled our measurements as shown in this graph:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">book_plots</span><span class="o">.</span><span class="n">plot_errorbars</span><span class="p">([(</span><span class="mi">160</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;A&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">)],</span> <span class="n">xlims</span><span class="o">=</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">180</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/d0e05a4ac2198d9c08fdb748e3367b647887b5e1462112ad73203e20dec139f8.png" src="../../../../_images/d0e05a4ac2198d9c08fdb748e3367b647887b5e1462112ad73203e20dec139f8.png" />
</div>
</div>
<p>Sensor A returned a measurement of 160, and sensor B returned 170. The bars are <a class="reference external" href="https://en.wikipedia.org/wiki/Error_bar"><em>error bars</em></a> - they illustrate the possible range of error for the measurement. Hence, the actual value that A is measuring can be between 157 to 163, and B is measuring a value between 161 to 179.</p>
<p>I did not define it at the time, but this is a [<em>uniform distribution</em>](<a class="reference external" href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)</a>). A uniform distribution assigns equal probability to any event in the range. According to this model it is equally likely for sensor A to read 157, 160, or 163. Any value outside these ranges have 0 probability.</p>
<p>We can model this situation with Gaussians. Ill use <span class="math notranslate nohighlight">\(\mathcal{N}(160, 3^2)\)</span> for sensor A, and <span class="math notranslate nohighlight">\(\mathcal{N}(170, 9^2)\)</span> for sensor B. Ive plotted these below with the uniform distribution error bars for comparison.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">145</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">3</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>

<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">170</span><span class="p">,</span> <span class="mi">9</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.04</span><span class="p">],</span> <span class="n">xerr</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">capthick</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="mi">170</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.015</span><span class="p">],</span> <span class="n">xerr</span><span class="o">=</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">capthick</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/6129873d984cef87b3697914b6d0efd00b520fe2724d2f3179032155b132862a.png" src="../../../../_images/6129873d984cef87b3697914b6d0efd00b520fe2724d2f3179032155b132862a.png" />
</div>
</div>
<p>Using a uniform or Gaussian distribution is a modeling choice. Neither exactly describes reality. In most cases the Gaussian distribution is more realistic. Most sensors are more likely to return readings near the value being measured, and unlikely to return a reading far from that value. The Gaussian models this tendency. In contrast the uniform distribution assumes that any measurement within a range is equally likely.</p>
<p>Now lets see the <em>discrete distribution</em> used in the discrete Bayes filter. This model divides the range of possible values into discrete ranges and assigns a probability to each bucket. This assignment can be entirely arbitrary so long as the probabilities sum to one.</p>
<p>Lets plot the data for one sensor using a uniform distribution, a Gaussian distribution, and a discrete distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">random</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">145</span><span class="p">,</span> <span class="mi">190</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">3</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>
<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">random</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">)])</span>
<span class="n">belief</span> <span class="o">=</span> <span class="n">belief</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">155</span><span class="p">,</span> <span class="mi">165</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">belief</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="mi">160</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.04</span><span class="p">],</span> <span class="n">xerr</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">capthick</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">capsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">170</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/2728b59324bcfe618867aa310bf0949d765b91207b9be0da4d93f98bee640b53.png" src="../../../../_images/2728b59324bcfe618867aa310bf0949d765b91207b9be0da4d93f98bee640b53.png" />
</div>
</div>
<p>I used random numbers to form the discrete distribution to illustrate that it can model any arbitrary probability distribution. This provides it with enormous power. With enough discrete buckets we can model the error characteristics of any sensor no matter how complicated. But with this power comes mathematical intractability. Multiplying or adding Gaussians takes two lines of math, and the result is another Gaussian. This regularity allows us to perform powerful analysis on the performance and behavior of our filters. Multiplying or adding a discrete distribution requires looping over the data, and we have no easy way to characterize the result.  Analyzing the performance characteristics of a filter based on a discrete distribution is extremely difficult to impossible.</p>
<p>There is no correct choice here. Later in the book we will introduce the <em>particle filter</em> which uses a discrete distribution. It is an extremely powerful technique because it can handle arbitrarily complex situations. This comes at the cost of slow performance, and resistance to analytical analysis.</p>
<p>For now we will ignore these matters and return to using Gaussians for the next several chapters. As we progress you will learn the strengths and limitations of using Gaussians in our mathematical models.</p>
</section>
<section id="introduction-to-designing-a-filter">
<h2>Introduction to Designing a Filter<a class="headerlink" href="#introduction-to-designing-a-filter" title="Permalink to this headline">#</a></h2>
<p>So far we have developed filters for a position sensor. We are used to this problem by now, and may feel ill-equipped to implement a Kalman filter for a different problem. To be honest, there is still quite a bit of information missing from this presentation. Following chapters will fill in the gaps. Still, lets get a feel for it by designing and implementing a Kalman filter for a thermometer. The sensor for the thermometer outputs a voltage that corresponds to the temperature that is being measured. We have read the manufacturers specifications for the sensor, and it tells us that the sensor exhibits white noise with a standard deviation of 0.13 volts.</p>
<p>We can simulate the temperature sensor measurement with this function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">volt</span><span class="p">(</span><span class="n">voltage</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">voltage</span> <span class="o">+</span> <span class="p">(</span><span class="n">randn</span><span class="p">()</span> <span class="o">*</span> <span class="n">std</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we need to write the Kalman filter processing loop. As with our previous problem, we need to perform a cycle of predicting and updating. The sensing step probably seems clear - call <code class="docutils literal notranslate"><span class="pre">volt()</span></code> to get the measurement, pass the result into <code class="docutils literal notranslate"><span class="pre">update()</span></code> method, but what about the predict step? We do not have a sensor to detect movement in the voltage, and for any small duration we expect the voltage to remain constant. How shall we handle this?</p>
<p>As always, we will trust in the math. We have no known movement, so we will set that to zero. However, that means that we are predicting that the temperature will never change. If that is true, then over time we should become extremely confident in our results. Once the filter has enough measurements it will become very confident that it can predict the subsequent temperatures, and this will lead it to ignoring measurements that result due to an actual temperature change. This is called a <em>smug</em> filter, and is something you want to avoid. So we will add a bit of error to our prediction step to tell the filter not to discount changes in voltage over time. In the code below I set <code class="docutils literal notranslate"><span class="pre">process_var</span> <span class="pre">=</span> <span class="pre">.05**2</span></code>. This is the expected variance in the change of voltage over each time step. I chose this value merely to be able to show how the variance changes through the update and predict steps. For a real sensor you would set this value for the actual amount of change you expect. For example, this would be an extremely small number if it is a thermometer for ambient air temperature in a house, and a high number if this is a thermocouple in a chemical reaction chamber. We will say more about selecting the actual value in the later chapters.</p>
<p>Lets see what happens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">temp_change</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">voltage_std</span> <span class="o">=</span> <span class="mf">.13</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">.05</span><span class="o">**</span><span class="mi">2</span>
<span class="n">actual_voltage</span> <span class="o">=</span> <span class="mf">16.3</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">25.</span><span class="p">,</span> <span class="mf">1000.</span><span class="p">)</span> <span class="c1"># initial state</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">volt</span><span class="p">(</span><span class="n">actual_voltage</span><span class="p">,</span> <span class="n">voltage_std</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">estimates</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">voltage_std</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

    <span class="c1"># save for latter plotting</span>
    <span class="n">estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">var</span><span class="p">)</span>

<span class="c1"># plot the filter output and the variance</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">estimates</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ps</span><span class="p">))</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">show_legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">set_labels</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;volts&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Variance&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Variance converges to </span><span class="si">{:.3f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ps</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/8d16d45555cbf25aeb186e3c143fcf7d6176baf4e10d1961c7d831c71f76a794.png" src="../../../../_images/8d16d45555cbf25aeb186e3c143fcf7d6176baf4e10d1961c7d831c71f76a794.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance converges to 0.005
</pre></div>
</div>
<img alt="../../../../_images/5adfcc3edf7b8c3de03d072d1cfff16f95018cd6fa626c3ac3cef2ec4ca7784c.png" src="../../../../_images/5adfcc3edf7b8c3de03d072d1cfff16f95018cd6fa626c3ac3cef2ec4ca7784c.png" />
</div>
</div>
<p>The first plot shows the individual sensor measurements vs the filter output. Despite a lot of noise in the sensor we quickly discover the approximate voltage of the sensor. In the run I just completed at the time of authorship, the last voltage output from the filter is <span class="math notranslate nohighlight">\(16.213\)</span>, which is quite close to the <span class="math notranslate nohighlight">\(16.4\)</span> used by the <code class="docutils literal notranslate"><span class="pre">volt()</span></code> function. On other runs I have gotten larger and smaller results.</p>
<p>Spec sheets are what they sound like - specifications. Any individual sensor will exhibit different performance based on normal manufacturing variations. Values are often maximums - the spec is a guarantee that the performance will be at least that good. If you buy an expensive piece of equipment it often comes with a sheet of paper displaying the test results of your specific item; this is usually very trustworthy. On the other hand, if this is a cheap sensor it is likely it received little to no testing prior to being sold. Manufacturers typically test a small subset of their output to verify that a sample falls within the desired performance range. If you have a critical application you will need to read the specification sheet carefully to figure out exactly what they mean by their ranges. Do they guarantee their number is a maximum, or is it, say, the <span class="math notranslate nohighlight">\(3\sigma\)</span> error rate? Is every item tested? Is the variance normal, or some other distribution? Finally, manufacturing is not perfect. Your part might be defective and not match the performance on the sheet.</p>
<p>For example, I am looking at a data sheet for an airflow sensor. There is a field <em>Repeatability</em>, with the value <span class="math notranslate nohighlight">\(\pm 0.50\%\)</span>. Is this a Gaussian? Is there a bias? For example, perhaps the repeatability is nearly <span class="math notranslate nohighlight">\(0.0\%\)</span> at low temperatures, and always nearly  <span class="math notranslate nohighlight">\(+0.50\%\)</span> at high temperatures. Data sheets for electrical components often contain a section of Typical Performance Characteristics. These are used to capture information that cannot be easily conveyed in a table. For example, I am looking at a chart showing output voltage vs current for a LM555 timer. There are three curves showing the performance at different temperatures. The response is ideally linear, but all three lines are curved. This clarifies that errors in voltage outputs are probably not Gaussian - in this chips case higher temperatures lead to lower voltage output, and the voltage output is quite nonlinear if the input current is very high.</p>
<p>As you might guess, modeling the performance of your sensors is one of the harder parts of creating a Kalman filter that performs well.</p>
<section id="animation">
<h3>Animation<a class="headerlink" href="#animation" title="Permalink to this headline">#</a></h3>
<p>For those reading this in a browser here is an animation showing the filter working. If you are not using a browser you can see this plot at <a class="github reference external" href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python/blob/master/animations/05_volt_animate.gif">rlabbe/Kalman-and-Bayesian-Filters-in-Python</a>.</p>
<img alt="aiml-common/lectures/pgm/kalman-filters/animations/05_volt_animate.gif" src="aiml-common/lectures/pgm/kalman-filters/animations/05_volt_animate.gif" />
<p>The top plot in the animation draws a green line for the predicted next voltage, then a red + for the actual measurement, draws a light red line to show the residual, and then draws a blue line to the filters output. You can see that when the filter starts the corrections made are quite large, but after only a few updates the filter only adjusts its output by a small amount even when the measurement is far from it.</p>
<p>The lower plot shows the Gaussian belief as the filter innovates. When the filter starts the Gaussian curve is centered over 25, our initial guess for the voltage, and is very wide and short due to our initial uncertainty. But as the filter innovates, the Gaussian quickly moves to about 16.0 and becomes taller, reflecting the growing confidence that the filter has in its estimate for the voltage. You will also note that the Gaussians height bounces up and down a little bit. If you watch closely you will see that the Gaussian becomes a bit shorter and more spread out during the prediction step, and becomes taller and narrower as the filter incorporates another measurement.</p>
<p>Think of this animation in terms of the g-h filter. At each step the g-h filter makes a prediction, takes a measurement, computes the residual (the difference between the prediction and the measurement), and then selects a point on the residual line based on the scaling factor <span class="math notranslate nohighlight">\(g\)</span>. The Kalman filter is doing exactly the same thing, except that the scaling factor <span class="math notranslate nohighlight">\(g\)</span> varies with time. As the filter becomes more confident in its state the scaling factor favors the filters prediction over the measurement.</p>
</section>
</section>
<section id="example-extreme-amounts-of-noise">
<h2>Example: Extreme Amounts of Noise<a class="headerlink" href="#example-extreme-amounts-of-noise" title="Permalink to this headline">#</a></h2>
<p>With the dog filter I didnt put a lot of noise in the signal, and I guessed that the dog was at position 0. How does the filter perform in real world conditions? I will start by injecting more noise in the RFID sensor while leaving the process variance at 2 m<span class="math notranslate nohighlight">\(^2\)</span>.  I will inject an extreme amount of noise - noise that apparently swamps the actual measurement. What does your intuition say about the filters performance if the sensor has a standard deviation of 300 meters? In other words, an actual position of 1.0 m might be reported as 287.9 m, or -589.6 m, or any other number in roughly that range. Think about it before you scroll down.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">300.</span><span class="o">**</span><span class="mi">2</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>    
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/5da1e1937a46791c9b33e4e1b16219b190bd2bc7b47e97d580e3d645136f120f.png" src="../../../../_images/5da1e1937a46791c9b33e4e1b16219b190bd2bc7b47e97d580e3d645136f120f.png" />
</div>
</div>
<p>In this example the noise is extreme yet the filter still outputs a nearly straight line! This is an astonishing result! What do you think might be the cause of this performance?</p>
<p>We get a nearly straight line because our process error is small. A small process error tells the filter that the prediction is very trustworthy, and the prediction is a straight line, so the filter outputs a nearly straight line.</p>
</section>
<section id="example-incorrect-process-variance">
<h2>Example: Incorrect Process Variance<a class="headerlink" href="#example-incorrect-process-variance" title="Permalink to this headline">#</a></h2>
<p>That last filter looks fantastic! Why wouldnt we set the process variance very low, as it guarantees the result will be straight and smooth?</p>
<p>The process variance tells the filter how much the system is changing over time. If you lie to the filter by setting this number artificially low the filter will not be able to react to changes that are happening. Lets have the dog increase his velocity by a small amount at each time step and see how the filter performs with a process variance of 0.001 m<span class="math notranslate nohighlight">\(^2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">20.</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">.001</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="o">*</span><span class="mi">10000</span><span class="p">)</span>
<span class="n">zs</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="n">dog</span><span class="o">.</span><span class="n">velocity</span> <span class="o">+=</span> <span class="mf">0.04</span>
    <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">())</span>

<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>    
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/48f72df7ac9431021812671afae2c9407ee573c4859a1b34516f729d1f9ce335.png" src="../../../../_images/48f72df7ac9431021812671afae2c9407ee573c4859a1b34516f729d1f9ce335.png" />
</div>
</div>
<p>It is easy to see that the filter is not correctly responding to the measurements. The measurements  clearly indicate that the dog is changing speed but the filter has been told that its predictions are nearly perfect so it almost entirely ignores them. I encourage you to adjust the amount of movement in the dog vs process variance. We will also be studying this topic much more in the later chapters. The key point is to recognize that math requires that the variances correctly describe your system. The filter does not notice that it is diverging from the measurements and correct itself. It computes the Kalman gain from the variance of the prior and the measurement, and forms the estimate depending on which is more accurate.</p>
</section>
<section id="example-bad-initial-estimate">
<h2>Example: Bad Initial Estimate<a class="headerlink" href="#example-bad-initial-estimate" title="Permalink to this headline">#</a></h2>
<p>Now lets look at the results when we make a bad initial estimate of position. To avoid obscuring the results Ill reduce the sensor variance to 30, but set the initial position to 1000 meters. Can the filter recover from a 1000 meter error?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">5.</span><span class="o">**</span><span class="mi">2</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1000.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>    
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/090cca4cbdf39429ca6952bd1b4ac23e6ef1c846919c00c032620776292edcc5.png" src="../../../../_images/090cca4cbdf39429ca6952bd1b4ac23e6ef1c846919c00c032620776292edcc5.png" />
</div>
</div>
<p>Again the answer is yes! Because we are relatively sure about our belief in the sensor (<span class="math notranslate nohighlight">\(\sigma^2=5^2\)</span>) after only the first step we have changed our position estimate from 1000 m to roughly 50 m. After another 5-10 measurements we have converged to the correct value. This is how we get around the chicken and egg problem of initial guesses. In practice we would likely assign the first measurement from the sensor as the initial value, but you can see it doesnt matter much if we wildly guess at the initial conditions - the Kalman filter still converges so long as the filter variances are chosen to match the actual process and measurement variances.</p>
</section>
<section id="example-large-noise-and-bad-initial-estimate">
<h2>Example: Large Noise and Bad Initial Estimate<a class="headerlink" href="#example-large-noise-and-bad-initial-estimate" title="Permalink to this headline">#</a></h2>
<p>What about the worst of both worlds, large noise and a bad initial estimate?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">30000.</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1000.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span> 
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/a82a1aea8c5ad9a892b929a6939e96af96135973882729492a4e75eef2536099.png" src="../../../../_images/a82a1aea8c5ad9a892b929a6939e96af96135973882729492a4e75eef2536099.png" />
</div>
</div>
<p>This time the filter struggles. Notice that the previous example only computed 100 updates, whereas this example uses 1000. By my eye it takes the filter 400 or so iterations to become reasonable accurate, but maybe over 600 before the results are good. Kalman filters are good, but we cannot expect miracles. If we have extremely noisy data and extremely bad initial conditions, this is as good as it gets.</p>
<p>Finally, lets implement the suggestion of using the first measurement as the initial position.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">30000.</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span> 
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_measurements</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_filter</span><span class="p">(</span><span class="n">ps</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/eadf26c346cf830a7535fbf4424a9637453099bffbe80444818efb997e0a4c93.png" src="../../../../_images/eadf26c346cf830a7535fbf4424a9637453099bffbe80444818efb997e0a4c93.png" />
</div>
</div>
<p>This simple change significantly improves the results. On some runs it takes 200 iterations or so to settle to a good solution, but other runs it converges very rapidly. This all depends on the amount of noise in the first measurement. A large amount of noise causes the initial estimate to be far from the dogs position.</p>
<p>200 iterations may seem like a lot, but the amount of noise we are injecting is truly huge. In the real world we use sensors like thermometers,  laser range finders, GPS satellites, computer vision, and so on. None have the enormous errors in these examples. A reasonable variance for a cheap thermometer might be 0.2 C<span class="math notranslate nohighlight">\(^{\circ 2}\)</span>, and our code is using 30,000 C<span class="math notranslate nohighlight">\(^{\circ 2}\)</span>.</p>
</section>
<section id="exercise-interactive-plots">
<h2>Exercise: Interactive Plots<a class="headerlink" href="#exercise-interactive-plots" title="Permalink to this headline">#</a></h2>
<p>Implement the Kalman filter using Jupyter Notebooks animation features to allow you to modify the various constants in real time using sliders. Refer to the section <strong>Interactive Gaussians</strong> in the <strong>Gaussians</strong> chapter to see how to do this. You will use the <code class="docutils literal notranslate"><span class="pre">interact()</span></code> function to call a calculation and plotting function. Each parameter passed into <code class="docutils literal notranslate"><span class="pre">interact()</span></code> automatically gets a slider created for it. I have written the boilerplate for this; you fill in the required code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>
<span class="kn">from</span> <span class="nn">kf_book.book_plots</span> <span class="kn">import</span> <span class="n">FloatSlider</span>

<span class="k">def</span> <span class="nf">plot_kalman_filter</span><span class="p">(</span><span class="n">start_pos</span><span class="p">,</span> 
                       <span class="n">sensor_noise</span><span class="p">,</span> 
                       <span class="n">velocity</span><span class="p">,</span> 
                       <span class="n">process_noise</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">();</span>
    <span class="c1"># your code goes here</span>

<span class="n">interact</span><span class="p">(</span><span class="n">plot_kalman_filter</span><span class="p">,</span>
         <span class="n">start_pos</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
         <span class="n">sensor_noise</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> 
         <span class="n">velocity</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">2.</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">2.</span><span class="p">),</span> 
         <span class="n">process_noise</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">100.</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 900x400 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
<section id="solution">
<h3>Solution<a class="headerlink" href="#solution" title="Permalink to this headline">#</a></h3>
<p>One possible solution follows. We have sliders for the start position, the amount of noise in the sensor, the amount we move in each time step, and how much movement error there is. Process noise is perhaps the least clear - it models how much the dog wanders off course at each time step, so we add that into the dogs position at each step. I set the random number generator seed so that each redraw uses the same random numbers, allowing us to compare the graphs as we move the sliders.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">seed</span> 
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="k">def</span> <span class="nf">plot_kalman_filter</span><span class="p">(</span><span class="n">start_pos</span><span class="p">,</span> 
                       <span class="n">sensor_noise</span><span class="p">,</span> 
                       <span class="n">velocity</span><span class="p">,</span>
                       <span class="n">process_noise</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">zs</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>   
    <span class="n">seed</span><span class="p">(</span><span class="mi">303</span><span class="p">)</span>
    <span class="n">dog</span> <span class="o">=</span> <span class="n">DogSimulation</span><span class="p">(</span><span class="n">start_pos</span><span class="p">,</span> <span class="n">velocity</span><span class="p">,</span> <span class="n">sensor_noise</span><span class="p">,</span> <span class="n">process_noise</span><span class="p">)</span>
    <span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dog</span><span class="o">.</span><span class="n">move_and_sense</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)]</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1000.</span><span class="p">)</span> <span class="c1"># mean and variance</span>
    <span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">velocity</span><span class="p">,</span> <span class="n">process_noise</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">:</span>    
        <span class="n">pos</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_noise</span><span class="p">))</span>
        <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;measurement&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;#004080&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;filter&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>

<span class="n">interact</span><span class="p">(</span><span class="n">plot_kalman_filter</span><span class="p">,</span>
         <span class="n">start_pos</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
         <span class="n">sensor_noise</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> 
         <span class="n">velocity</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">2.</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">2.</span><span class="p">),</span> 
         <span class="n">process_noise</span><span class="o">=</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">40</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/a24bc5137a015d21b9fcc038042b3b90555fcaf941ddf470687b904439eebf7e.png" src="../../../../_images/a24bc5137a015d21b9fcc038042b3b90555fcaf941ddf470687b904439eebf7e.png" />
</div>
</div>
</section>
</section>
<section id="exercise-nonlinear-systems">
<h2>Exercise - Nonlinear Systems<a class="headerlink" href="#exercise-nonlinear-systems" title="Permalink to this headline">#</a></h2>
<p>Our equations for the Kalman filter are linear:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned}
\mathcal{N}(\bar\mu,\, \bar\sigma^2) &amp;= \mathcal{N}(\mu,\, \sigma^2) + \mathcal{N}(\mu_\mathtt{move},\, \sigma^2_\mathtt{move})\\
\mathcal{N}(\mu,\, \sigma^2) &amp;= \mathcal{N}(\bar\mu,\, \bar\sigma^2)  \times \mathcal{N}(\mu_\mathtt{z},\, \sigma^2_\mathtt{z})
\end{aligned}\end{split}\]</div>
<p>Do you suppose that this filter works well or poorly with nonlinear systems?</p>
<p>Implement a Kalman filter that uses the following equation to generate the measurement value</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="mf">3.</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
</pre></div>
</div>
<p>Adjust the variance and initial positions to see the effect. What is, for example, the result of a very bad initial guess?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#enter your code here.</span>
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h3>Solution<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="n">sensor_var</span> <span class="o">=</span> <span class="mf">30.</span>
<span class="n">process_var</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">100.</span><span class="p">,</span> <span class="mf">500.</span><span class="p">)</span>
<span class="n">process_model</span> <span class="o">=</span> <span class="n">gaussian</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="n">process_var</span><span class="p">)</span>

<span class="n">zs</span><span class="p">,</span> <span class="n">ps</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">process_model</span><span class="p">)</span>

    <span class="n">z</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">i</span><span class="o">/</span><span class="mf">3.</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span> <span class="o">+</span> <span class="n">randn</span><span class="p">()</span><span class="o">*</span><span class="mf">1.2</span>
    <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    
    <span class="n">pos</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">gaussian</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sensor_var</span><span class="p">))</span>
    <span class="n">ps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos</span><span class="o">.</span><span class="n">mean</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;measurement&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;#004080&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;filter&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/ce378630c2ce448b1cf182637b7562cfdb3b8d290ebe26e43a1554df4e3413fd.png" src="../../../../_images/ce378630c2ce448b1cf182637b7562cfdb3b8d290ebe26e43a1554df4e3413fd.png" />
</div>
</div>
</section>
<section id="discussion">
<h3>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">#</a></h3>
<p>This is terrible! The output is not at all like a sin wave, except in the grossest way. With linear systems we could add extreme amounts of noise to our signal and still extract a very accurate result, but here even modest noise creates a very bad result.</p>
<p>If we recall the <strong>g-h Filter</strong> chapter we can understand what is happening here. The structure of the g-h filter requires that the filter output chooses a value part way between the prediction and measurement. A varying signal like this one is always accelerating, whereas our process model assumes constant velocity, so the filter is mathematically guaranteed to always lag the input signal.</p>
<p>Very shortly after practitioners began implementing Kalman filters they recognized the poor performance of them for nonlinear systems and began devising ways of dealing with it. Later chapters are devoted to this problem.</p>
</section>
</section>
<section id="fixed-gain-filters">
<h2>Fixed Gain Filters<a class="headerlink" href="#fixed-gain-filters" title="Permalink to this headline">#</a></h2>
<p>Embedded computers usually have extremely limited processors. Many do not have floating point circuitry. These simple equations can impose a heavy burden on the chip. This is less true as technology advances, but do not underestimate the value of spending one dollar less on a processor when you will be buying millions of them.</p>
<p>In the example above the variance of the filter converged to a fixed value. This will always happen if the variance of the measurement and process is a constant. You can take advantage of this fact by running simulations to determine what the variance converges to. Then you can hard code this value into your filter. So long as you initialize the filter to a good starting guess (I recommend using the first measurement as your initial value) the filter will perform very well. For example, the dog tracking filter can be reduced to this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="n">K</span> <span class="o">=</span> <span class="mf">.13232</span>  <span class="c1"># experimentally derived Kalman gain</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">z</span> <span class="o">-</span> <span class="n">x</span>   <span class="c1"># residual</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">K</span><span class="o">*</span><span class="n">y</span> <span class="c1"># posterior</span>
    <span class="k">return</span> <span class="n">x</span>
    
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">vel</span><span class="o">*</span><span class="n">dt</span>
</pre></div>
</div>
<p>I used the Kalman gain form of the update function to emphasize that we do not need to consider the variances at all. If the variances converge to a single value so does the Kalman gain.</p>
</section>
<section id="filterpys-implementation">
<h2>FilterPys Implementation<a class="headerlink" href="#filterpys-implementation" title="Permalink to this headline">#</a></h2>
<p>FilterPy implements <code class="docutils literal notranslate"><span class="pre">predict()</span></code> and <code class="docutils literal notranslate"><span class="pre">update()</span></code>.  They work not only for the univariate case developed in this chapter, but the more general multivariate case that we learn in subsequent chapters. Because of this their interface is slightly different. They do not take Gaussians as tuples, but as two separately named variables.</p>
<p><code class="docutils literal notranslate"><span class="pre">predict()</span></code> takes several arguments, but we will only need to use these four:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">Q</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">x</span></code> is the state of the system. <code class="docutils literal notranslate"><span class="pre">P</span></code> is the variance of the system. <code class="docutils literal notranslate"><span class="pre">u</span></code> is the movement due to the process, and <code class="docutils literal notranslate"><span class="pre">Q</span></code> is the noise in the process. You will need to used named arguments when you call <code class="docutils literal notranslate"><span class="pre">predict()</span></code> because most of the arguments are optional. The third argument to <code class="docutils literal notranslate"><span class="pre">predict()</span></code> is <strong>not</strong> <code class="docutils literal notranslate"><span class="pre">u</span></code>.</p>
<p>These may strike you as terrible variable names. They are! As I already mentioned they come from a long history of control theory, and every paper or book you read will use these names. So, we just have to get used to it. Refusing to memorize them means you will never be able to read the literature.</p>
<p>Lets try it for the state <span class="math notranslate nohighlight">\(\mathcal N(10, 3)\)</span> and the movement <span class="math notranslate nohighlight">\(\mathcal N(1, 4)\)</span>. Wed expect a final position of 11 (10+1) with a variance of 7 (3+4).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">filterpy.kalman</span> <span class="k">as</span> <span class="nn">kf</span>
<span class="n">kf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">P</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">4.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(11.0, 7.0)
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">update</span></code> also takes several arguments, but for now you will be interested in these four:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">R</span><span class="p">)</span>
</pre></div>
</div>
<p>As before, <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">P</span></code> are the state and variance of the system. <code class="docutils literal notranslate"><span class="pre">z</span></code> is the measurement, and <code class="docutils literal notranslate"><span class="pre">R</span></code> is the measurement variance. Lets perform the last predict statement to get our prior, and then perform an update:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">10.</span><span class="p">,</span> <span class="n">P</span><span class="o">=</span><span class="mf">3.</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">Q</span><span class="o">=</span><span class="mf">2.</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">x</span><span class="p">)</span>

<span class="n">x</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="n">kf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">P</span><span class="o">=</span><span class="n">P</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mf">12.</span><span class="p">,</span> <span class="n">R</span><span class="o">=</span><span class="mf">3.5</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11.000
11.364 4.455
</pre></div>
</div>
</div>
</div>
<p>I gave it a noisy measurement with a big variance, so the estimate remained close to the prior of 11.</p>
<p>One final point. I did not use the variable name <code class="docutils literal notranslate"><span class="pre">prior</span></code> for the output of the predict step. I will not use that variable name in the rest of the book. The Kalman filter equations just use <span class="math notranslate nohighlight">\(\mathbf x\)</span>. Both the prior and the posterior are the estimated state of the system, the former is the estimate before the measurement is incorporated, and the latter is after the measurement has been incorporated.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h2>
<p>The Kalman filter that we describe in this chapter is a special, restricted case of the more general filter we will learn next. Most texts do not discuss this one dimensional form. However, I think it is a vital stepping stone. We started the book with the g-h filter, then implemented the discrete Bayes filter, and now implemented the one dimensional Kalman filter. I have tried to show you that each of these filters use the same algorithm and reasoning. The mathematics of the Kalman filter that we will learn shortly is fairly sophisticated, and it can be difficult to understand the underlying simplicity of the filter. That sophistication comes with significant benefits: the generalized filter will markedly outperform the filters in this chapter.</p>
<p>This chapter takes time to assimilate. To truly understand it you will probably have to work through this chapter several times. I encourage you to change the various constants in the code and observe the results. Convince yourself that Gaussians are a good representation of a unimodal belief of  the position of a dog in a hallway, the position of an aircraft in the sky, or the temperature of a chemical reaction chamber. Then convince yourself that multiplying Gaussians truly does compute a new belief from your prior belief and the new measurement. Finally, convince yourself that if you are measuring movement, that adding the Gaussians together updates your belief.</p>
<p>Most of all, spend enough time with the <strong>Full Description of the Algorithm</strong> section to ensure you understand the algorithm and how it relates to the g-h filter and discrete Bayes filter. There is just one trick here - selecting a value somewhere between a prediction and a measurement. Each algorithm performs that trick with different math, but all use the same logic.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/artificial-intelligence",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/pgm/kalman-filters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../hmm-localization/_index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Localization and Tracking</p>
      </div>
    </a>
    <a class="right-next"
       href="../../logical-reasoning/automated-reasoning/_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Automated Reasoning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-description">Problem Description</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beliefs-as-gaussians">Beliefs as Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-with-gaussian-probabilities">Tracking with Gaussian Probabilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predictions-with-gaussians">Predictions with Gaussians</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#updates-with-gaussians">Updates with Gaussians</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-gaussian-multiplication">Understanding Gaussian Multiplication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-example">Interactive Example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-kalman-filter">First Kalman Filter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#code-walkthrough">Code Walkthrough</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-modify-variance-values">Exercise: Modify Variance Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kf-animation">KF Animation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kalman-gain">Kalman Gain</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#full-description-of-the-algorithm">Full Description of the Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-with-g-h-and-discrete-bayes-filters">Comparison with g-h and discrete Bayes Filters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-designing-a-filter">Introduction to Designing a Filter</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#animation">Animation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-extreme-amounts-of-noise">Example: Extreme Amounts of Noise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-incorrect-process-variance">Example: Incorrect Process Variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-bad-initial-estimate">Example: Bad Initial Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-large-noise-and-bad-initial-estimate">Example: Large Noise and Bad Initial Estimate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-interactive-plots">Exercise: Interactive Plots</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise-nonlinear-systems">Exercise - Nonlinear Systems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Solution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discussion">Discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fixed-gain-filters">Fixed Gain Filters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#filterpys-implementation">FilterPys Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>