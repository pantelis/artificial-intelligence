
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/information-theory-dnn/index';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/information-theory-dnn/index.html" />
    <link rel="icon" href="../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Introduction to Convolutional Neural Networks" href="../cnn/cnn-intro/_index.html" />
    <link rel="prev" title="Regularization Workshop" href="../optimization/regularization/regularization-workshop-1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Introduction to Artificial Intelligence - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Introduction to Artificial Intelligence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="list-caption"><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="label-parts" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../syllabus/_index.html">Syllabus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to AI</span></p><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="label-parts" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ai-intro/systems-approach/_index.html">The four approaches towards AI</a></li>

<li class="toctree-l1"><a class="reference internal" href="../ai-intro/agents/_index.html">Agent-Environment Interface</a></li>



</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-1</span></p><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="label-parts" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../entropy/index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../optimization/maximum-likelihood/mle-gaussian-parameters.html">Maximum Likelihood Estimation of Gaussian Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-2</span></p><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="label-parts" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="label-parts" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dnn/dnn-intro/index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimization/regularization/regularization-workshop-1.html">Regularization Workshop</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="label-parts" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">Visualizing what convnets learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="label-parts" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../scene-understanding/semantic-segmentation/index.html">Object Det. &amp; Semantic Segm. Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">Mask R-CNN Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">Mask R-CNN Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">Mask R-CNN - Inspect Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">Mask R-CNN - Inspect Trained Model</a></li>










<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">Mask R-CNN - Inspect Weights of a Trained Model</a></li>





<li class="toctree-l2"><a class="reference internal" href="../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">Detectron2 Beginner’s Tutorial</a></li>





</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="label-parts" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Probabilistic Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="label-parts" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../rse/recursive-state-estimation/index.html">Recursive State Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rse/discrete-bayesian-filter/discrete-bayesian-filter.html">Discrete Bayes Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rse/hmm-localization/_index.html">Localization and Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rse/kalman-filters/one-dimensional-kalman-filters.html">Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Logical Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="label-parts" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../logical-reasoning/automated-reasoning/_index.html">Automated Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logical-reasoning/propositional-logic/_index.html">World Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logical-reasoning/logical-inference/index.html">Logical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../logical-reasoning/logical-agents/_index.html">Logical Agents</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Planning without Interactions</span></p><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="label-parts" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../planning/index.html">Automated Planning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../planning/pddl/index.html">PDDL</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../planning/pddl/blocksworld/up_blocksworld_demo.html">The Unified Planning Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../planning/pddl/logistics/index.html">Logistics Planning in PDDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../planning/pddl/manufacturing/index.html">Manufacrturing Robot Planning in PDDL</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../planning/search/index.html">Search Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../planning/search/forward-search/index.html">Forward Search Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../planning/search/a-star/index.html">The A* Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../planning/search/search-alg-demo/index.html">Interactive Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../motion-planning-cars/index.html">Motion Planning for Autonomous Cars</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Markov Decision Processes</span></p><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="label-parts" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../mdp/index.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mdp/mdp-intro/mdp_intro.html">Introduction to MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mdp/bellman-expectation-backup/_index.html">Bellman Expectation Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mdp/policy-evaluation/_index.html">Policy Evaluation (Prediction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mdp/bellman-optimality-backup/_index.html">Bellman Optimality Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mdp/policy-improvement/_index.html">Policy Improvement (Control)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mdp/dynamic-programming-algorithms/index.html">Dynamic Programming Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mdp/dynamic-programming-algorithms/policy-iteration/_index.html">Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mdp/dynamic-programming-algorithms/value-iteration/index.html">Value Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mdp/mdp-workshop/index.html">MDP Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mdp/mdp-workshop/cleaning-robot/deterministic_mdp.html">Cleaning Robot - Deterministic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mdp/mdp-workshop/cleaning-robot/stochastic_mdp.html">Cleaning Robot - Stochastic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mdp/mdp-workshop/recycling-robot/_index.html">The recycling robot.</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="label-parts" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../reinforcement-learning/_index.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reinforcement-learning/prediction/monte-carlo.html">Monte-Carlo Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reinforcement-learning/prediction/temporal-difference.html">Temporal Difference (TD) Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../reinforcement-learning/model-free-control/index.html">Model-free Control</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/model-free-control/generalized-policy-iteration/index.html">Generalized Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/model-free-control/greedy-monte-carlo/index.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy Monte-Carlo (MC) Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/model-free-control/sarsa/index.html">The SARSA Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reinforcement-learning/model-free-control/sarsa/gridworld/sarsa_gridworld.html">SARSA Gridworld Example</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="label-parts" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="label-parts" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nlp/nlp-introduction/nlp-pipelines/_index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp/nlp-introduction/tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp/nlp-introduction/word2vec/_index.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/nlp-introduction/word2vec/word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp/language-models/_index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/language-models/cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/language-models/simple-rnn-language-model/index.html">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/language-models/lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp/nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/nmt/rnn-attention-workshop/seq2seq_and_attention.html">Attention in RNN NMT Workshop</a></li>




</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp/transformers/transformers-intro.html">Transformers and Self-attention</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp/transformers/singlehead-self-attention.html">Single-head self-attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/transformers/multihead-self-attention.html">Multi-head attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp/transformers/positional_embeddings.html">Positional Embeddings</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="label-parts" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml-math/calculus/index.html">Calculus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="label-parts" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/environment/slurm-keras-example.html">Training Keras with the SLURM Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/environment/nyu-jupyterhub-envs.html">NYU JupyrterHub Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613 / CS370 Common Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="label-parts" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../assignments/probability/probability-assignment-8/index.html">Probability &amp; Linear Algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../assignments/optimization/sgd.html">Stochastic Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../assignments/object-detection/video-search.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../assignments/object-tracking-kalman/drone-follow-me.html">Drone follow me using Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613-INET-Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="label-parts" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../assignments/probability/probability-assignment-3/index.html">Probability Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../assignments/optimization/sgd-linear-regression/index.html">Optimization algorithms for linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../assignments/object-detection/video-search2.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../assignments/object-tracking-kalman/drone-follow-me2.html">Drone follow me using Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Undergraduate Project</span></p><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="label-parts" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../projects/cv/sam-finetuning-remote-sensing/index.html">Segment Anything Model Finetuning for Remote Sensing Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../projects/robotics/learning-in-simulated-worlds/index.html">Learning in Simulated Worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../projects/cv/wasm-pipelines/index.html">Webassembly (WASM) media pipelines</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Graduate Projects</span></p><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="label-parts" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../projects/cv/sam-advanced-remote-sensing/index.html">Visual Prompting and Oclusion Handling for Remote Sensing Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../projects/robotics/nl-guided-robotics/index.html">Natual Language Guided Robotics</a></li>
</ul></li></ul>
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/information-theory-dnn/index.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/aiml-common/lectures/information-theory-dnn/index.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy-or-kl-divergence">Relative entropy or KL Divergence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-mutual-information-mi">Average Mutual Information (MI)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dnn-as-a-markov-chain">DNN as a Markov Chain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-inequality">Data Processing Inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparameterization-invariance">Reparameterization Invariance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-plane-theorem">The Information Plane Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-mutual-information">Estimation of Mutual Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digging-further">Digging further</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="fusion-of-statistical-learning-theory-information-theory-and-stochastic-optimization">
<h1>Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization<a class="headerlink" href="#fusion-of-statistical-learning-theory-information-theory-and-stochastic-optimization" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>The Vapnik diagram we have seen earlier, a manifestation of the classical statistical learning theory, focused the attention to the hypothesis set aka what kind of functions can be learned. The viewpoint of a hypothesis-driven complexity was used, for pedagogical purposes in the chapters of linear regression and generalized linear classification and under the umbrella of the small number of parameters, statistical learning theorist developed generalization bounds driven by the concept of <a class="reference external" href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension">VC dimension</a>.</p>
<p>Here we claim that such bounds are overly pessimistic and are of very little value today due to the large number of parameters in modern DNNs that seemingly always over parameterize the problems but despite the large number of parameters they possess they are able to generalize well.</p>
<p>More specifically, after a review of basic information theoretic quantities associated with entropy (self-information) and average mutual information, we will recognize that the later offers a more promising approach to understanding the generalization properties of DNNs, effectively replacing the VC dimension, that focuses on what kind of functions can be learned by a model, with a measure of how much information can be learned from the examples and offering a generalization bound based on the input compression.</p>
<p>In addition,we will see that the noisy gradient plays an important role in the optimization of the DNNs and SGD converges to a maximal entropy weight distribution. Its dynamics seem to possess two phases: a first phase when mutual information about the output label is increasing and a second phase when information about the input data is decreasing aka data representation is compressed. Its convergence time to an optimal solution is also heavily influenced by the number of layers of the network.</p>
<section id="relative-entropy-or-kl-divergence">
<h3>Relative entropy or KL Divergence<a class="headerlink" href="#relative-entropy-or-kl-divergence" title="Link to this heading">#</a></h3>
<p>In many settings we need to have a metric that compares two probability distributions <span class="math notranslate nohighlight">\(\{P,Q\}\)</span> in terms of their “distance” from each other (the quotes will be explained shortly). This is given by the quantity known as <em>relative entropy</em> or <em>KL divergence</em>. For discrete distributions, the relative entropy is defined as,</p>
<div class="math notranslate nohighlight">
\[ D_{\text{KL}}(P||Q)= \mathbb{E}_P\left[\log\left(\frac{P(x)}{Q(x)}\right)\right] = \sum_{x} P(x) \log\left(\frac{P(x)}{Q(x)}\right)
\]</div>
<p>For continuous distributions, the sum is replaced by an integral,</p>
<div class="math notranslate nohighlight">
\[D_{\text{KL}}(P \parallel Q) = \int_{-\infty}^{\infty} p(x) \log\frac{p(x)}{q(x)} dx
\]</div>
<p>If the two distributions are identical, <span class="math notranslate nohighlight">\(KL=0\)</span> - in general however <span class="math notranslate nohighlight">\(KL(P||Q) \ge 0\)</span>. One key element to understand is that <span class="math notranslate nohighlight">\(KL\)</span> is not a true distance metric as its asymmetric.</p>
<p><img alt="KL-asymmetry" src="../../../_images/KL-asymmetry.png" /></p>
<p>The following <a class="reference external" href="https://www.youtube.com/watch?v=SxGYPqCgJWM">video</a> is instructive for understanding the KL divergence using coin tossing distributions as an example.</p>
<div class="video_wrapper align-center" style="text-align: center">
<iframe allowfullscreen="true" src="https://www.youtube.com/embed/SxGYPqCgJWM" style="border: 0; height: 345px; width: 560px">
</iframe></div></section>
<section id="conditional-entropy">
<h3>Conditional Entropy<a class="headerlink" href="#conditional-entropy" title="Link to this heading">#</a></h3>
<p>The conditional entropy <span class="math notranslate nohighlight">\(H(Y|X)\)</span> is a measure of the uncertainty of a random variable <span class="math notranslate nohighlight">\(Y\)</span> given that the value of another random variable <span class="math notranslate nohighlight">\(X\)</span> is known. It is defined as:</p>
<div class="math notranslate nohighlight">
\[
H(Y|X) = - \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} P(x, y) \log\left(P(y|x)\right)
\]</div>
<p>Below is a handy rule for entropy,</p>
<div class="math notranslate nohighlight">
\[H(X,Y) = H(X) + H(Y|X)\]</div>
<p>We can see in the diagram shown below a key relationship between joint entropy, conditional entropies and average mutual information that we will discuss further next.</p>
<p><img alt="entropy-relations" src="../../../_images/entropy-relations.png" /></p>
<p>Clearly, $<span class="math notranslate nohighlight">\(H(Y|X) = H(X,Y) - H(X)\)</span>$</p>
</section>
<section id="average-mutual-information-mi">
<h3>Average Mutual Information (MI)<a class="headerlink" href="#average-mutual-information-mi" title="Link to this heading">#</a></h3>
<p>Very close to the relative entropy is a measure called mutual information. These expressions quantify the amount of information obtained about one variable through the other, reflecting their mutual dependence.</p>
<p>For discrete random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, the mutual information <span class="math notranslate nohighlight">\(I(X; Y)\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
I(X; Y) = \sum_{x \in \mathcal{X}} \sum_{y \in \mathcal{Y}} P(x, y) \log\left(\frac{P(x, y)}{P(x)P(y)}\right)
\]</div>
<p>For continuous random variables, the mutual information <span class="math notranslate nohighlight">\(I(X; Y)\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
I(X; Y) = \int_{\mathcal{X}} \int_{\mathcal{Y}} p(x, y) \log\left(\frac{p(x, y)}{p(x)p(y)}\right) dx dy
\]</div>
<p>In both formulas:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x, y)\)</span> or <span class="math notranslate nohighlight">\(p(x, y)\)</span> represents the joint probability distribution of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, for discrete or continuous variables respectively.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x)\)</span> and <span class="math notranslate nohighlight">\(P(y)\)</span> are the marginal probability distributions of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p></li>
<li><p>The logarithm can be base 2 for bits or natural for nats, depending on the context.</p></li>
</ul>
<p>A handy rule is the chain rule for mutual information,</p>
<div class="math notranslate nohighlight">
\[I(X;H,Y) = I(X;H) + I(X;Y|H)\]</div>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h4>
<p>Let’s consider an example with two urns, A and B, to calculate the mutual information between the random variable <span class="math notranslate nohighlight">\(x\)</span> that selects an urn and the random variable <span class="math notranslate nohighlight">\(y\)</span> that represents drawing a black or white widget from the selected urn. Assume the following probabilities:</p>
<ul class="simple">
<li><p>Probability of selecting urn A, <span class="math notranslate nohighlight">\(P(x=A) = 0.5\)</span>,</p></li>
<li><p>Probability of selecting urn B, <span class="math notranslate nohighlight">\(P(x=B) = 0.5\)</span>,</p></li>
<li><p>Probability of drawing a black widget from urn A, <span class="math notranslate nohighlight">\(P(y=0 | x=A) = 0.8\)</span>,</p></li>
<li><p>Probability of drawing a white widget from urn A, <span class="math notranslate nohighlight">\(P(y=1 | x=A) = 0.2\)</span>,</p></li>
<li><p>Probability of drawing a black widget from urn B, <span class="math notranslate nohighlight">\(P(y=0 | x=B) = 0.1\)</span>,</p></li>
<li><p>Probability of drawing a white widget from urn B, <span class="math notranslate nohighlight">\(P(y=1 | x=B) = 0.9\)</span>.</p></li>
</ul>
<p>The joint probabilities <span class="math notranslate nohighlight">\(P(x, y)\)</span> and the marginal probabilities <span class="math notranslate nohighlight">\(P(y)\)</span> can be calculated as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x=A, y=0) = P(x=A) \cdot P(y=0 | x=A) = 0.5 \cdot 0.8 = 0.4\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=A, y=1) = P(x=A) \cdot P(y=1 | x=A) = 0.5 \cdot 0.2 = 0.1\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=B, y=0) = P(x=B) \cdot P(y=0 | x=B) = 0.5 \cdot 0.1 = 0.05\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=B, y=1) = P(x=B) \cdot P(y=1 | x=B) = 0.5 \cdot 0.9 = 0.45\)</span>.</p></li>
</ul>
<p>The marginal probability <span class="math notranslate nohighlight">\(P(y)\)</span> is obtained by summing over the possible values of <span class="math notranslate nohighlight">\(x\)</span>:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(y=0) = P(x=A, y=0) + P(x=B, y=0) = 0.4 + 0.05 = 0.45\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(P(y=1) = P(x=A, y=1) + P(x=B, y=1) = 0.1 + 0.45 = 0.55\)</span>.</p></li>
</ul>
<p>Now, the mutual information <span class="math notranslate nohighlight">\(I(x; y)\)</span> can be calculated using the formula:</p>
<div class="math notranslate nohighlight">
\[I(x; y) = \sum_{x \in \{A, B\}} \sum_{y \in \{0, 1\}} P(x, y) \log_2\left(\frac{P(x, y)}{P(x)P(y)}\right)\]</div>
<p>Substituting the values:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
I(x; y) = &amp; P(x=A, y=0) \log_2\left(\frac{P(x=A, y=0)}{P(x=A)P(y=0)}\right) \\
&amp; + P(x=A, y=1) \log_2\left(\frac{P(x=A, y=1)}{P(x=A)P(y=1)}\right) \\
&amp; + P(x=B, y=0) \log_2\left(\frac{P(x=B, y=0)}{P(x=B)P(y=0)}\right) \\
&amp; + P(x=B, y=1) \log_2\left(\frac{P(x=B, y=1)}{P(x=B)P(y=1)}\right)
\end{align*}
\end{split}\]</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Joint probabilities</span>
<span class="n">p_A0</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">p_A1</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">p_B0</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">p_B1</span> <span class="o">=</span> <span class="mf">0.45</span>

<span class="c1"># Marginal probabilities</span>
<span class="n">P_xA</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">P_xB</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">p_0</span> <span class="o">=</span> <span class="n">p_A0</span> <span class="o">+</span> <span class="n">p_B0</span>
<span class="n">p_1</span> <span class="o">=</span> <span class="n">p_A1</span> <span class="o">+</span> <span class="n">p_B1</span>

<span class="c1"># Compute mutual information I(x; y)</span>
<span class="n">I_xy</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">p_A0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_A0</span> <span class="o">/</span> <span class="p">(</span><span class="n">P_xA</span> <span class="o">*</span> <span class="n">p_0</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">p_A1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_A1</span> <span class="o">/</span> <span class="p">(</span><span class="n">P_xA</span> <span class="o">*</span> <span class="n">p_1</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">p_B0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_B0</span> <span class="o">/</span> <span class="p">(</span><span class="n">P_xB</span> <span class="o">*</span> <span class="n">p_0</span><span class="p">))</span> <span class="o">+</span>
    <span class="n">p_B1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_B1</span> <span class="o">/</span> <span class="p">(</span><span class="n">P_xB</span> <span class="o">*</span> <span class="n">p_1</span><span class="p">))</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">I_xy</span><span class="p">)</span>
</pre></div>
</div>
<p>The mutual information <span class="math notranslate nohighlight">\(I(x; y)\)</span> between the random variable <span class="math notranslate nohighlight">\(x\)</span> that selects the urn and the random variable <span class="math notranslate nohighlight">\(y\)</span> that samples the black or white widget out of the urn is approximately 0.397 bits. This value quantifies the amount of information gained about the outcome of the widget color through the choice of the urn, demonstrating the mutual dependence between these two variables.</p>
</section>
</section>
</section>
<section id="dnn-as-a-markov-chain">
<h2>DNN as a Markov Chain<a class="headerlink" href="#dnn-as-a-markov-chain" title="Link to this heading">#</a></h2>
<p>Let us consider a dense neural network (DNN) that consists of matrices <span class="math notranslate nohighlight">\(W_1-W_L\)</span> and biases <span class="math notranslate nohighlight">\(b_1-b_L\)</span>.  The DNN in our context here can be seen as a Markov chain, with input <span class="math notranslate nohighlight">\(X\)</span>, output <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(H_l = f_l(H_{l-1}W_l + b_l)\)</span> as the outputs of the <span class="math notranslate nohighlight">\(l\)</span>-th layer of the network.</p>
<p>We treat each layer output a single multidimensional random variable that encodes the input <span class="math notranslate nohighlight">\(X\)</span> via an encoder <span class="math notranslate nohighlight">\(p_model(H_l|X)\)</span> and predicts the output via a decoder <span class="math notranslate nohighlight">\(p_model(Y|H_l)\)</span>.</p>
<p><img alt="" src="../../../_images/encoder-decoder.png" /></p>
<p>This means that the input is encoded differently by each layer and the output is formed by different decoders. The deeper the layer the encoder becomes more complicated but its decoder less so. In the limit of the last layer the decoder is trivially what we called the head (a sigmoidal neuron for binary classification) but its encoder is much more complicated as compared to that of the first layer.</p>
<section id="data-processing-inequality">
<h3>Data Processing Inequality<a class="headerlink" href="#data-processing-inequality" title="Link to this heading">#</a></h3>
<p>Quantitatively, we use one of the key inequalities in information theory, the data processing inequality, that states that if we have a Markov chain <span class="math notranslate nohighlight">\(X \rightarrow H \rightarrow Y\)</span>, then</p>
<div class="math notranslate nohighlight">
\[I(X;H) \ge I(X;Y)\]</div>
<p>Given that a neural network is a Markov chain, the data processing inequality simply says that the mutual information of the input and each of the hidden layers is decreasing as we move through the layers of the network.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The analogy with the information gain of decision trees</p>
<p>The data processing inequality is analogous to the information gain of decision trees. In decision trees, the information gain is the difference between the entropy of the parent node and the weighted sum of the entropies of the child nodes. The information gain is used to decide which feature to split on. The data processing inequality is similar in that it measures the reduction in uncertainty of the output given the input.</p>
<p><img alt="" src="../../../_images/information-gain.png" /></p>
</div>
</section>
<section id="reparameterization-invariance">
<h3>Reparameterization Invariance<a class="headerlink" href="#reparameterization-invariance" title="Link to this heading">#</a></h3>
<p>The other key relationship we will use is that the mutual information is invariant to reparameterization when the transformation is invertible.</p>
<div class="math notranslate nohighlight">
\[I(X;Y) = I(\phi(X);\psi(Y))\]</div>
</section>
</section>
<section id="the-information-plane-theorem">
<h2>The Information Plane Theorem<a class="headerlink" href="#the-information-plane-theorem" title="Link to this heading">#</a></h2>
<p>Given the setting of the problem we outlined, the mutual information between the layers of the network is governed by the following inequalities that are derived from the data processing inequality,</p>
<div class="math notranslate nohighlight">
\[I(X;Y) \ge I(H_1;Y) \ge I(H_2;Y) \ge ... \ge I(H_L;Y) \ge I(\hat Y;Y)\]</div>
<div class="math notranslate nohighlight">
\[H(X) \ge I(X;H_1) \ge I(X;H_2) \ge ... \ge I(X;H_L) \ge I(X; \hat Y)\]</div>
<p>Using these inequalities we can arrive at the following theorem that establishes the trade off between sample complexity and accuracy. It states that the sample complexity is entirely determined by the mutual information between the input and the hidden layers of the network <span class="math notranslate nohighlight">\(I(X;H) = H(X) - H(X|H)\)</span> and the generalization error (accuracy) is determined by the mutual information between the <strong>last</strong> hidden layer and the output <span class="math notranslate nohighlight">\(I(H;Y) = H(Y) - H(Y|H)\)</span>.</p>
<p>The two functions <span class="math notranslate nohighlight">\(I(X;H)\)</span> and <span class="math notranslate nohighlight">\(I(H;Y)\)</span> are called the information plane and the theorem states that the network learns by moving through the information plane as shown in the following animation.</p>
<div class="video_wrapper align-center" style="text-align: center">
<iframe allowfullscreen="true" src="https://www.youtube.com/embed/P1A1yNsxMjc" style="border: 0; height: 345px; width: 560px">
</iframe></div><p>The points shown in the animation are the information plane coordinates of multiple networks at different stages of the training. Each network has been initialized with initial weights (Gaussian). Different colors represent the different layers of those networks. The network starts with a high sample complexity and low accuracy and moves to a low sample complexity and high accuracy. There is a typo - the vertical axis of the 2nd plot should read “generalization error” instead of “precision”.</p>
<p>From the animation it is evident the behavior of each hidden layer: as the epochs progress it will move rapidly up to gain information about the output and then move to the left forgetting information about the input. The later compression factor is dependent on the layer where layers closer to the input forget less of the input and deeper layers forget more.</p>
<p><img alt="" src="../../../_images/information-plane.png" /></p>
</section>
<section id="estimation-of-mutual-information">
<h2>Estimation of Mutual Information<a class="headerlink" href="#estimation-of-mutual-information" title="Link to this heading">#</a></h2>
<p>An important complication that prevents an even wider adoption of information-based analyses is that mutual information and related quantities are notoriously difficult to estimate from empirical data. Mutual information involves averages of logarithms of <span class="math notranslate nohighlight">\(p\)</span>, the underlying probability distribution.Since, for small <span class="math notranslate nohighlight">\(p\)</span>, <span class="math notranslate nohighlight">\(– log_2 p → ∞\)</span>, the ranges of x, y where <span class="math notranslate nohighlight">\(p\)</span> is small and hence cannot be sampled and estimated reliably from data contribute disproportionately to the value of information. In other words, unlike correlation functions, information depends nonlinearly on <span class="math notranslate nohighlight">\(p\)</span>, so that these sampling errors result in a strong sample size dependent and <span class="math notranslate nohighlight">\(p\)</span> -dependent bias in information estimates. In fact, even for discrete data, there can be no universally unbiased estimators of information until the number of samples, <span class="math notranslate nohighlight">\(m\)</span>, is much larger than the cardinality of the underlying distribution, <span class="math notranslate nohighlight">\(n\)</span>. This means that, for continuous variables, universally unbiased information estimators do not exist at all. These simple observations have resulted in a lively field of developing entropy / information <a class="reference external" href="https://www.biorxiv.org/content/10.1101/589929v2-0.full">estimators</a> for discrete variables, which work under a variety of different assumptions .</p>
<p>One of the MI estimators is based on the discretization of the continuous vector random variables and then doing the joint and marginal probabilities in this discrete space approximating the actual densities. For an example of a method see <a class="reference external" href="https://github.com/pantelis/IDNNs/blob/main/idnns/information/mutual_info_estimation.py">this estimator</a> that borrows heavily from the [non-parametric entropy estimation toolb]</p>
</section>
<section id="digging-further">
<h2>Digging further<a class="headerlink" href="#digging-further" title="Link to this heading">#</a></h2>
<p>If you are a visual learner, <a class="reference external" href="http://colah.github.io/posts/2015-09-Visual-Information/#fn4">the visual information theory</a> blog post is a good starting point to the baiscs of information theory.  <a class="reference external" href="https://www.inference.org.uk/itprnn/book.pdf">MacKay’s book (Chapter 2)</a> goes much deeper on information theory concepts and you can test your understanding by doing the exercises in that chapter.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/artificial-intelligence",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/information-theory-dnn"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../optimization/regularization/regularization-workshop-1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Regularization Workshop</p>
      </div>
    </a>
    <a class="right-next"
       href="../cnn/cnn-intro/_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Convolutional Neural Networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy-or-kl-divergence">Relative entropy or KL Divergence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#average-mutual-information-mi">Average Mutual Information (MI)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dnn-as-a-markov-chain">DNN as a Markov Chain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-processing-inequality">Data Processing Inequality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reparameterization-invariance">Reparameterization Invariance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-plane-theorem">The Information Plane Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-mutual-information">Estimation of Mutual Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digging-further">Digging further</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>