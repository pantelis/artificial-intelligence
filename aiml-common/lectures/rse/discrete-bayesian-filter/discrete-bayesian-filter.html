

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Discrete Bayes Filter &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/vnd.jupyter.widget-state+json">{"state": {"1ea315f115ff43d8aedcd574bbeed410": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "step", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_51963e73dba4487f95d2e6c2b9a9c71a", "max": 100, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_bf7a2628623c422bbdc7983f76a57c75", "value": 1}}, "24a3f8a7d3c44508a9d0ae15bb97df92": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "24f0f28eff1947719418be9532a5054c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "376e66cbf1e74103a1a93d5ec7611004": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_24f0f28eff1947719418be9532a5054c", "msg_id": "", "outputs": []}}, "4825caa46e18450f9afcba67c27cbeba": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "time_step", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_6409d65c66d5483ab1dff92c7199efb0", "max": 19, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_c448c06a3e904b0d811dd099733429bc", "value": 0}}, "48c69b49621547b9972c8eb7cddfa10e": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_4fbf3d96470d4f168fdd3af62ae85189", "msg_id": "", "outputs": []}}, "4fbf3d96470d4f168fdd3af62ae85189": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "51963e73dba4487f95d2e6c2b9a9c71a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "557aede106aa460da09898120cf2c111": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6127afe680be4cc5bd3e14626d4493f0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_7f99b7560aa04802a5b1b03b5e4ad81e", "IPY_MODEL_48c69b49621547b9972c8eb7cddfa10e"], "layout": "IPY_MODEL_557aede106aa460da09898120cf2c111"}}, "6409d65c66d5483ab1dff92c7199efb0": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7e810cc52ae044aba08c2672377d716c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7f99b7560aa04802a5b1b03b5e4ad81e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "step", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_7e810cc52ae044aba08c2672377d716c", "max": 12, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_d4f45abe59a24e19a6168202f72b914e", "value": 12}}, "9260e86291ea4ceabb18583e1b480bd9": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "964107123dbf442593d2a43411c04268": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b51e90e175e14117b4c0727749c1047d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "bf7a2628623c422bbdc7983f76a57c75": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "c383bd000ae248f0adeec4825dc0923b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "c448c06a3e904b0d811dd099733429bc": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "d13d51f518a64cbfb548a3ac5fe0412d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_e99d98efa98146f7ae449672d8f4da71", "IPY_MODEL_e67fb12631604743a7b242a173e2250c"], "layout": "IPY_MODEL_24a3f8a7d3c44508a9d0ae15bb97df92"}}, "d4f45abe59a24e19a6168202f72b914e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "SliderStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "e67fb12631604743a7b242a173e2250c": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_9260e86291ea4ceabb18583e1b480bd9", "msg_id": "", "outputs": []}}, "e99d98efa98146f7ae449672d8f4da71": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "IntSliderModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "IntSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "IntSliderView", "continuous_update": true, "description": "step", "description_tooltip": null, "disabled": false, "layout": "IPY_MODEL_fb2dce3f803243b3a6a4619bc0099cc2", "max": 100, "min": 0, "orientation": "horizontal", "readout": true, "readout_format": "d", "step": 1, "style": "IPY_MODEL_c383bd000ae248f0adeec4825dc0923b", "value": 1}}, "ecba7b7412dc454d9c606867bb343235": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_4825caa46e18450f9afcba67c27cbeba", "IPY_MODEL_ecf2533746d74ee18336f04b86e21736"], "layout": "IPY_MODEL_fa98c8f5d70f48af9968b14005fa2274"}}, "ecf2533746d74ee18336f04b86e21736": {"model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "model_name": "OutputModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_964107123dbf442593d2a43411c04268", "msg_id": "", "outputs": []}}, "fa98c8f5d70f48af9968b14005fa2274": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fb2dce3f803243b3a6a4619bc0099cc2": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "fd3a9bcbc55f432dad319c4248e1f8ef": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "VBoxModel", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_1ea315f115ff43d8aedcd574bbeed410", "IPY_MODEL_376e66cbf1e74103a1a93d5ec7611004"], "layout": "IPY_MODEL_b51e90e175e14117b4c0727749c1047d"}}}, "version_major": 2, "version_minor": 0}</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter.html" />
    <link rel="shortcut icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Localization and Tracking" href="../hmm-localization/_index.html" />
    <link rel="prev" title="Recursive State Estimation" href="../recursive-state-estimation/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Introduction to Artificial Intelligence - Home"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Introduction to Artificial Intelligence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="list-caption"><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="label-parts" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../syllabus/_index.html">Syllabus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to AI</span></p><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="label-parts" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/systems-approach/_index.html">The four approaches towards AI</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/agents/_index.html">A systems approach to AI</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-1</span></p><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="label-parts" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/mle-gaussian-parameters.html">Maximum Likelihood Estimation of Gaussian Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-2</span></p><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="label-parts" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="label-parts" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/dnn-intro/index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/regularization-workshop-1.html">Regularization Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../information-theory-dnn/index.html">Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="label-parts" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">Visualizing what convnets learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="label-parts" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/index.html">Object Det. &amp; Semantic Segm. Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">Mask R-CNN Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">Mask R-CNN Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">Mask R-CNN - Inspect Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">Mask R-CNN - Inspect Trained Model</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">Mask R-CNN - Inspect Weights of a Trained Model</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">Detectron2 Beginnerâ€™s Tutorial</a></li>





</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="label-parts" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Probabilistic Reasoning</span></p><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="label-parts" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../recursive-state-estimation/index.html">Recursive State Estimation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Discrete Bayes Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hmm-localization/_index.html">Localization and Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kalman-filters/one-dimensional-kalman-filters.html">Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Logical Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="label-parts" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/automated-reasoning/_index.html">Automated Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/propositional-logic/_index.html">World Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/logical-inference/index.html">Logical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/logical-agents/_index.html">Logical Agents</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Planning without Interactions</span></p><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="label-parts" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../planning/index.html">Automated Planning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../planning/pddl/index.html">PDDL</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/blocksworld/up_blocksworld_demo.html">The Unified Planning Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/logistics/index.html">Logistics Planning in PDDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/manufacturing/index.html">Manufacrturing Robot Planning in PDDL</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../planning/search/index.html">Search Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../planning/search/forward-search/index.html">Forward Search Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/search/a-star/index.html">The A* Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/search/search-alg-demo/index.html">Interactive Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../motion-planning-cars/index.html">Motion Planning for Autonomous Cars</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Markov Decision Processes</span></p><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="label-parts" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mdp/index.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/mdp-intro/mdp_intro.html">Introduction to MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-expectation-backup/_index.html">Bellman Expectation Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/policy-evaluation/_index.html">Policy Evaluation (Prediction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-optimality-backup/_index.html">Bellman Optimality Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/policy-improvement/_index.html">Policy Improvement (Control)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/index.html">Dynamic Programming Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/policy-iteration/_index.html">Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/value-iteration/index.html">Value Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mdp/mdp-workshop/index.html">MDP Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/cleaning-robot/deterministic_mdp.html">Cleaning Robot - Deterministic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/cleaning-robot/stochastic_mdp.html">Cleaning Robot - Stochastic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/recycling-robot/_index.html">The recycling robot.</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="label-parts" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/_index.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/monte-carlo.html">Monte-Carlo Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/temporal-difference.html">Temporal Difference (TD) Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reinforcement-learning/model-free-control/index.html">Model-free Control</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/generalized-policy-iteration/index.html">Generalized Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/greedy-monte-carlo/index.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy Monte-Carlo (MC) Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/sarsa/index.html">The SARSA Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/sarsa/gridworld/sarsa_gridworld.html">SARSA Gridworld Example</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="label-parts" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="label-parts" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../nlp/nlp-introduction/nlp-pipelines/_index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nlp/nlp-introduction/tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/_index.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/language-models/_index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/simple-rnn-language-model/index.html">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/language-models/lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/nmt/rnn-attention-workshop/seq2seq_and_attention.html">Attention in RNN NMT Workshop</a></li>




</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nlp/transformers/transformers-intro.html">Transformers and Self-attention</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/transformers/singlehead-self-attention.html">Single-head self-attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/transformers/multihead-self-attention.html">Multi-head attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nlp/transformers/positional_embeddings.html">Positional Embeddings</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="label-parts" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/calculus/index.html">Calculus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="label-parts" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613 / CS370 Common Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="label-parts" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/probability/probability-assignment-8/index.html">Probability &amp; Linear Algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/optimization/sgd.html">Stochastic Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-detection/video-search.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-tracking-kalman/drone-follow-me.html">Cyclist Detection and Tracking</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613-INET-Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="label-parts" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/probability/probability-assignment-3/index.html">Probability Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../assignments/optimization/sgd-linear-regression/index.html">Optimization algorithms for linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-detection/video-search2.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../assignments/object-tracking-kalman/drone-follow-me2.html">Drone follow me using Kalman Filters</a></li>
</ul></li></ul>
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pantelis/artificial-intelligence/master?urlpath=tree/artificial_intelligence/aiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pantelis/artificial-intelligence/blob/master/artificial_intelligence/aiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/aiml-common/lectures/rse/discrete-bayesian-filter/discrete-bayesian-filter.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Discrete Bayes Filter</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-a-dog">Tracking a Dog</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-information-from-sensor-readings">Extracting Information from Sensor Readings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#noisy-sensors">Noisy Sensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-movement">Incorporating Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology">Terminology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-uncertainty-to-the-prediction">Adding Uncertainty to the Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalizing-with-convolution">Generalizing with Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrating-measurements-and-movement-updates">Integrating Measurements and Movement Updates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-discrete-bayes-algorithm">The Discrete Bayes Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-effect-of-bad-sensor-data">The Effect of Bad Sensor Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drawbacks-and-limitations">Drawbacks and Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-and-control">Tracking and Control</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-the-train-behavior">Simulating the Train Behavior</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem-and-the-total-probability-theorem">Bayes Theorem and the Total Probability Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><span class="xref myst">Table of Contents</span></p>
<section class="tex2jax_ignore mathjax_ignore" id="discrete-bayes-filter">
<h1>Discrete Bayes Filter<a class="headerlink" href="#discrete-bayes-filter" title="Permalink to this heading">#</a></h1>
<p>This notebook was copied from the excellent book <a class="github reference external" href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python">rlabbe/Kalman-and-Bayesian-Filters-in-Python</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#format the book</span>
<span class="kn">import</span> <span class="nn">book_format</span>
<span class="n">book_format</span><span class="o">.</span><span class="n">set_style</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
        <style>
        .output_wrapper, .output {
            height:auto !important;
            max-height:100000px;
        }
        .output_scroll {
            box-shadow:none !important;
            webkit-box-shadow:none !important;
        }
        </style>
    </div></div>
</div>
<p>The Kalman filter belongs to a family of filters called <em>Bayesian filters</em>. Most textbook treatments of the Kalman filter present the Bayesian formula, perhaps shows how it factors into the Kalman filter equations, but mostly keeps the discussion at a very abstract level.</p>
<p>That approach requires a fairly sophisticated understanding of several fields of mathematics, and it still leaves much of the work of understanding and forming an intuitive grasp of the situation in the hands of the reader.</p>
<p>I will use a different way to develop the topic, to which I owe the work of Dieter Fox and Sebastian Thrun a great debt. It depends on building an intuition on how Bayesian statistics work by tracking an object through a hallway - they use a robot, I use a dog. I like dogs, and they are less predictable than robots which imposes interesting difficulties for filtering. The first published example of this that I can find seems to be Fox 1999 [1], with a fuller example in Fox 2003 [2]. Sebastian Thrun also uses this formulation in his excellent Udacity course Artificial Intelligence for Robotics [3]. In fact, if you like watching videos, I highly recommend pausing reading this book in favor of first few lessons of that course, and then come back to this book for a deeper dive into the topic.</p>
<p>Letâ€™s now use a simple thought experiment, much like we did with the g-h filter, to see how we might reason about the use of probabilities for filtering and tracking.</p>
<section id="tracking-a-dog">
<h2>Tracking a Dog<a class="headerlink" href="#tracking-a-dog" title="Permalink to this heading">#</a></h2>
<p>Letâ€™s begin with a simple problem. We have a dog friendly workspace, and so people bring their dogs to work. Occasionally the dogs wander out of offices and down the halls. We want to be able to track them. So during a hackathon somebody invented a sonar sensor to attach to the dogâ€™s collar. It emits a signal, listens for the echo, and based on how quickly an echo comes back we can tell whether the dog is in front of an open doorway or not. It also senses when the dog walks, and reports in which direction the dog has moved. It connects to the network via wifi and sends an update once a second.</p>
<p>I want to track my dog Simon, so I attach the device to his collar and then fire up Python, ready to write code to track him through the building. At first blush this may appear impossible. If I start listening to the sensor of Simonâ€™s collar I might read <strong>door</strong>, <strong>hall</strong>, <strong>hall</strong>, and so on. How can I use that information to determine where Simon is?</p>
<p>To keep the problem small enough to plot easily we will assume that there are only 10 positions in the hallway, which we will number 0 to 9, where 1 is to the right of 0. For reasons that will be clear later, we will also assume that the hallway is circular or rectangular. If you move right from position 9, you will be at position 0.</p>
<p>When I begin listening to the sensor I have no reason to believe that Simon is at any particular position in the hallway. From my perspective he is equally likely to be in any position. There are 10 positions, so the probability that he is in any given position is 1/10.</p>
<p>Letâ€™s represent our belief of his position in a NumPy array. I could use a Python list, but NumPy arrays offer functionality that we will be using soon.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">10</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
</pre></div>
</div>
</div>
</div>
<p>In <a class="reference external" href="https://en.wikipedia.org/wiki/Bayesian_probability">Bayesian statistics</a> this is called a <a class="reference external" href="https://en.wikipedia.org/wiki/Prior_probability"><em>prior</em></a>. It is the probability prior to incorporating measurements or other information. More completely, this is called the <em>prior probability distribution</em>. A <a class="reference external" href="https://en.wikipedia.org/wiki/Probability_distribution"><em>probability distribution</em></a> is a collection of all possible probabilities for an event. Probability distributions always sum to 1 because something had to happen; the distribution lists all possible events and the probability of each.</p>
<p>Iâ€™m sure youâ€™ve used probabilities before - as in â€œthe probability of rain today is 30%â€. The last paragraph sounds like more of that. But Bayesian statistics was a revolution in probability because it treats probability as a belief about a single event. Letâ€™s take an example. I know that if I flip a fair coin infinitely many times I will get 50% heads and 50% tails. This is called <a class="reference external" href="https://en.wikipedia.org/wiki/Frequentist_inference"><em>frequentist statistics</em></a> to distinguish it from Bayesian statistics. Computations are based on the frequency in which events occur.</p>
<p>I flip the coin one more time and let it land. Which way do I believe it landed? Frequentist probability has nothing to say about that; it will merely state that 50% of coin flips land as heads. In some ways it is meaningless to assign a probability to the current state of the coin. It is either heads or tails, we just donâ€™t know which. Bayes treats this as a belief about a single event - the strength of my belief or knowledge that this specific coin flip is heads is 50%. Some object to the term â€œbeliefâ€; belief can imply holding something to be true without evidence. In this book it always is a measure of the strength of our knowledge. Weâ€™ll learn more about this as we go.</p>
<p>Bayesian statistics takes past information (the prior) into account. We observe that it rains 4 times every 100 days. From this I could state that the chance of rain tomorrow is 1/25. This is not how weather prediction is done. If I know it is raining today and the storm front is stalled, it is likely to rain tomorrow. Weather prediction is Bayesian.</p>
<p>In practice statisticians use a mix of frequentist and Bayesian techniques. Sometimes finding the prior is difficult or impossible, and frequentist techniques rule. In this book we can find the prior. When I talk about the probability of something I am referring to the probability that some specific thing is true given past events. When I do that Iâ€™m taking the Bayesian approach.</p>
<p>Now letâ€™s create a map of the hallway. Weâ€™ll place the first two doors close together, and then another door further away. We will use 1 for doors, and 0 for walls:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hallway</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>I start listening to Simonâ€™s transmissions on the network, and the first data I get from the sensor is <strong>door</strong>. For the moment assume the sensor always returns the correct answer. From this I conclude that he is in front of a door, but which one? I have no reason to believe he is in front of the first, second, or third door. What I can do is assign a probability to each door. All doors are equally likely, and there are three of them, so I assign a probability of 1/3 to each door.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">kf_book.book_plots</span> <span class="k">as</span> <span class="nn">book_plots</span>
<span class="kn">from</span> <span class="nn">kf_book.book_plots</span> <span class="kn">import</span> <span class="n">figsize</span><span class="p">,</span> <span class="n">set_figsize</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/f795d6a493ff861b38a0bcf1a5159b7a3a5a31c31557f97c0907a321c6e63a62.png" src="../../../../_images/f795d6a493ff861b38a0bcf1a5159b7a3a5a31c31557f97c0907a321c6e63a62.png" />
</div>
</div>
<p>This distribution is called a <a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution"><em>categorical distribution</em></a>, which is a discrete distribution describing the probability of observing <span class="math notranslate nohighlight">\(n\)</span> outcomes. It is a <a class="reference external" href="https://en.wikipedia.org/wiki/Multimodal_distribution"><em>multimodal distribution</em></a> because we have multiple beliefs about the position of our dog. Of course we are not saying that we think he is simultaneously in three different locations, merely that we have narrowed down our knowledge to one of these three locations. My (Bayesian) belief is that there is a 33.3% chance of being at door 0, 33.3% at door 1, and a 33.3% chance of being at door 8.</p>
<p>This is an improvement in two ways. Iâ€™ve rejected a number of hallway positions as impossible, and the strength of my belief in the remaining positions has increased from 10% to 33%. This will always happen. As our knowledge improves the probabilities will get closer to 100%.</p>
<p>A few words about the <a class="reference external" href="https://en.wikipedia.org/wiki/Mode_%28statistics%29"><em>mode</em></a>
of a distribution. Given a list of numbers, such as {1, 2, 2, 2, 3, 3, 4}, the <em>mode</em> is the number that occurs most often. For this set the mode is 2. A distribution can contain more than one mode. The list {1, 2, 2, 2, 3, 3, 4, 4, 4} contains the modes 2 and 4, because both occur three times. We say the former list is <a class="reference external" href="https://en.wikipedia.org/wiki/Unimodality"><em>unimodal</em></a>, and the latter is <em>multimodal</em>.</p>
<p>Another term used for this distribution is a <a class="reference external" href="https://en.wikipedia.org/wiki/Histogram"><em>histogram</em></a>. Histograms graphically depict the distribution of a set of numbers. The bar chart above is a histogram.</p>
<p>I hand coded the <code class="docutils literal notranslate"><span class="pre">belief</span></code> array in the code above. How would we implement this in code? We represent doors with 1, and walls as 0, so we will multiply the hallway variable by the percentage, like so;</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span> <span class="o">=</span> <span class="n">hallway</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.333 0.333 0.    0.    0.    0.    0.    0.    0.333 0.   ]
</pre></div>
</div>
</div>
</div>
</section>
<section id="extracting-information-from-sensor-readings">
<h2>Extracting Information from Sensor Readings<a class="headerlink" href="#extracting-information-from-sensor-readings" title="Permalink to this heading">#</a></h2>
<p>Letâ€™s put Python aside and think about the problem a bit. Suppose we were to read the following from Simonâ€™s sensor:</p>
<ul class="simple">
<li><p>door</p></li>
<li><p>move right</p></li>
<li><p>door</p></li>
</ul>
<p>Can we deduce Simonâ€™s location? Of course! Given the hallwayâ€™s layout there is only one place from which you can get this sequence, and that is at the left end. Therefore we can confidently state that Simon is in front of the second doorway. If this is not clear, suppose Simon had started at the second or third door. After moving to the right, his sensor would have returned â€˜wallâ€™. That doesnâ€™t match the sensor readings, so we know he didnâ€™t start there. We can continue with that logic for all the remaining starting positions. The only possibility is that he is now in front of the second door. Our belief is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>I designed the hallway layout and sensor readings to give us an exact answer quickly. Real problems are not so clear cut. But this should trigger your intuition - the first sensor reading only gave us low probabilities (0.333) for Simonâ€™s location, but after a position update and another sensor reading we know more about where he is. You might suspect, correctly, that if you had a very long hallway with a large number of doors that after several sensor readings and positions updates we would either be able to know where Simon was, or have the possibilities narrowed down to a small number of possibilities. This is possible when a set of sensor readings only matches one to a few starting locations.</p>
<p>We could implement this solution now, but instead letâ€™s consider a real world complication to the problem.</p>
</section>
<section id="noisy-sensors">
<h2>Noisy Sensors<a class="headerlink" href="#noisy-sensors" title="Permalink to this heading">#</a></h2>
<p>Perfect sensors are rare. Perhaps the sensor would not detect a door if Simon sat in front of it while scratching himself, or misread if he is not facing down the hallway. Thus when I get <strong>door</strong> I cannot use 1/3 as the probability. I have to assign less than 1/3 to each door, and assign a small probability to each blank wall position. Something like</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="mf">.31</span><span class="p">,</span> <span class="mf">.31</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.01</span><span class="p">,</span> <span class="mf">.31</span><span class="p">,</span> <span class="mf">.01</span><span class="p">]</span>
</pre></div>
</div>
<p>At first this may seem insurmountable. If the sensor is noisy it casts doubt on every piece of data. How can we conclude anything if we are always unsure?</p>
<p>The answer, as for the problem above, is with probabilities. We are already comfortable assigning a probabilistic belief to the location of the dog; now we have to incorporate the additional uncertainty caused by the sensor noise.</p>
<p>Say we get a reading of <strong>door</strong>, and suppose that testing shows that the sensor is 3 times more likely to be right than wrong. We should scale the probability distribution by 3 where there is a door. If we do that the result will no longer be a probability distribution, but we will learn how to fix that in a moment.</p>
<p>Letâ€™s look at that in Python code. Here I use the variable <code class="docutils literal notranslate"><span class="pre">z</span></code> to denote the measurement. <code class="docutils literal notranslate"><span class="pre">z</span></code> or <code class="docutils literal notranslate"><span class="pre">y</span></code> are customary choices in the literature for the measurement. As a programmer I prefer meaningful variable names, but I want you to be able to read the literature and/or other filtering code, so I will start introducing these abbreviated names now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update_belief</span><span class="p">(</span><span class="n">hall</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">correct_scale</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hall</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">val</span> <span class="o">==</span> <span class="n">z</span><span class="p">:</span>
            <span class="n">belief</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="n">correct_scale</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">reading</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># 1 is &#39;door&#39;</span>
<span class="n">update_belief</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">reading</span><span class="p">,</span> <span class="n">correct_scale</span><span class="o">=</span><span class="mf">3.</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;belief:&#39;</span><span class="p">,</span> <span class="n">belief</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sum =&#39;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">belief</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>belief: [0.3 0.3 0.1 0.1 0.1 0.1 0.1 0.1 0.3 0.1]
sum = 1.6000000000000003
</pre></div>
</div>
<img alt="../../../../_images/3e647965259bda0a65cd6092451c7c5bac2edf749369d7a8a3fac113556789f3.png" src="../../../../_images/3e647965259bda0a65cd6092451c7c5bac2edf749369d7a8a3fac113556789f3.png" />
</div>
</div>
<p>This is not a probability distribution because it does not sum to 1.0. But the code is doing mostly the right thing - the doors are assigned a number (0.3) that is 3 times higher than the walls (0.1). All we need to do is normalize the result so that the probabilities correctly sum to 1.0. Normalization is done by dividing each element by the sum of all elements in the list. That is easy with NumPy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.188, 0.188, 0.062, 0.062, 0.062, 0.062, 0.062, 0.062, 0.188,
       0.062])
</pre></div>
</div>
</div>
</div>
<p>FilterPy implements this with the <code class="docutils literal notranslate"><span class="pre">normalize</span></code> function:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">filterpy.discrete_bayes</span> <span class="kn">import</span> <span class="n">normalize</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
<p>It is a bit odd to say â€œ3 times as likely to be right as wrongâ€. We are working in probabilities, so letâ€™s specify the probability of the sensor being correct, and compute the scale factor from that. The equation for that is</p>
<div class="math notranslate nohighlight">
\[scale =  \frac{prob_{correct}}{prob_{incorrect}} = \frac{prob_{correct}} {1-prob_{correct}}\]</div>
<p>Also, the <code class="docutils literal notranslate"><span class="pre">for</span></code> loop is cumbersome. As a general rule you will want to avoid using <code class="docutils literal notranslate"><span class="pre">for</span></code> loops in NumPy code. NumPy is implemented in C and Fortran, so if you avoid for loops the result often runs 100x faster than the equivalent loop.</p>
<p>How do we get rid of this <code class="docutils literal notranslate"><span class="pre">for</span></code> loop? NumPy lets you index arrays with boolean arrays. You create a boolean array with logical operators. We can find all the doors in the hallway with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hallway</span> <span class="o">==</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ True,  True, False, False, False, False, False, False,  True,
       False])
</pre></div>
</div>
</div>
</div>
<p>When you use the boolean array as an index to another array it returns only the elements where the index is <code class="docutils literal notranslate"><span class="pre">True</span></code>. Thus we can replace the <code class="docutils literal notranslate"><span class="pre">for</span></code> loop with</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span><span class="p">[</span><span class="n">hall</span><span class="o">==</span><span class="n">z</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale</span>
</pre></div>
</div>
<p>and only the elements which equal <code class="docutils literal notranslate"><span class="pre">z</span></code> will be multiplied by <code class="docutils literal notranslate"><span class="pre">scale</span></code>.</p>
<p>Teaching you NumPy is beyond the scope of this book. I will use idiomatic NumPy constructs and explain them the first time I present them. If you are new to NumPy there are many blog posts and videos on how to use NumPy efficiently and idiomatically.</p>
<p>Here is our improved version:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">filterpy.discrete_bayes</span> <span class="kn">import</span> <span class="n">normalize</span>

<span class="k">def</span> <span class="nf">scaled_update</span><span class="p">(</span><span class="n">hall</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">):</span> 
    <span class="n">scale</span> <span class="o">=</span> <span class="n">z_prob</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">z_prob</span><span class="p">)</span>
    <span class="n">belief</span><span class="p">[</span><span class="n">hall</span><span class="o">==</span><span class="n">z</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale</span>
    <span class="n">normalize</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">scaled_update</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sum =&#39;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">belief</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;probability of door =&#39;</span><span class="p">,</span> <span class="n">belief</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;probability of wall =&#39;</span><span class="p">,</span> <span class="n">belief</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sum = 1.0
probability of door = 0.1875
probability of wall = 0.06249999999999999
</pre></div>
</div>
<img alt="../../../../_images/4855650b5303087cd7cadd95dacd4f1c9f5e5f08ab9a10bd13683a0c337f09ce.png" src="../../../../_images/4855650b5303087cd7cadd95dacd4f1c9f5e5f08ab9a10bd13683a0c337f09ce.png" />
</div>
</div>
<p>We can see from the output that the sum is now 1.0, and that the probability of a door vs wall is still three times larger. The result also fits our intuition that the probability of a door must be less than 0.333, and that the probability of a wall must be greater than 0.0. Finally, it should fit our intuition that we have not yet been given any information that would allow us to distinguish between any given door or wall position, so all door positions should have the same value, and the same should be true for wall positions.</p>
<p>This result is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Posterior_probability"><em>posterior</em></a>, which is short for <em>posterior probability distribution</em>. All this means is a probability distribution <em>after</em> incorporating the measurement information (posterior means â€˜afterâ€™ in this context). To review, the <em>prior</em> is the probability distribution before including the measurementâ€™s information.</p>
<p>Another term is the <a class="reference external" href="https://en.wikipedia.org/wiki/Likelihood_function"><em>likelihood</em></a>. When we computed <code class="docutils literal notranslate"><span class="pre">belief[hall==z]</span> <span class="pre">*=</span> <span class="pre">scale</span></code> we were computing how <em>likely</em> each position was given the measurement. The likelihood is not a probability distribution because it does not sum to one.</p>
<p>The combination of these gives the equation</p>
<div class="math notranslate nohighlight">
\[\mathtt{posterior} = \frac{\mathtt{likelihood} \times \mathtt{prior}}{\mathtt{normalization}}\]</div>
<p>When we talk about the filterâ€™s output we typically call the state after performing the prediction the <em>prior</em> or <em>prediction</em>, and we call the state after the update either the <em>posterior</em> or the <em>estimated state</em>.</p>
<p>It is very important to learn and internalize these terms as most of the literature uses them extensively.</p>
<p>Does <code class="docutils literal notranslate"><span class="pre">scaled_update()</span></code> perform this computation? It does. Let me recast it into this form:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_update</span><span class="p">(</span><span class="n">hall</span><span class="p">,</span> <span class="n">belief</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">):</span> 
    <span class="n">scale</span> <span class="o">=</span> <span class="n">z_prob</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">z_prob</span><span class="p">)</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hall</span><span class="p">))</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">hall</span><span class="o">==</span><span class="n">z</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale</span>
    <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">likelihood</span> <span class="o">*</span> <span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This function is not fully general. It contains knowledge about the hallway, and how we match measurements to it. We always strive to write general functions. Here we will remove the computation of the likelihood from the function, and require the caller to compute the likelihood themselves.</p>
<p>Here is a full implementation of the algorithm:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">normalize</span><span class="p">(</span><span class="n">likelihood</span> <span class="o">*</span> <span class="n">prior</span><span class="p">)</span>
</pre></div>
</div>
<p>Computation of the likelihood varies per problem. For example, the sensor might not return  just 1 or 0, but a <code class="docutils literal notranslate"><span class="pre">float</span></code> between 0 and 1 indicating the probability of being in front of a door. It might use computer vision and report a blob shape that you then probabilistically match to a door. It might use sonar and return a distance reading. In each case the computation of the likelihood will be different. We will see many examples of this throughout the book, and learn how to perform these calculations.</p>
<p>FilterPy implements <code class="docutils literal notranslate"><span class="pre">update</span></code>. Here is the previous example in a fully general form:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">filterpy.discrete_bayes</span> <span class="kn">import</span> <span class="n">update</span>

<span class="k">def</span> <span class="nf">lh_hallway</span><span class="p">(</span><span class="n">hall</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; compute likelihood that a measurement matches</span>
<span class="sd">    positions in the hallway.&quot;&quot;&quot;</span>
    
    <span class="k">try</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">z_prob</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">z_prob</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1e8</span>

    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hall</span><span class="p">))</span>
    <span class="n">likelihood</span><span class="p">[</span><span class="n">hall</span><span class="o">==</span><span class="n">z</span><span class="p">]</span> <span class="o">*=</span> <span class="n">scale</span>
    <span class="k">return</span> <span class="n">likelihood</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
<span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">belief</span><span class="p">)</span>  
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.188, 0.188, 0.062, 0.062, 0.062, 0.062, 0.062, 0.062, 0.188,
       0.062])
</pre></div>
</div>
</div>
</div>
</section>
<section id="incorporating-movement">
<h2>Incorporating Movement<a class="headerlink" href="#incorporating-movement" title="Permalink to this heading">#</a></h2>
<p>Recall how quickly we were able to find an exact solution when we incorporated a series of measurements and movement updates. However, that occurred in a fictional world of perfect sensors. Might we be able to find an exact solution with noisy sensors?</p>
<p>Unfortunately, the answer is no. Even if the sensor readings perfectly match an extremely complicated hallway map, we cannot be 100% certain that the dog is in a specific position - there is, after all, a tiny possibility that every sensor reading was wrong! Naturally, in a more typical situation most sensor readings will be correct, and we might be close to 100% sure of our answer, but never 100% sure. This may seem complicated, but letâ€™s go ahead and program the math.</p>
<p>First letâ€™s deal with the simple case - assume the movement sensor is perfect, and it reports that the dog has moved one space to the right. How would we alter our <code class="docutils literal notranslate"><span class="pre">belief</span></code> array?</p>
<p>I hope that after a momentâ€™s thought it is clear that we should shift all the values one space to the right. If we previously thought there was a 50% chance of Simon being at position 3, then after he moved one position to the right we should believe that there is a 50% chance he is at position 4. The hallway is circular, so we will use modulo arithmetic to perform the shift.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">perfect_predict</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">move</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; move the position by `move` spaces, where positive is </span>
<span class="sd">    to the right, and negative is to the left</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">belief</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="n">move</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">result</span>
        
<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.35</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Before prediction&#39;</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.4</span><span class="p">))</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">perfect_predict</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;After prediction&#39;</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/b9c2a80269144d18134b629b139f9fe91293aec187c29549a806ba35aa530602.png" src="../../../../_images/b9c2a80269144d18134b629b139f9fe91293aec187c29549a806ba35aa530602.png" />
</div>
</div>
<p>We can see that we correctly shifted all values one position to the right, wrapping from the end of the array back to the beginning.</p>
<p>The next cell animates this so you can see it in action. Use the slider to move forwards and backwards in time. This simulates Simon walking around and around the hallway. It does not yet incorporate new measurements so the probability distribution does not change shape, only position.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">IntSlider</span>

<span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.35</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.05</span><span class="p">])</span>
<span class="n">perfect_beliefs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="c1"># Simon takes one step to the right</span>
    <span class="n">belief</span> <span class="o">=</span> <span class="n">perfect_predict</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">perfect_beliefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simulate</span><span class="p">(</span><span class="n">time_step</span><span class="p">):</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">perfect_beliefs</span><span class="p">[</span><span class="n">time_step</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.4</span><span class="p">))</span>
    
<span class="n">interact</span><span class="p">(</span><span class="n">simulate</span><span class="p">,</span> <span class="n">time_step</span><span class="o">=</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">perfect_beliefs</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "69e1cf784fd743ddaeae41d5fa161216", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="terminology">
<h2>Terminology<a class="headerlink" href="#terminology" title="Permalink to this heading">#</a></h2>
<p>Letâ€™s pause a moment to review terminology. I introduced this terminology in the last chapter, but letâ€™s take a second to help solidify your knowledge.</p>
<p>The <em>system</em> is what we are trying to model or filter. Here the system is our dog. The <em>state</em> is its current configuration or value. In this chapter the state is our dogâ€™s position. We rarely know the actual state, so we say our filters produce the <em>estimated state</em> of the system. In practice this often gets called the state, so be careful to understand the context.</p>
<p>One cycle of prediction and updating with a measurement is called the state or system <em>evolution</em>, which is short for <em>time evolution</em> [7]. Another term is <em>system propagation</em>. It refers to how the state of the system changes over time. For filters, time is usually a discrete step, such as 1 second. For our dog tracker the system state is the position of the dog, and the state evolution is the position after a discrete amount of time has passed.</p>
<p>We model the system behavior with the <em>process model</em>. Here, our process model is that the dog moves one or more positions at each time step. This is not a particularly accurate model of how dogs behave. The error in the model is called the <em>system error</em> or <em>process error</em>.</p>
<p>The prediction is our new <em>prior</em>. Time has moved forward and we made a prediction without benefit of knowing the measurements.</p>
<p>Letâ€™s work an example. The current position of the dog is 17 m. Our epoch is 2 seconds long, and the dog is traveling at 15 m/s. Where do we predict he will be in two seconds?</p>
<p>Clearly,</p>
<div class="math notranslate nohighlight">
\[\begin{split} \begin{aligned}
\bar x &amp;= 17 + (15*2) \\
&amp;= 47
\end{aligned}\end{split}\]</div>
<p>I use bars over variables to indicate that they are priors (predictions). We can write the equation for the process model like this:</p>
<div class="math notranslate nohighlight">
\[ \bar x_{k+1} = f_x(\bullet) + x_k\]</div>
<p><span class="math notranslate nohighlight">\(x_k\)</span> is the current position or state. If the dog is at 17 m then <span class="math notranslate nohighlight">\(x_k = 17\)</span>.</p>
<p><span class="math notranslate nohighlight">\(f_x(\bullet)\)</span> is the state propagation function for x. It describes how much the <span class="math notranslate nohighlight">\(x_k\)</span> changes over one time step. For our example it performs the computation <span class="math notranslate nohighlight">\(15 \cdot 2\)</span> so we would define it as</p>
<p>$<span class="math notranslate nohighlight">\(f_x(v_x, t) = v_k t\)</span>$.</p>
</section>
<section id="adding-uncertainty-to-the-prediction">
<h2>Adding Uncertainty to the Prediction<a class="headerlink" href="#adding-uncertainty-to-the-prediction" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">perfect_predict()</span></code> assumes perfect measurements, but all sensors have noise. What if the sensor reported that our dog moved one space, but he actually moved two spaces, or zero? This may sound like an insurmountable problem, but letâ€™s model it and see what happens.</p>
<p>Assume that the sensorâ€™s movement measurement is 80% likely to be correct, 10% likely to overshoot one position to the right, and 10% likely to undershoot to the left. That is, if the movement measurement is 4 (meaning 4 spaces to the right), the dog is 80% likely to have moved 4 spaces to the right, 10% to have moved 3 spaces, and 10% to have moved 5 spaces.</p>
<p>Each result in the array now needs to incorporate probabilities for 3 different situations. For example, consider the reported movement of 2. If we are 100% certain the dog started from position 3, then there is an 80% chance he is at 5, and a 10% chance for either 4 or 6. Letâ€™s try coding that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_move</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">move</span><span class="p">,</span> <span class="n">p_under</span><span class="p">,</span> <span class="n">p_correct</span><span class="p">,</span> <span class="n">p_over</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">belief</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="n">move</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span><span class="p">]</span>   <span class="o">*</span> <span class="n">p_correct</span> <span class="o">+</span>
            <span class="n">belief</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="n">move</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">p_over</span> <span class="o">+</span>
            <span class="n">belief</span><span class="p">[(</span><span class="n">i</span><span class="o">-</span><span class="n">move</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">n</span><span class="p">]</span> <span class="o">*</span> <span class="n">p_under</span><span class="p">)</span>      
    <span class="k">return</span> <span class="n">prior</span>

<span class="n">belief</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">predict_move</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_belief_vs_prior</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/287ce06a908c6bd7890022b3b4f3bf69523f6de7b023869283d94fa1d4aa121d.png" src="../../../../_images/287ce06a908c6bd7890022b3b4f3bf69523f6de7b023869283d94fa1d4aa121d.png" />
</div>
</div>
<p>It appears to work correctly. Now what happens when our belief is not 100% certain?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">.4</span><span class="p">,</span> <span class="mf">.6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">predict_move</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_belief_vs_prior</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
<span class="n">prior</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.  , 0.  , 0.  , 0.04, 0.38, 0.52, 0.06, 0.  , 0.  , 0.  ])
</pre></div>
</div>
<img alt="../../../../_images/e199ba0cfe5411f4c921106e9f9b13c98a8023ebb68a46385b7fa13c023bf87c.png" src="../../../../_images/e199ba0cfe5411f4c921106e9f9b13c98a8023ebb68a46385b7fa13c023bf87c.png" />
</div>
</div>
<p>Here the results are more complicated, but you should still be able to work it out in your head. The 0.04 is due to the possibility that the 0.4 belief undershot by 1. The 0.38 is due to the following: the 80% chance that we moved 2 positions (0.4 <span class="math notranslate nohighlight">\(\times\)</span> 0.8) and the 10% chance that we undershot (0.6 <span class="math notranslate nohighlight">\(\times\)</span> 0.1). Overshooting plays no role here because if we overshot both 0.4 and 0.6 would be past this position. <strong>I strongly suggest working some examples until all of this is very clear, as so much of what follows depends on understanding this step.</strong></p>
<p>If you look at the probabilities after performing the update you might be dismayed. In the example above we started with probabilities of 0.4 and 0.6 in two positions; after performing the update the probabilities are not only lowered, but they are strewn out across the map.</p>
<p>This is not a coincidence, or the result of a carefully chosen example - it is always true of the prediction. If the sensor is noisy we lose some information on every prediction. Suppose we were to perform the prediction an infinite number of times - what would the result be? If we lose information on every step, we must eventually end up with no information at all, and our probabilities will be equally distributed across the <code class="docutils literal notranslate"><span class="pre">belief</span></code> array. Letâ€™s try this with 100 iterations. The plot is animated; use the slider to change the step number.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">belief</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">predict_beliefs</span> <span class="o">=</span> <span class="p">[]</span>
    
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">belief</span> <span class="o">=</span> <span class="n">predict_move</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
    <span class="n">predict_beliefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">belief</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Final Belief:&#39;</span><span class="p">,</span> <span class="n">belief</span><span class="p">)</span>

<span class="c1"># make interactive plot</span>
<span class="k">def</span> <span class="nf">show_prior</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">predict_beliefs</span><span class="p">[</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">interact</span><span class="p">(</span><span class="n">show_prior</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">predict_beliefs</span><span class="p">)));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Belief: [0.104 0.103 0.101 0.099 0.097 0.096 0.097 0.099 0.101 0.103]
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b7f90f29b9394f82b4c64982c8eab901", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Final Belief:&#39;</span><span class="p">,</span> <span class="n">belief</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Final Belief: [0.104 0.103 0.101 0.099 0.097 0.096 0.097 0.099 0.101 0.103]
</pre></div>
</div>
</div>
</div>
<p>After 100 iterations we have lost almost all information, even though we were 100% sure that we started in position 0. Feel free to play with the numbers to see the effect of differing number of updates. For example, after 100 updates a small amount of information is left, after 50 a lot is left, but by 200 iterations essentially all information is lost.</p>
<p>And, if you are viewing this online here is an animation of that output.
<img alt="aiml-common/lectures/rse/discrete-bayesian-filter/animations/02_no_info.gif" src="aiml-common/lectures/rse/discrete-bayesian-filter/animations/02_no_info.gif" /></p>
<p>I will not generate these standalone animations through the rest of the book. Please see the preface for instructions to run this book on the web, for free, or install IPython on your computer. This will allow you to run all of the cells and see the animations. Itâ€™s very important that you practice with this code, not just read passively.</p>
</section>
<section id="generalizing-with-convolution">
<h2>Generalizing with Convolution<a class="headerlink" href="#generalizing-with-convolution" title="Permalink to this heading">#</a></h2>
<p>We made the assumption that the movement error is at most one position. But it is possible for the error to be two, three, or more positions. As programmers we always want to generalize our code so that it works for all cases.</p>
<p>This is easily solved with <a class="reference external" href="https://en.wikipedia.org/wiki/Convolution"><em>convolution</em></a>. Convolution modifies one function with another function. In our case we are modifying a probability distribution with the error function of the sensor. The implementation of <code class="docutils literal notranslate"><span class="pre">predict_move()</span></code> is a convolution, though we did not call it that. Formally, convolution is defined as</p>
<div class="math notranslate nohighlight">
\[ (f \ast g) (t) = \int_0^t \!f(\tau) \, g(t-\tau) \, \mathrm{d}\tau\]</div>
<p>where <span class="math notranslate nohighlight">\(f\ast g\)</span> is the notation for convolving f by g. It does not mean multiply.</p>
<p>Integrals are for continuous functions, but we are using discrete functions. We replace the integral with a summation, and the parenthesis with array brackets.</p>
<div class="math notranslate nohighlight">
\[ (f \ast g) [t] = \sum\limits_{\tau=0}^t \!f[\tau] \, g[t-\tau]\]</div>
<p>Comparison shows that <code class="docutils literal notranslate"><span class="pre">predict_move()</span></code> is computing this equation - it computes the sum of a series of multiplications.</p>
<p><a class="reference external" href="https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution">Khan Academy</a> [4] has a good introduction to convolution, and Wikipedia has some excellent animations of convolutions [5]. But the general idea is already clear. You slide an array called the <em>kernel</em> across another array, multiplying the neighbors of the current cell with the values of the second array. In our example above we used 0.8 for the probability of moving to the correct location, 0.1 for undershooting, and 0.1 for overshooting. We make a kernel of this with the array <code class="docutils literal notranslate"><span class="pre">[0.1,</span> <span class="pre">0.8,</span> <span class="pre">0.1]</span></code>. All we need to do is write a loop that goes over each element of our array, multiplying by the kernel, and summing the results. To emphasize that the belief is a probability distribution I have named it <code class="docutils literal notranslate"><span class="pre">pdf</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_move_convolution</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">kernel</span><span class="p">):</span>
    <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pdf</span><span class="p">)</span>
    <span class="n">kN</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">kernel</span><span class="p">)</span>
    <span class="n">width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">kN</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">kN</span><span class="p">):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="p">(</span><span class="n">width</span><span class="o">-</span><span class="n">k</span><span class="p">)</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span> <span class="o">%</span> <span class="n">N</span>
            <span class="n">prior</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">prior</span>
</pre></div>
</div>
</div>
</div>
<p>This illustrates the algorithm, but it runs very slow. SciPy provides a convolution routine <code class="docutils literal notranslate"><span class="pre">convolve()</span></code> in the <code class="docutils literal notranslate"><span class="pre">ndimage.filters</span></code> module. We  need to shift the pdf by <code class="docutils literal notranslate"><span class="pre">offset</span></code> before convolution; <code class="docutils literal notranslate"><span class="pre">np.roll()</span></code> does that. The move and predict algorithm can be implemented with one line:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">convolve</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="n">offset</span><span class="p">),</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;wrap&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>FilterPy implements this with <code class="docutils literal notranslate"><span class="pre">discrete_bayes</span></code>â€™ <code class="docutils literal notranslate"><span class="pre">predict()</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">filterpy.discrete_bayes</span> <span class="kn">import</span> <span class="n">predict</span>

<span class="n">belief</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.55</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">]</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_belief_vs_prior</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/cf74c5b671413365fe2fa1a41feeddb095d5d085330f66c7831b1210772c619f.png" src="../../../../_images/cf74c5b671413365fe2fa1a41feeddb095d5d085330f66c7831b1210772c619f.png" />
</div>
</div>
<p>All of the elements are unchanged except the middle ones. The values in position 4 and 6 should be
$<span class="math notranslate nohighlight">\((0.1 \times 0.05)+ (0.8 \times 0.05) + (0.1 \times 0.55) = 0.1\)</span>$</p>
<p>Position 5 should be $<span class="math notranslate nohighlight">\((0.1 \times 0.05) + (0.8 \times 0.55)+ (0.1 \times 0.05) = 0.45\)</span>$</p>
<p>Letâ€™s ensure that it shifts the positions correctly for movements greater than one and for asymmetric kernels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">.05</span><span class="p">,</span> <span class="mf">.05</span><span class="p">,</span> <span class="mf">.6</span><span class="p">,</span> <span class="mf">.2</span><span class="p">,</span> <span class="mf">.1</span><span class="p">])</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_belief_vs_prior</span><span class="p">(</span><span class="n">belief</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.6</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/4015ede96d89ecd812b8e429dde9b3412cb62d786a01a400aa0599aa746389f9.png" src="../../../../_images/4015ede96d89ecd812b8e429dde9b3412cb62d786a01a400aa0599aa746389f9.png" />
</div>
</div>
<p>The position was correctly shifted by 3 positions and we give more weight to the likelihood of an overshoot vs an undershoot, so this looks correct.</p>
<p>Make sure you understand what we are doing. We are making a prediction of where the dog is moving, and convolving the probabilities to get the prior.</p>
<p>If we werenâ€™t using probabilities we would use this equation that I gave earlier:</p>
<div class="math notranslate nohighlight">
\[ \bar x_{k+1} = x_k + f_{\mathbf x}(\bullet)\]</div>
<p>The prior, our prediction of where the dog will be, is the amount the dog moved plus his current position. The dog was at 10, he moved 5 meters, so he is now at 15 m. It couldnâ€™t be simpler. But we are using probabilities to model this, so our equation is:</p>
<div class="math notranslate nohighlight">
\[ \bar{ \mathbf x}_{k+1} = \mathbf x_k \ast f_{\mathbf x}(\bullet)\]</div>
<p>We are <em>convolving</em> the current probabilistic position estimate with a probabilistic estimate of how much we think the dog moved. Itâ€™s the same concept, but the math is slightly different. <span class="math notranslate nohighlight">\(\mathbf x\)</span> is bold to denote that it is an array of numbers.</p>
</section>
<section id="integrating-measurements-and-movement-updates">
<h2>Integrating Measurements and Movement Updates<a class="headerlink" href="#integrating-measurements-and-movement-updates" title="Permalink to this heading">#</a></h2>
<p>The problem of losing information during a prediction may make it seem as if our system would quickly devolve into having no knowledge. However, each prediction is followed by an update where we incorporate the measurement into the estimate. The update improves our knowledge. The output of the update step is fed into the next prediction. The prediction degrades our certainty. That is passed into another update, where certainty is again increased.</p>
<p>Letâ€™s think about this intuitively. Consider a simple case - you are tracking a dog while he sits still. During each prediction you predict he doesnâ€™t move. Your filter quickly <em>converges</em> on an accurate estimate of his position. Then the microwave in the kitchen turns on, and he goes streaking off. You donâ€™t know this, so at the next prediction you predict he is in the same spot. But the measurements tell a different story. As you incorporate the measurements your belief will be smeared along the hallway, leading towards the kitchen. On every epoch (cycle) your belief that he is sitting still will get smaller, and your belief that he is inbound towards the kitchen at a startling rate of speed increases.</p>
<p>That is what intuition tells us. What does the math tell us?</p>
<p>We have already programmed the update and predict steps. All we need to do is feed the result of one into the other, and we will have implemented a dog tracker!!! Letâ€™s see how it performs. We will input measurements as if the dog started at position 0 and moved right one position each epoch. As in a real world application, we will start with no knowledge of his position by assigning equal probability to all positions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">filterpy.discrete_bayes</span> <span class="kn">import</span> <span class="n">update</span>

<span class="n">hallway</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_prior_vs_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/53bf10bc56eb5964c72f4dc1c86c6f95fcb72512fc66a5c2437a77bef58e9c40.png" src="../../../../_images/53bf10bc56eb5964c72f4dc1c86c6f95fcb72512fc66a5c2437a77bef58e9c40.png" />
</div>
</div>
<p>After the first update we have assigned a high probability to each door position, and a low probability to each wall position.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_prior_vs_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/5b0b0e79c7de8ae1bcc617acab1f89aec2f85ebf915dc327d64143a5194a3198.png" src="../../../../_images/5b0b0e79c7de8ae1bcc617acab1f89aec2f85ebf915dc327d64143a5194a3198.png" />
</div>
</div>
<p>The predict step shifted these probabilities to the right, smearing them about a bit. Now letâ€™s look at what happens at the next sense.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_prior_vs_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/b657c0578820e7778eb28d9568314af04a7e8856d9c1a4f4373b2a900a32a926.png" src="../../../../_images/b657c0578820e7778eb28d9568314af04a7e8856d9c1a4f4373b2a900a32a926.png" />
</div>
</div>
<p>Notice the tall bar at position 1. This corresponds with the (correct) case of starting at position 0, sensing a door, shifting 1 to the right, and sensing another door. No other positions make this set of observations as likely. Now we will add an update and then sense the wall.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_prior_vs_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/b3b36363e69945675cad63bdab0818be0afbe65d0de67e62ebd235c605ba186a.png" src="../../../../_images/b3b36363e69945675cad63bdab0818be0afbe65d0de67e62ebd235c605ba186a.png" />
</div>
</div>
<p>This is exciting! We have a very prominent bar at position 2 with a value of around 35%. It is over twice the value of any other bar in the plot, and is about 4% larger than our last plot, where the tallest bar was around 31%. Letâ€™s see one more cycle.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
<span class="n">book_plots</span><span class="o">.</span><span class="n">plot_prior_vs_posterior</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/d6eb3afc027d0af17b4a49947154f250bb1fd1c015bf858ee37db2cb60907495.png" src="../../../../_images/d6eb3afc027d0af17b4a49947154f250bb1fd1c015bf858ee37db2cb60907495.png" />
</div>
</div>
<p>I ignored an important issue. Earlier I assumed that we had a motion sensor for the predict step; then, when talking about the dog and the microwave I assumed that you had no knowledge that he suddenly began running. I mentioned that your belief that the dog is running would increase over time, but I did not provide any code for this. In short, how do we detect and/or estimate changes in the process model if we arenâ€™t directly measuring it?</p>
<p>For now I want to ignore this problem. In later chapters we will learn the mathematics behind this estimation; for now it is a large enough task just to learn this algorithm. It is profoundly important to solve this problem, but we havenâ€™t yet built enough of the mathematical apparatus that is required, and so for the remainder of the chapter we will ignore the problem by assuming we have a sensor that senses movement.</p>
</section>
<section id="the-discrete-bayes-algorithm">
<h2>The Discrete Bayes Algorithm<a class="headerlink" href="#the-discrete-bayes-algorithm" title="Permalink to this heading">#</a></h2>
<p>This chart illustrates the algorithm:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">book_plots</span><span class="o">.</span><span class="n">predict_update_chart</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/3ad874606e939b2e86ba19516d7c985ae017c4f1206fe46581db53088dbdfb69.png" src="../../../../_images/3ad874606e939b2e86ba19516d7c985ae017c4f1206fe46581db53088dbdfb69.png" />
</div>
</div>
<p>This filter is a form of the g-h filter. Here we are using the percentages for the errors to implicitly compute the <span class="math notranslate nohighlight">\(g\)</span> and <span class="math notranslate nohighlight">\(h\)</span> parameters. We could express the discrete Bayes algorithm as a g-h filter, but that would obscure the logic of this filter.</p>
<p>The filter equations are:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} \bar {\mathbf x} &amp;= \mathbf x \ast f_{\mathbf x}(\bullet)\, \, &amp;\text{Predict Step} \\
\mathbf x &amp;= \|\mathcal L \cdot \bar{\mathbf x}\|\, \, &amp;\text{Update Step}\end{aligned}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\mathcal L\)</span> is the usual way to write the likelihood function, so I use that. The <span class="math notranslate nohighlight">\(\|\|\)</span> notation denotes taking the norm. We need to normalize the product of the likelihood with the prior to ensure <span class="math notranslate nohighlight">\(x\)</span> is a probability distribution that sums to one.</p>
<p>We can express this in pseudocode.</p>
<p><strong>Initialization</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Initialize our belief in the state
</pre></div>
</div>
<p><strong>Predict</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Based on the system behavior, predict state for the next time step
2. Adjust belief to account for the uncertainty in prediction
</pre></div>
</div>
<p><strong>Update</strong></p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1. Get a measurement and associated belief about its accuracy
2. Compute how likely it is the measurement matches each state
3. Update state belief with this likelihood
</pre></div>
</div>
<p>When we cover the Kalman filter we will use this exact same algorithm; only the details of the computation will differ.</p>
<p>Algorithms in this form are sometimes called <em>predictor correctors</em>. We make a prediction, then correct them.</p>
<p>Letâ€™s animate this. First Letâ€™s write functions to perform the filtering and to plot the results at any step. Iâ€™ve plotted the position of the doorways in black. Prior are drawn in orange, and the posterior in blue. I draw a thick vertical line to indicate where Simon really is. This is not an output of the filter - we know where Simon is only because we are simulating his movement.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">discrete_bayes_sim</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">measurements</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">,</span> <span class="n">hallway</span><span class="p">):</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.1</span><span class="p">]</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">z</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measurements</span><span class="p">):</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
        <span class="n">priors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>

        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
        <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span>


<span class="k">def</span> <span class="nf">plot_posterior</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Posterior&#39;</span><span class="p">)</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">posteriors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">hallway</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>    
    
<span class="k">def</span> <span class="nf">plot_prior</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Prior&#39;</span><span class="p">)</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">priors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;#ff8015&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">hallway</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>    

<span class="k">def</span> <span class="nf">animate_discrete_bayes</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
        <span class="n">step</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">step</span> <span class="o">//</span> <span class="mi">2</span>    
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_prior</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plot_posterior</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">animate</span>
</pre></div>
</div>
</div>
</div>
<p>Letâ€™s run the filter and animate it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># change these numbers to alter the simulation</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">z_prob</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">hallway</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># measurements with no noise</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">hallway</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">hallway</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">)]</span>

<span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span> <span class="o">=</span> <span class="n">discrete_bayes_sim</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">zs</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">,</span> <span class="n">hallway</span><span class="p">)</span>
<span class="n">interact</span><span class="p">(</span><span class="n">animate_discrete_bayes</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5e52dc4ac04b4244ad4357a4fd837902", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Now we can see the results. You can see how the prior shifts the position and reduces certainty, and the posterior stays in the same position and increases certainty as it incorporates the information from the measurement. Iâ€™ve made the measurement perfect with the line <code class="docutils literal notranslate"><span class="pre">z_prob</span> <span class="pre">=</span> <span class="pre">1.0</span></code>; we will explore the effect of imperfect measurements in the next section. Finally,</p>
<p>Another thing to note is how accurate our estimate becomes when we are in front of a door, and how it degrades when in the middle of the hallway. This should make intuitive sense. There are only a few doorways, so when the sensor tells us we are in front of a door this boosts our certainty in our position. A long stretch of no doors reduces our certainty.</p>
</section>
<section id="the-effect-of-bad-sensor-data">
<h2>The Effect of Bad Sensor Data<a class="headerlink" href="#the-effect-of-bad-sensor-data" title="Permalink to this heading">#</a></h2>
<p>You may be suspicious of the results above because I always passed correct sensor data into the functions. However, we are claiming that this code implements a <em>filter</em> - it should filter out bad sensor measurements. Does it do that?</p>
<p>To make this easy to program and visualize I will change the layout of the hallway to mostly alternating doors and hallways, and run the algorithm on 6 correct measurements:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hallway</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">)</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">zs</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">z_prob</span> <span class="o">=</span> <span class="mf">0.75</span>
<span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span> <span class="o">=</span> <span class="n">discrete_bayes_sim</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">zs</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">,</span> <span class="n">hallway</span><span class="p">)</span>
<span class="n">interact</span><span class="p">(</span><span class="n">animate_discrete_bayes</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">),</span> <span class="n">step</span><span class="o">=</span><span class="n">IntSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "562f60dcb79f4651953d34fd40c1cab7", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>We have identified the likely cases of having started at position 0 or 5, because we saw this sequence of doors and walls: 1,0,1,0,0. Now I inject a bad measurement. The next measurement should be 0, but instead we get a 1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">priors</span><span class="p">,</span> <span class="n">posteriors</span> <span class="o">=</span> <span class="n">discrete_bayes_sim</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">measurements</span><span class="p">,</span> <span class="n">z_prob</span><span class="p">,</span> <span class="n">hallway</span><span class="p">);</span>
<span class="n">plot_posterior</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/5e49e6be2f0eeeafe5024e945518aca3acfc2443057eff3f2d9f13f9fc524083.png" src="../../../../_images/5e49e6be2f0eeeafe5024e945518aca3acfc2443057eff3f2d9f13f9fc524083.png" />
</div>
</div>
<p>That one bad measurement has significantly eroded our knowledge. Now letâ€™s continue with a series of correct measurements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">figsize</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">5.5</span><span class="p">):</span>
    <span class="n">measurements</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">measurements</span><span class="p">):</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">hallway</span><span class="p">,</span> <span class="n">z</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">z_prob</span><span class="o">=</span><span class="mf">.75</span><span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.4</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;step </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/251f1832a8b85bc48c2ca99d13f4f99f57893efd6ff3f4334750d3e4c3cbb83d.png" src="../../../../_images/251f1832a8b85bc48c2ca99d13f4f99f57893efd6ff3f4334750d3e4c3cbb83d.png" />
</div>
</div>
<p>We quickly filtered out the bad sensor reading and converged on the most likely positions for our dog.</p>
</section>
<section id="drawbacks-and-limitations">
<h2>Drawbacks and Limitations<a class="headerlink" href="#drawbacks-and-limitations" title="Permalink to this heading">#</a></h2>
<p>Do not be mislead by the simplicity of the examples I chose. This is a robust and complete filter, and you may use the code in real world solutions. If you need a multimodal, discrete filter, this filter works.</p>
<p>With that said, this filter it is not used often because it has several limitations. Getting around those limitations is the motivation behind the chapters in the rest of this book.</p>
<p>The first problem is scaling. Our dog tracking problem used only one variable, <span class="math notranslate nohighlight">\(pos\)</span>, to denote the dogâ€™s position. Most interesting problems will want to track several things in a large space. Realistically, at a minimum we would want to track our dogâ€™s <span class="math notranslate nohighlight">\((x,y)\)</span> coordinate, and probably his velocity <span class="math notranslate nohighlight">\((\dot{x},\dot{y})\)</span> as well. We have not covered the multidimensional case, but instead of an array we use a multidimensional grid to store the probabilities at each discrete location. Each <code class="docutils literal notranslate"><span class="pre">update()</span></code> and <code class="docutils literal notranslate"><span class="pre">predict()</span></code> step requires updating all values in the grid, so a simple four variable problem would require <span class="math notranslate nohighlight">\(O(n^4)\)</span> running time <em>per time step</em>. Realistic filters can have 10 or more variables to track, leading to exorbitant computation requirements.</p>
<p>The second problem is that the filter is discrete, but we live in a continuous world. The histogram requires that you model the output of your filter as a set of discrete points. A 100 meter hallway requires 10,000 positions to model the hallway to 1cm accuracy. So each update and predict operation would entail performing calculations for 10,000 different probabilities. It gets exponentially worse as we add dimensions. A 100x100 m<span class="math notranslate nohighlight">\(^2\)</span> courtyard requires 100,000,000 bins to get 1cm accuracy.</p>
<p>A third problem is that the filter is multimodal. In the last example we ended up with strong beliefs that the dog was in position 4 or 9. This is not always a problem. Particle filters, which we will study later, are multimodal and are often used because of this property. But imagine if the GPS in your car reported to you that it is 40% sure that you are on D street, and 30% sure you are on Willow Avenue.</p>
<p>A forth problem is that it requires a measurement of the change in state. We need a motion sensor to detect how much the dog moves. There are ways to work around this problem, but it would complicate the exposition of this chapter, so, given the aforementioned problems, I will not discuss it further.</p>
<p>With that said, if I had a small problem that this technique could handle I would choose to use it; it is trivial to implement, debug, and understand, all virtues.</p>
</section>
<section id="tracking-and-control">
<h2>Tracking and Control<a class="headerlink" href="#tracking-and-control" title="Permalink to this heading">#</a></h2>
<p>We have been passively tracking an autonomously moving object. But consider this very similar problem. I am automating a warehouse and want to use robots to collect all of the items for a customerâ€™s order. Perhaps the easiest way to do this is to have the robots travel on a train track. I want to be able to send the robot a destination and have it go there. But train tracks and robot motors are imperfect. Wheel slippage and imperfect motors means that the robot is unlikely to travel to exactly the position you command. There is more than one robot, and we need to know where they all are so we do not cause them to crash.</p>
<p>So we add sensors. Perhaps we mount magnets on the track every few feet, and use a Hall sensor to count how many magnets are passed. If we count 10 magnets then the robot should be at the 10th magnet. Of course it is possible to either miss a magnet or to count it twice, so we have to accommodate some degree of error. We can use the code from the previous section to track our robot since magnet counting is very similar to doorway sensing.</p>
<p>But we are not done. Weâ€™ve learned to never throw information away. If you have information you should use it to improve your estimate. What information are we leaving out? We know what control inputs we are feeding to the wheels of the robot at each moment in time. For example, letâ€™s say that once a second we send a movement command to the robot - move left 1 unit, move right 1 unit, or stand still.  If I send the command â€˜move left 1 unitâ€™ I expect that in one second from now the robot will be 1 unit to the left of where it is now. This is a simplification because I am not taking acceleration into account, but I am not trying to teach control theory. Wheels and motors are imperfect. The robot might end up 0.9 units away, or maybe 1.2 units.</p>
<p>Now the entire solution is clear. We assumed that the dog kept moving in whatever direction he was previously moving. That is a dubious assumption for my dog! Robots are far more predictable. Instead of making a dubious prediction based on assumption of behavior we will feed in the command that we sent to the robot! In other words, when we call <code class="docutils literal notranslate"><span class="pre">predict()</span></code> we will pass in the commanded movement that we gave the robot along with a kernel that describes the likelihood  of that movement.</p>
<section id="simulating-the-train-behavior">
<h3>Simulating the Train Behavior<a class="headerlink" href="#simulating-the-train-behavior" title="Permalink to this heading">#</a></h3>
<p>We need to simulate an imperfect train. When we command it to move it will sometimes make a small mistake, and its sensor will sometimes return the incorrect value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Train</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">track_len</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span> <span class="n">sensor_accuracy</span><span class="o">=</span><span class="mf">.9</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">track_len</span> <span class="o">=</span> <span class="n">track_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensor_accuracy</span> <span class="o">=</span> <span class="n">sensor_accuracy</span>

    <span class="k">def</span> <span class="nf">move</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distance</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot; move in the specified direction</span>
<span class="sd">        with some small chance of error&quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">+=</span> <span class="n">distance</span>
        <span class="c1"># insert random movement error according to kernel</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">:</span>
            <span class="n">s</span> <span class="o">+=</span> <span class="n">k</span>
            <span class="k">if</span> <span class="n">r</span> <span class="o">&lt;=</span> <span class="n">s</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">offset</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">track_len</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span>

    <span class="k">def</span> <span class="nf">sense</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pos</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span>
         <span class="c1"># insert random sensor error</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sensor_accuracy</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
                <span class="n">pos</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pos</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">pos</span>
</pre></div>
</div>
</div>
</div>
<p>With that we are ready to write the filter. We will put it in a function so that we can run it with different assumptions. I will assume that the robot always starts at the beginning of the track. The track is implemented as being 10 units long, but think of it as a track of length, say 10,000, with the magnet pattern repeated every 10 units. A length of 10 makes it easier to plot and inspect.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_filter</span><span class="p">(</span><span class="n">iterations</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">sensor_accuracy</span><span class="p">,</span> 
             <span class="n">move_distance</span><span class="p">,</span> <span class="n">do_print</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">track</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">.9</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">]</span><span class="o">*</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">prior</span><span class="p">[:]</span>
    <span class="n">normalize</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
    
    <span class="n">robot</span> <span class="o">=</span> <span class="n">Train</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">track</span><span class="p">),</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">sensor_accuracy</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
        <span class="c1"># move the robot and</span>
        <span class="n">robot</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">distance</span><span class="o">=</span><span class="n">move_distance</span><span class="p">)</span>

        <span class="c1"># peform prediction</span>
        <span class="n">prior</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">move_distance</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>       

        <span class="c1">#  and update the filter</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">robot</span><span class="o">.</span><span class="n">sense</span><span class="p">()</span>
        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">lh_hallway</span><span class="p">(</span><span class="n">track</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">sensor_accuracy</span><span class="p">)</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">do_print</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;time </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: pos </span><span class="si">{</span><span class="n">robot</span><span class="o">.</span><span class="n">pos</span><span class="si">}</span><span class="s1">, sensed </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">, at position </span><span class="si">{</span><span class="n">track</span><span class="p">[</span><span class="n">robot</span><span class="o">.</span><span class="n">pos</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">conf</span> <span class="o">=</span> <span class="n">posterior</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;        estimated position is </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> with confidence </span><span class="si">{</span><span class="n">conf</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">%:&#39;</span><span class="p">)</span>            

    <span class="n">book_plots</span><span class="o">.</span><span class="n">bar_plot</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">do_print</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;final position is&#39;</span><span class="p">,</span> <span class="n">robot</span><span class="o">.</span><span class="n">pos</span><span class="p">)</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;Estimated position is </span><span class="si">{}</span><span class="s1"> with &#39;&#39;&#39;</span>
<span class="w">              </span><span class="sd">&#39;&#39;&#39;confidence {:.4f}%:&#39;&#39;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">index</span><span class="p">,</span> <span class="n">posterior</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Read the code and make sure you understand it. Now letâ€™s do a run with no sensor or movement error. If the code is correct it should be able to locate the robot with no error. The output is a bit tedious to read, but if you are at all unsure of how the update/predict cycle works make sure you read through it carefully to solidify your understanding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">train_filter</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">1.</span><span class="p">],</span> <span class="n">sensor_accuracy</span><span class="o">=</span><span class="mf">.999</span><span class="p">,</span>
             <span class="n">move_distance</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">do_print</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>time 0: pos 4, sensed 4, at position 4
        estimated position is 4 with confidence 99.9900%:
time 1: pos 8, sensed 8, at position 8
        estimated position is 8 with confidence 100.0000%:
time 2: pos 2, sensed 2, at position 2
        estimated position is 2 with confidence 100.0000%:
time 3: pos 6, sensed 6, at position 6
        estimated position is 6 with confidence 100.0000%:

final position is 6
Estimated position is 6 with confidence 100.0000%:
</pre></div>
</div>
<img alt="../../../../_images/adb9a429b1166e77ddee4a82749b42386c30ef44978100f89d6fb5157cf0f260.png" src="../../../../_images/adb9a429b1166e77ddee4a82749b42386c30ef44978100f89d6fb5157cf0f260.png" />
</div>
</div>
<p>We can see that the code was able to perfectly track the robot so we should feel reasonably confident that the code is working. Now letâ€™s see how it fairs with some errors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">train_filter</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">],</span> <span class="n">sensor_accuracy</span><span class="o">=</span><span class="mf">.9</span><span class="p">,</span>
         <span class="n">move_distance</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">do_print</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>time 0: pos 4, sensed 4, at position 4
        estimated position is 4 with confidence 96.0390%:
time 1: pos 8, sensed 9, at position 8
        estimated position is 9 with confidence 52.1180%:
time 2: pos 3, sensed 3, at position 3
        estimated position is 3 with confidence 88.3993%:
time 3: pos 7, sensed 8, at position 7
        estimated position is 8 with confidence 49.3174%:

final position is 7
Estimated position is 8 with confidence 49.3174%:
</pre></div>
</div>
<img alt="../../../../_images/c85b3063b8ccd6c85d89266258cfeecafa9a296e1fcaeb7dc3d900d190fc8950.png" src="../../../../_images/c85b3063b8ccd6c85d89266258cfeecafa9a296e1fcaeb7dc3d900d190fc8950.png" />
</div>
</div>
<p>There was a sensing error at time 1, but we are still quite confident in our position.</p>
<p>Now letâ€™s run a very long simulation and see how the filter responds to errors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">figsize</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">5.5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="o">+</span><span class="n">i</span><span class="p">)</span>
        <span class="n">train_filter</span><span class="p">(</span><span class="mi">148</span><span class="o">+</span><span class="n">i</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.8</span><span class="p">,</span> <span class="mf">.1</span><span class="p">],</span> 
                     <span class="n">sensor_accuracy</span><span class="o">=</span><span class="mf">.8</span><span class="p">,</span>
                     <span class="n">move_distance</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">do_print</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;iteration </span><span class="si">{</span><span class="mi">148</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/f4dd2bae08aca189c6aee80a411e2bfeb3f1d887fcc93731b2a8f0f919e0da02.png" src="../../../../_images/f4dd2bae08aca189c6aee80a411e2bfeb3f1d887fcc93731b2a8f0f919e0da02.png" />
</div>
</div>
<p>We can see that there was a problem on iteration 149 as the confidence degrades. But within a few iterations the filter is able to correct itself and regain confidence in the estimated position.</p>
</section>
</section>
<section id="bayes-theorem-and-the-total-probability-theorem">
<h2>Bayes Theorem and the Total Probability Theorem<a class="headerlink" href="#bayes-theorem-and-the-total-probability-theorem" title="Permalink to this heading">#</a></h2>
<p>We developed the math in this chapter merely by reasoning about the information we have at each moment. In the process we discovered <a class="reference external" href="https://en.wikipedia.org/wiki/Bayes%27_theorem"><em>Bayesâ€™ Theorem</em></a> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Law_of_total_probability"><em>Total Probability Theorem</em></a>.</p>
<p>Bayes theorem tells us how to compute the probability of an event given previous information.</p>
<p>We implemented the <code class="docutils literal notranslate"><span class="pre">update()</span></code> function with this probability calculation:</p>
<div class="math notranslate nohighlight">
\[ \mathtt{posterior} = \frac{\mathtt{likelihood}\times \mathtt{prior}}{\mathtt{normalization\, factor}}\]</div>
<p>We havenâ€™t developed the mathematics to discuss Bayes yet, but this is Bayesâ€™ theorem. Every filter in this book is an expression of Bayesâ€™ theorem. In the next chapter we will develop the mathematics, but in many ways that obscures the simple idea expressed in this equation:</p>
<div class="math notranslate nohighlight">
\[ updated\,knowledge = \big\|likelihood\,of\,new\,knowledge\times prior\, knowledge \big\|\]</div>
<p>where <span class="math notranslate nohighlight">\(\| \cdot\|\)</span> expresses normalizing the term.</p>
<p>We came to this with simple reasoning about a dog walking down a hallway. Yet, as we will see the same equation applies to a universe of filtering problems. We will use this equation in every subsequent chapter.</p>
<p>Likewise, the <code class="docutils literal notranslate"><span class="pre">predict()</span></code> step computes the total probability of multiple possible events. This is known as the <em>Total Probability Theorem</em> in statistics, and we will also cover this in the next chapter after developing some supporting math.</p>
<p>For now I need you to understand that Bayesâ€™ theorem is a formula to incorporate new information into existing information.</p>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<p>The code is very short, but the result is impressive! We have implemented a form of a Bayesian filter. We have learned how to start with no information and derive information from noisy sensors. Even though the sensors in this chapter are very noisy (most sensors are more than 80% accurate, for example) we quickly converge on the most likely position for our dog. We have learned how the predict step always degrades our knowledge, but the addition of another measurement, even when it might have noise in it, improves our knowledge, allowing us to converge on the most likely result.</p>
<p>This book is mostly about the Kalman filter. The math it uses is different, but the logic is exactly the same as used in this chapter. It uses Bayesian reasoning to form estimates from a combination of measurements and process models.</p>
<p><strong>If you can understand this chapter you will be able to understand and implement Kalman filters.</strong> I cannot stress this enough. If anything is murky, go back and reread this chapter and play with the code. The rest of this book will build on the algorithms that we use here. If you donâ€™t understand why this filter works you will have little success with the rest of the material. However, if you grasp the fundamental insight - multiplying probabilities when we measure, and shifting probabilities when we update leads to a converging solution - then after learning a bit of math you are ready to implement a Kalman filter.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>[1] D. Fox, W. Burgard, and S. Thrun. â€œMonte carlo localization: Efficient position estimation for mobile robots.â€ In <em>Journal of Artifical Intelligence Research</em>, 1999.</p></li>
</ul>
<p><a class="reference external" href="http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/fox99a-html/jair-localize.html">http://www.cs.cmu.edu/afs/cs/project/jair/pub/volume11/fox99a-html/jair-localize.html</a></p>
<ul class="simple">
<li><p>[2] Dieter Fox, et. al. â€œBayesian Filters for Location Estimationâ€. In <em>IEEE Pervasive Computing</em>, September 2003.</p></li>
</ul>
<p><a class="reference external" href="http://swarmlab.unimaas.nl/wp-content/uploads/2012/07/fox2003bayesian.pdf">http://swarmlab.unimaas.nl/wp-content/uploads/2012/07/fox2003bayesian.pdf</a></p>
<ul class="simple">
<li><p>[3] Sebastian Thrun. â€œArtificial Intelligence for Roboticsâ€.</p></li>
</ul>
<p><a class="reference external" href="https://www.udacity.com/course/cs373">https://www.udacity.com/course/cs373</a></p>
<ul class="simple">
<li><p>[4] Khan Acadamy. â€œIntroduction to the Convolutionâ€</p></li>
</ul>
<p><a class="reference external" href="https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution">https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution</a></p>
<ul class="simple">
<li><p>[5] Wikipedia. â€œConvolutionâ€</p></li>
</ul>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/Convolution">http://en.wikipedia.org/wiki/Convolution</a></p>
<ul>
<li><p>[6] Wikipedia. â€œLaw of total probabilityâ€</p>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/Law_of_total_probability">http://en.wikipedia.org/wiki/Law_of_total_probability</a></p>
</li>
<li><p>[7] Wikipedia. â€œTime Evolutionâ€</p></li>
</ul>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Time_evolution">https://en.wikipedia.org/wiki/Time_evolution</a></p>
<ul class="simple">
<li><p>[8] We need to rethink how we teach statistics from the ground up</p></li>
</ul>
<p><a class="reference external" href="http://www.statslife.org.uk/opinion/2405-we-need-to-rethink-how-we-teach-statistics-from-the-ground-up">http://www.statslife.org.uk/opinion/2405-we-need-to-rethink-how-we-teach-statistics-from-the-ground-up</a></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/artificial-intelligence",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/rse/discrete-bayesian-filter"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../recursive-state-estimation/index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Recursive State Estimation</p>
      </div>
    </a>
    <a class="right-next"
       href="../hmm-localization/_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Localization and Tracking</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-a-dog">Tracking a Dog</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extracting-information-from-sensor-readings">Extracting Information from Sensor Readings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#noisy-sensors">Noisy Sensors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-movement">Incorporating Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology">Terminology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-uncertainty-to-the-prediction">Adding Uncertainty to the Prediction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalizing-with-convolution">Generalizing with Convolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integrating-measurements-and-movement-updates">Integrating Measurements and Movement Updates</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-discrete-bayes-algorithm">The Discrete Bayes Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-effect-of-bad-sensor-data">The Effect of Bad Sensor Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drawbacks-and-limitations">Drawbacks and Limitations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-and-control">Tracking and Control</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulating-the-train-behavior">Simulating the Train Behavior</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-theorem-and-the-total-probability-theorem">Bayes Theorem and the Total Probability Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>