

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Word2Vec Workshop &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/nlp/word2vec/word2vec-workshop';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/lms/aiml-common/lectures/nlp/word2vec/word2vec-workshop.html" />
    <link rel="shortcut icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="RNN Language Models" href="../language-models/_index.html" />
    <link rel="prev" title="Word2Vec Embeddings" href="_index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../syllabus/_index.html">
                        Syllabus
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/course-introduction/_index.html">
                        Course Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/data-science-360/_index.html">
                        Data Science 360
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/systems-approach/_index.html">
                        The four approaches towards AI
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/agents/_index.html">
                        Agent-Environment Interface
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/pipelines/_index.html">
                        ML Pipelines
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../learning-problem/_index.html">
                        The Learning Problem
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../regression/linear-regression/linear_regression.html">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/sgd/_index.html">
                        Stochastic Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../entropy/_index.html">
                        Entropy
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">
                        Maximum Likelihood Estimation of a marginal model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">
                        Maximum Likelihood (ML) Estimation of conditional models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/classification-intro/_index.html">
                        Introduction to Classification
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/logistic-regression/_index.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-inference/_index.html">
                        Bayesian Inference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-inference/bayesian_regression.html">
                        Bayesian Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-coin/bayesian_update_coin_flip.html">
                        Posterior updates in a coin flipping experiment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/perceptron/_index.html">
                        The Neuron (Perceptron)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/dnn-intro/_index.html">
                        Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-intro/_index.html">
                        Introduction to Backpropagation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-dnn/_index.html">
                        Backpropagation in Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-dnn-exercises/_index.html">
                        Backpropagation DNN exercises
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/fashion-mnist-case-study.html">
                        Fashion MNIST Case Study
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/regularization/_index.html">
                        Regularization in Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/regularization/regularization-workshop-1.html">
                        Regularization Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-intro/_index.html">
                        Introduction to Convolutional Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-layers/_index.html">
                        CNN Architectures
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/_index.html">
                        CNN Example Architectures
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
                        Using convnets with small datasets
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">
                        Visualizing what convnets learn
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-explainers/gradcam.html">
                        CNN Explainers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../transfer-learning/transfer-learning-introduction.html">
                        Introduction to Transfer Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../transfer-learning/transfer_learning_tutorial.html">
                        Transfer Learning for Computer Vision Tutorial
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/scene-understanding-intro/index.html">
                        Introduction to Scene Understanding
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/feature-extraction-resnet/index.html">
                        Feature Extraction via Residual Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">
                        Object Detection
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/semantic-segmentation/index.html">
                        Semantic Segmentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/pgm-intro/_index.html">
                        Introduction to Probabilistic Reasoning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/recursive-state-estimation/_index.html">
                        Recursive State Estimation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-filter-workshop/_index.html">
                        Bayesian Filter Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/hmm-localization/_index.html">
                        Localization and Tracking
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/kalman-workshop/_index.html">
                        Kalman Filter Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/automated-reasoning/_index.html">
                        Automated Reasoning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/propositional-logic/_index.html">
                        World Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/logical-agents/_index.html">
                        Logical Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/_index.html">
                        Planning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../autonomous-cars/_index.html">
                        Autonomous Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../autonomous-cars/imitation-learning/_index.html">
                        Imitation Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/classical-planning/_index.html">
                        Classical Planning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/_index.html">
                        Planning with Search
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/forward-search/_index.html">
                        Forward Search Algorithms
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/a-star/_index.html">
                        The A* Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/_index.html">
                        Markov Decision Processes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/mdp-intro/_index.html">
                        Introduction to MDP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/bellman-expectation-backup/_index.html">
                        Bellman Expectation Backup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/bellman-optimality-backup/_index.html">
                        MDP Dynamic Programming Algorithms
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/_index.html">
                        Reinforcement Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/prediction/monte-carlo.html">
                        Monte-Carlo Prediction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/prediction/temporal-difference.html">
                        Temporal Difference (TD) Prediction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/control/_index.html">
                        Model-free Control
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/generalized-policy-iteration/_index.html">
                        Generalized Policy Iteration
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/control/sarsa/_index.html">
                        The SARSA Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/reinforce/_index.html">
                        The REINFORCE Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/introduction/_index.html">
                        Introduction to Recurrent Neural Networks (RNN)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/simple-rnn/_index.html">
                        Simple RNN
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/lstm/_index.html">
                        The Long Short-Term Memory (LSTM) Cell Architecture
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/15_processing_sequences_using_rnns_and_cnns.html">
                        Processing Sequences Using RNN
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nlp-intro/_index.html">
                        Introduction to NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="_index.html">
                        Word2Vec Embeddings
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Word2Vec Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/_index.html">
                        RNN Language Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/simple-rnn-language-model.html">
                        Simple RNN Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/cnn-language-model.html">
                        CNN Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nmt/_index.html">
                        Neural Machine Translation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nmt-metrics/_index.html">
                        NMT Metrics - BLEU
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../attention/_index.html">
                        Attention in NMT
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../transformers/_index.html">
                        Transformers Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/index.html">
                        Math for ML Textbook
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/probability/index.html">
                        Probability Basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/linear-algebra/index.html">
                        Linear Algebra for Machine Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/calculus/index.html">
                        Calculus
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/index.html">
                        Your Programming Environment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/assignment-submission.html">
                        Submitting Your Assignment / Project
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../python/index.html">
                        Learn Python
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/notebook-status.html">
                        Notebook execution status
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/probability/probability-assignment-5/index.html">
                        Probability Assignment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/mle/mle-gaussian.html">
                        Gaussian Maximum Likelihood
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/mle/poisson-regression-1/index.html">
                        Bike Rides and the Poisson Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../projects/nlp/finetuning-language-models-tweets/index.html">
                        Finetuning Language Models - Toxic Tweets
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/logistic-regression-1/index.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../projects/nlp/finetuning-language-models-patents/index.html">
                        Finetuning Language Models - Can I Patent This?
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../../syllabus/_index.html">
                        Syllabus
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/course-introduction/_index.html">
                        Course Introduction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/data-science-360/_index.html">
                        Data Science 360
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/systems-approach/_index.html">
                        The four approaches towards AI
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/agents/_index.html">
                        Agent-Environment Interface
                      </a>
                    </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ai-intro/pipelines/_index.html">
                        ML Pipelines
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../learning-problem/_index.html">
                        The Learning Problem
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../regression/linear-regression/linear_regression.html">
                        Linear Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/sgd/_index.html">
                        Stochastic Gradient Descent
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../entropy/_index.html">
                        Entropy
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">
                        Maximum Likelihood Estimation of a marginal model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">
                        Maximum Likelihood (ML) Estimation of conditional models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/classification-intro/_index.html">
                        Introduction to Classification
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/logistic-regression/_index.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-inference/_index.html">
                        Bayesian Inference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-inference/bayesian_regression.html">
                        Bayesian Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-coin/bayesian_update_coin_flip.html">
                        Posterior updates in a coin flipping experiment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../classification/perceptron/_index.html">
                        The Neuron (Perceptron)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/dnn-intro/_index.html">
                        Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-intro/_index.html">
                        Introduction to Backpropagation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-dnn/_index.html">
                        Backpropagation in Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/backprop-dnn-exercises/_index.html">
                        Backpropagation DNN exercises
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../dnn/fashion-mnist-case-study.html">
                        Fashion MNIST Case Study
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/regularization/_index.html">
                        Regularization in Deep Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../optimization/regularization/regularization-workshop-1.html">
                        Regularization Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-intro/_index.html">
                        Introduction to Convolutional Neural Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-layers/_index.html">
                        CNN Architectures
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/_index.html">
                        CNN Example Architectures
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">
                        Using convnets with small datasets
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">
                        Visualizing what convnets learn
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../cnn/cnn-explainers/gradcam.html">
                        CNN Explainers
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../transfer-learning/transfer-learning-introduction.html">
                        Introduction to Transfer Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../transfer-learning/transfer_learning_tutorial.html">
                        Transfer Learning for Computer Vision Tutorial
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/scene-understanding-intro/index.html">
                        Introduction to Scene Understanding
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/feature-extraction-resnet/index.html">
                        Feature Extraction via Residual Networks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">
                        Object Detection
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../scene-understanding/semantic-segmentation/index.html">
                        Semantic Segmentation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/pgm-intro/_index.html">
                        Introduction to Probabilistic Reasoning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/recursive-state-estimation/_index.html">
                        Recursive State Estimation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/bayesian-filter-workshop/_index.html">
                        Bayesian Filter Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/hmm-localization/_index.html">
                        Localization and Tracking
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../pgm/kalman-workshop/_index.html">
                        Kalman Filter Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/automated-reasoning/_index.html">
                        Automated Reasoning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/propositional-logic/_index.html">
                        World Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../logical-reasoning/logical-agents/_index.html">
                        Logical Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/_index.html">
                        Planning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../autonomous-cars/_index.html">
                        Autonomous Agents
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../autonomous-cars/imitation-learning/_index.html">
                        Imitation Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/classical-planning/_index.html">
                        Classical Planning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/_index.html">
                        Planning with Search
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/forward-search/_index.html">
                        Forward Search Algorithms
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../planning/search/a-star/_index.html">
                        The A* Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/_index.html">
                        Markov Decision Processes
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/mdp-intro/_index.html">
                        Introduction to MDP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/bellman-expectation-backup/_index.html">
                        Bellman Expectation Backup
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../mdp/bellman-optimality-backup/_index.html">
                        MDP Dynamic Programming Algorithms
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/_index.html">
                        Reinforcement Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/prediction/monte-carlo.html">
                        Monte-Carlo Prediction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/prediction/temporal-difference.html">
                        Temporal Difference (TD) Prediction
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/control/_index.html">
                        Model-free Control
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/generalized-policy-iteration/_index.html">
                        Generalized Policy Iteration
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/control/sarsa/_index.html">
                        The SARSA Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../reinforcement-learning/reinforce/_index.html">
                        The REINFORCE Algorithm
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/introduction/_index.html">
                        Introduction to Recurrent Neural Networks (RNN)
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/simple-rnn/_index.html">
                        Simple RNN
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/lstm/_index.html">
                        The Long Short-Term Memory (LSTM) Cell Architecture
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../rnn/15_processing_sequences_using_rnns_and_cnns.html">
                        Processing Sequences Using RNN
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nlp-intro/_index.html">
                        Introduction to NLP
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="_index.html">
                        Word2Vec Embeddings
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="#">
                        Word2Vec Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/_index.html">
                        RNN Language Models
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/simple-rnn-language-model.html">
                        Simple RNN Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../language-models/cnn-language-model.html">
                        CNN Language Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nmt/_index.html">
                        Neural Machine Translation
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../nmt-metrics/_index.html">
                        NMT Metrics - BLEU
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../attention/_index.html">
                        Attention in NMT
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../transformers/_index.html">
                        Transformers Workshop
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/index.html">
                        Math for ML Textbook
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/probability/index.html">
                        Probability Basics
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/linear-algebra/index.html">
                        Linear Algebra for Machine Learning
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../ml-math/calculus/index.html">
                        Calculus
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/index.html">
                        Your Programming Environment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/assignment-submission.html">
                        Submitting Your Assignment / Project
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../python/index.html">
                        Learn Python
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../resources/environment/notebook-status.html">
                        Notebook execution status
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/probability/probability-assignment-5/index.html">
                        Probability Assignment
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/mle/mle-gaussian.html">
                        Gaussian Maximum Likelihood
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/mle/poisson-regression-1/index.html">
                        Bike Rides and the Poisson Model
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../projects/nlp/finetuning-language-models-tweets/index.html">
                        Finetuning Language Models - Toxic Tweets
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../assignments/logistic-regression-1/index.html">
                        Logistic Regression
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../projects/nlp/finetuning-language-models-patents/index.html">
                        Finetuning Language Models - Can I Patent This?
                      </a>
                    </li>
                
                </div>
            </div>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../intro.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page">Word2Vec Workshop</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="word2vec-workshop">
<h1>Word2Vec Workshop<a class="headerlink" href="#word2vec-workshop" title="Permalink to this headline">#</a></h1>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following example is from <a class="reference external" href="https://iksinc.online/tag/skip-gram-model/">here</a>.</p>
</div>
<p>Consider the training corpus having the following sentences:</p>
<p>the dog saw a cat,</p>
<p>the dog chased the cat,</p>
<p>the cat climbed a tree</p>
<p>In this corpus <span class="math notranslate nohighlight">\(V=8\)</span> and we are interested in creating word embeddings of order <span class="math notranslate nohighlight">\(d=3\)</span>. The parameter matrices are randomly initialized as</p>
<div class="math notranslate nohighlight">
\[\begin{split}W = \begin{bmatrix} 0.54 &amp;  0.28 &amp;  0.42\\0.84 &amp;  0.00 &amp;  0.12\\ 0.67 &amp;  0.83 &amp;  0.14\\0.58 &amp;  0.89 &amp;  0.21\\0.19 &amp;  0.11 &amp;  0.22\\0.98 &amp;  0.81 &amp;  0.17\\0.82 &amp;  0.27 &amp;  0.43\\0.94 &amp;  0.82 &amp;  0.34
\end{bmatrix}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split} W^\prime = \begin{bmatrix}0.18 &amp;  0.37 &amp;  0.01 &amp;  0.25 &amp;  0.80 &amp;  0.02 &amp;  0.60 &amp;  0.60\\0.11 &amp;  0.38 &amp;  0.04 &amp;  0.89 &amp;  0.98 &amp;  0.06 &amp;  0.89 &amp;  0.58\\0.74 &amp;  0.63 &amp;  0.58 &amp;  0.02 &amp;  0.21 &amp;  0.54 &amp;  0.77 &amp;  0.25
\end{bmatrix}\end{split}\]</div>
<p><strong>Suppose we want the network to learn relationship between the words cat and climbed. That is, the network should show a high probability for cat when climbed is presented at the input of the network.</strong> In word embedding terminology, the word cat is referred as the target word and the word climbed is referred as the context word. In this case, the input vector <span class="math notranslate nohighlight">\(\mathbf x_{t+1}  =  [0 0 0 1 0 0 0 0]^T\)</span>. Notice that only the 4th component of the vector is 1 - the input word climbed holds for example the 4th position in a sorted list of corpus words. Given that the target word is cat, the target vector will be <span class="math notranslate nohighlight">\(\mathbf x_t = [0 1 0 0 0 0 0 0 ]^T\)</span>.</p>
<p>With the input vector representing climbed, the output at the hidden layer neurons can be computed as</p>
<div class="math notranslate nohighlight">
\[\mathbf z_t^T = \mathbf x_{t+j}^T \mathbf W = \begin{bmatrix}
  0.58 &amp;  0.89 &amp;  0.21
\end{bmatrix}, j=1\]</div>
<p>Carrying out similar manipulations for hidden to output layer, the activation vector for output layer neurons can be written as</p>
<div class="math notranslate nohighlight">
\[\mathbf z^\prime_j = \mathbf z_t^T \mathbf W^\prime =\begin{bmatrix}
  0.35 &amp;  0.69 &amp;  0.16 &amp;  0.94 &amp;  1.38 &amp;  0.18 &amp;  1.30 &amp;  0.91
\end{bmatrix}\]</div>
<p>Since the goal is produce probabilities for words in the output layer,  <span class="math notranslate nohighlight">\(p(w_{t+j} | w_t; \theta)\)</span> to reflect their next word relationship with the context word at input, we need the sum of neuron outputs in the output layer to add to one. This can be achieved with the softmax</p>
<div class="math notranslate nohighlight">
\[\hat{\mathbf y}_j = \mathtt{softmax}(\mathbf z^\prime_j), j=1\]</div>
<p>Thus, the probabilities for eight words in the corpus are:</p>
<div class="math notranslate nohighlight">
\[\hat{\mathbf y} = \begin{bmatrix}
  0.35 &amp;  \mathbf{0.69} &amp;  0.16 &amp;  0.94 &amp;  1.38 &amp;  0.18 &amp;  1.30 &amp;  0.91
\end{bmatrix}\]</div>
<p>The probability in bold is for the chosen target word cat. Given the target vector [0 1 0 0 0 0 0 0 ], the error vector for the output layer is easily computed via CE loss. Once the loss is known, the weights in the matrices W can be updated using backpropagation. Thus, the training can proceed by presenting different context-target words pairs from the corpus. The context can be more than one word and in this case the loss is the average loss across all pairs.</p>
</section>
<section id="from-scratch">
<h2>From scratch<a class="headerlink" href="#from-scratch" title="Permalink to this headline">#</a></h2>
<p>This <a class="reference external" href="https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy">self-contained implementation</a> is instructive and you should <a class="reference external" href="https://github.com/nathanrooy/word2vec-from-scratch-with-python/blob/master/word2vec.py">go through it</a> to understand the word2vec embedding.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#   Nathan A. Rooy</span>
<span class="c1">#   Simple word2vec from scratch with Python</span>
<span class="c1">#   2018-FEB</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>



<span class="k">class</span> <span class="nc">word2vec</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span> <span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;window_size&#39;</span><span class="p">]</span>
        <span class="k">pass</span>
    
    
    <span class="c1"># GENERATE TRAINING DATA</span>
    <span class="k">def</span> <span class="nf">generate_training_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">settings</span><span class="p">,</span> <span class="n">corpus</span><span class="p">):</span>

        <span class="c1"># GENERATE WORD COUNTS</span>
        <span class="n">word_counts</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">row</span><span class="p">:</span>
                <span class="n">word_counts</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">v_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="c1"># GENERATE LOOKUP DICTIONARIES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">words_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">word_counts</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span><span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">word</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">words_list</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_word</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">words_list</span><span class="p">))</span>

        <span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># CYCLE THROUGH EACH SENTENCE IN CORPUS</span>
        <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
            <span class="n">sent_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>

            <span class="c1"># CYCLE THROUGH EACH WORD IN SENTENCE</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
                
                <span class="c1">#w_target  = sentence[i]</span>
                <span class="n">w_target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2onehot</span><span class="p">(</span><span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                <span class="c1"># CYCLE THROUGH CONTEXT WINDOW</span>
                <span class="n">w_context</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">j</span><span class="o">!=</span><span class="n">i</span> <span class="ow">and</span> <span class="n">j</span><span class="o">&lt;=</span><span class="n">sent_len</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">j</span><span class="o">&gt;=</span><span class="mi">0</span><span class="p">:</span>
                        <span class="n">w_context</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">word2onehot</span><span class="p">(</span><span class="n">sentence</span><span class="p">[</span><span class="n">j</span><span class="p">]))</span>
                <span class="n">training_data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">w_target</span><span class="p">,</span> <span class="n">w_context</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>


    <span class="c1"># SOFTMAX ACTIVATION FUNCTION</span>
    <span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">e_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">e_x</span> <span class="o">/</span> <span class="n">e_x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


    <span class="c1"># CONVERT WORD TO ONE HOT ENCODING</span>
    <span class="k">def</span> <span class="nf">word2onehot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="n">word_vec</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_count</span><span class="p">)]</span>
        <span class="n">word_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">word_vec</span><span class="p">[</span><span class="n">word_index</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">word_vec</span>


    <span class="c1"># FORWARD PASS</span>
    <span class="k">def</span> <span class="nf">forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">y_c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">u</span>
                

    <span class="c1"># BACKPROPAGATION</span>
    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">dl_dw2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>  
        <span class="n">dl_dw1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

        <span class="c1"># UPDATE WEIGHTS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">dl_dw1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eta</span> <span class="o">*</span> <span class="n">dl_dw2</span><span class="p">)</span>
        <span class="k">pass</span>


    <span class="c1"># TRAIN W2V model</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">):</span>
        <span class="c1"># INITIALIZE WEIGHT MATRICES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_count</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>     <span class="c1"># embedding matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_count</span><span class="p">))</span>     <span class="c1"># context matrix</span>
        
        <span class="c1"># CYCLE THROUGH EACH EPOCH</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># CYCLE THROUGH EACH TRAINING SAMPLE</span>
            <span class="k">for</span> <span class="n">w_t</span><span class="p">,</span> <span class="n">w_c</span> <span class="ow">in</span> <span class="n">training_data</span><span class="p">:</span>

                <span class="c1"># FORWARD PASS</span>
                <span class="n">y_pred</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">w_t</span><span class="p">)</span>
                
                <span class="c1"># CALCULATE ERROR</span>
                <span class="n">EI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">w_c</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

                <span class="c1"># BACKPROPAGATION</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">EI</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w_t</span><span class="p">)</span>

                <span class="c1"># CALCULATE LOSS</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">+=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">u</span><span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">w_c</span><span class="p">])</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">w_c</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">u</span><span class="p">)))</span>
                <span class="c1">#self.loss += -2*np.log(len(w_c)) -np.sum([u[word.index(1)] for word in w_c]) + (len(w_c) * np.log(np.sum(np.exp(u))))</span>
                
            <span class="nb">print</span> <span class="s1">&#39;EPOCH:&#39;</span><span class="p">,</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;LOSS:&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
        <span class="k">pass</span>


    <span class="c1"># input a word, returns a vector (if available)</span>
    <span class="k">def</span> <span class="nf">word_vec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="n">w_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">v_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">[</span><span class="n">w_index</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">v_w</span>


    <span class="c1"># input a vector, returns nearest word(s)</span>
    <span class="k">def</span> <span class="nf">vec_sim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">top_n</span><span class="p">):</span>

        <span class="c1"># CYCLE THROUGH VOCAB</span>
        <span class="n">word_sim</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_count</span><span class="p">):</span>
            <span class="n">v_w2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">theta_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">v_w2</span><span class="p">)</span>
            <span class="n">theta_den</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v_w2</span><span class="p">)</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">theta_num</span> <span class="o">/</span> <span class="n">theta_den</span>

            <span class="n">word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">word_sim</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span>

        <span class="n">words_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_sim</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">sim</span><span class="p">):</span><span class="n">sim</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">words_sorted</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]:</span>
            <span class="nb">print</span> <span class="n">word</span><span class="p">,</span> <span class="n">sim</span>
            
        <span class="k">pass</span>

    <span class="c1"># input word, returns top [n] most similar words</span>
    <span class="k">def</span> <span class="nf">word_sim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">top_n</span><span class="p">):</span>
        
        <span class="n">w1_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="n">v_w1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">[</span><span class="n">w1_index</span><span class="p">]</span>

        <span class="c1"># CYCLE THROUGH VOCAB</span>
        <span class="n">word_sim</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_count</span><span class="p">):</span>
            <span class="n">v_w2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">theta_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v_w1</span><span class="p">,</span> <span class="n">v_w2</span><span class="p">)</span>
            <span class="n">theta_den</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v_w1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v_w2</span><span class="p">)</span>
            <span class="n">theta</span> <span class="o">=</span> <span class="n">theta_num</span> <span class="o">/</span> <span class="n">theta_den</span>

            <span class="n">word</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">word_sim</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span>

        <span class="n">words_sorted</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">word_sim</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">sim</span><span class="p">):</span><span class="n">sim</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">sim</span> <span class="ow">in</span> <span class="n">words_sorted</span><span class="p">[:</span><span class="n">top_n</span><span class="p">]:</span>
            <span class="nb">print</span> <span class="n">word</span><span class="p">,</span> <span class="n">sim</span>
            
        <span class="k">pass</span>

<span class="c1">#--- EXAMPLE RUN --------------------------------------------------------------+</span>

<span class="n">settings</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>                   <span class="c1"># dimension of word embeddings</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;window_size&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>         <span class="c1"># context window +/- center word</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>           <span class="c1"># minimum word count</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5000</span>           <span class="c1"># number of training epochs</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;neg_samp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>           <span class="c1"># number of negative words to use during training</span>
<span class="n">settings</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.01</span>    <span class="c1"># learning rate</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                   <span class="c1"># set the seed for reproducibility</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span><span class="s1">&#39;quick&#39;</span><span class="p">,</span><span class="s1">&#39;brown&#39;</span><span class="p">,</span><span class="s1">&#39;fox&#39;</span><span class="p">,</span><span class="s1">&#39;jumped&#39;</span><span class="p">,</span><span class="s1">&#39;over&#39;</span><span class="p">,</span><span class="s1">&#39;the&#39;</span><span class="p">,</span><span class="s1">&#39;lazy&#39;</span><span class="p">,</span><span class="s1">&#39;dog&#39;</span><span class="p">]]</span>

<span class="c1"># INITIALIZE W2V MODEL</span>
<span class="n">w2v</span> <span class="o">=</span> <span class="n">word2vec</span><span class="p">()</span>

<span class="c1"># generate training data</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">w2v</span><span class="o">.</span><span class="n">generate_training_data</span><span class="p">(</span><span class="n">settings</span><span class="p">,</span> <span class="n">corpus</span><span class="p">)</span>

<span class="c1"># train word2vec model</span>
<span class="n">w2v</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>

</pre></div>
</div>
</section>
<section id="tensorflow-tutorial-notebook">
<h2>Tensorflow tutorial notebook<a class="headerlink" href="#tensorflow-tutorial-notebook" title="Permalink to this headline">#</a></h2>
<iframe src="https://nbviewer.jupyter.org/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb" width="900" height="1200"></iframe>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/nlp/word2vec"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              
              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="_index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Word2Vec Embeddings</p>
      </div>
    </a>
    <a class="right-next"
       href="../language-models/_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">RNN Language Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> 
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-scratch">From scratch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensorflow-tutorial-notebook">Tensorflow tutorial notebook</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  
  <div class="tocsection editthispage">
    <a href="https://github.com/pantelis/artificial-intelligence/edit/master/artificial_intelligence/aiml-common/lectures/nlp/word2vec/word2vec-workshop.md">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../../../_sources/aiml-common/lectures/nlp/word2vec/word2vec-workshop.md">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner"></div>
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://sphinx-doc.org/">Sphinx</a> 4.5.0.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>