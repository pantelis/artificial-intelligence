

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Word2Vec Tensorflow Tutorial &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <script src="../../../../../_static/clipboard.min.js"></script>
    <script src="../../../../../_static/copybutton.js"></script>
    <script src="../../../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html" />
    <link rel="shortcut icon" href="../../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
    <link rel="next" title="Language Models" href="../../language-models/_index.html" />
    <link rel="prev" title="Word2Vec from scratch" href="word2vec_from_scratch.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../../_static/logo.png" class="logo__image only-light" alt="Introduction to Artificial Intelligence - Home"/>
    <script>document.write(`<img src="../../../../../_static/logo.png" class="logo__image only-dark" alt="Introduction to Artificial Intelligence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="list-caption"><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Syllabus</span></p><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="label-parts" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../../syllabus/_index.html">Syllabus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to AI</span></p><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="label-parts" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ai-intro/course-introduction/_index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ai-intro/systems-approach/_index.html">The four approaches towards AI</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../ai-intro/agents/_index.html">Agent-Environment Interface</a></li>



</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-1</span></p><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="label-parts" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../learning-problem/_index.html">The Learning Problem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../regression/linear-regression/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/sgd/_index.html">Stochastic Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../entropy/index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../optimization/maximum-likelihood/mle-gaussian-parameters.html">Maximum Likelihood Estimation of Gaussian Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-2</span></p><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="label-parts" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../classification/classification-intro/_index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../classification/logistic-regression/_index.html">Logistic Regression</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="label-parts" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../classification/perceptron/_index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/dnn-intro/index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-intro/_index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-dnn/_index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/backprop-dnn-exercises/_index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/regularization/_index.html">Regularization in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optimization/regularization/regularization-workshop-1.html">Regularization Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../information-theory-dnn/index.html">Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="label-parts" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-intro/_index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-layers/_index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-example-architectures/_index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">Visualizing what convnets learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="label-parts" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/index.html">Object Det. &amp; Semantic Segm. Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">Mask R-CNN Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">Mask R-CNN Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">Mask R-CNN - Inspect Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">Mask R-CNN - Inspect Trained Model</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">Mask R-CNN - Inspect Weights of a Trained Model</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">Detectron2 Beginner’s Tutorial</a></li>





</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="label-parts" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Probabilistic Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="label-parts" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../rse/recursive-state-estimation/index.html">Recursive State Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rse/discrete-bayesian-filter/discrete-bayesian-filter.html">Discrete Bayes Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rse/hmm-localization/_index.html">Localization and Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rse/kalman-filters/one-dimensional-kalman-filters.html">Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Logical Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="label-parts" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../logical-reasoning/automated-reasoning/_index.html">Automated Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logical-reasoning/propositional-logic/_index.html">World Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logical-reasoning/logical-inference/index.html">Logical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logical-reasoning/logical-agents/_index.html">Logical Agents</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Planning without Interactions</span></p><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="label-parts" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../planning/index.html">Automated Planning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../planning/pddl/index.html">PDDL</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/pddl/blocksworld/up_blocksworld_demo.html">The Unified Planning Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/pddl/logistics/index.html">Logistics Planning in PDDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/pddl/manufacturing/index.html">Manufacrturing Robot Planning in PDDL</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../planning/search/index.html">Search Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/search/forward-search/index.html">Forward Search Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/search/a-star/index.html">The A* Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../planning/search/search-alg-demo/index.html">Interactive Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../motion-planning-cars/index.html">Motion Planning for Autonomous Cars</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Markov Decision Processes</span></p><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="label-parts" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/index.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/mdp-intro/mdp_intro.html">Introduction to MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/bellman-expectation-backup/_index.html">Bellman Expectation Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/policy-evaluation/_index.html">Policy Evaluation (Prediction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/bellman-optimality-backup/_index.html">Bellman Optimality Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mdp/policy-improvement/_index.html">Policy Improvement (Control)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../mdp/dynamic-programming-algorithms/index.html">Dynamic Programming Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mdp/dynamic-programming-algorithms/policy-iteration/_index.html">Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mdp/dynamic-programming-algorithms/value-iteration/index.html">Value Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../mdp/mdp-workshop/index.html">MDP Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mdp/mdp-workshop/cleaning-robot/deterministic_mdp.html">Cleaning Robot - Deterministic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mdp/mdp-workshop/cleaning-robot/stochastic_mdp.html">Cleaning Robot - Stochastic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mdp/mdp-workshop/recycling-robot/_index.html">The recycling robot.</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="label-parts" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../reinforcement-learning/_index.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reinforcement-learning/prediction/monte-carlo.html">Monte-Carlo Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reinforcement-learning/prediction/temporal-difference.html">Temporal Difference (TD) Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../reinforcement-learning/model-free-control/index.html">Model-free Control</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../reinforcement-learning/model-free-control/generalized-policy-iteration/index.html">Generalized Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reinforcement-learning/model-free-control/greedy-monte-carlo/index.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy Monte-Carlo (MC) Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reinforcement-learning/model-free-control/sarsa/index.html">The SARSA Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reinforcement-learning/model-free-control/sarsa/gridworld/sarsa_gridworld.html">SARSA Gridworld Example</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="label-parts" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/introduction/_index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/simple-rnn/_index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/lstm/_index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p><input checked="" class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="label-parts" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nlp-pipelines/_index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="_index.html">Embeddings</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../language-models/_index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../language-models/cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../language-models/simple-rnn-language-model/index.html">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../language-models/lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../nmt/rnn-attention-workshop/seq2seq_and_attention.html">Attention in RNN NMT Workshop</a></li>




</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../transformers/transformers-intro.html">Transformers and Self-attention</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../transformers/singlehead-self-attention.html">Single-head self-attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transformers/multihead-self-attention.html">Multi-head attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transformers/positional_embeddings.html">Positional Embeddings</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="label-parts" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ml-math/calculus/index.html">Calculus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/><label class="label-parts" for="toctree-checkbox-28"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613 / CS370 Common Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/><label class="label-parts" for="toctree-checkbox-29"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/probability/probability-assignment-8/index.html">Probability &amp; Linear Algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/optimization/sgd.html">Stochastic Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/object-detection/video-search.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/object-tracking-kalman/drone-follow-me.html">Drone follow me using Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">CS-GY-6613-INET-Assignments</span></p><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/><label class="label-parts" for="toctree-checkbox-30"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/probability/probability-assignment-3/index.html">Probability Assignment</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/optimization/sgd-linear-regression/index.html">Optimization algorithms for linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/object-detection/video-search2.html">Video Search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../assignments/object-tracking-kalman/drone-follow-me2.html">Drone follow me using Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Undergraduate Project</span></p><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/><label class="label-parts" for="toctree-checkbox-31"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/cv/sam-finetuning-remote-sensing/index.html">Segment Anything Model Finetuning for Remote Sensing Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/robotics/learning-in-simulated-worlds/index.html">Learning in Simulated Worlds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/cv/wasm-pipelines/index.html">Webassembly (WASM) media pipelines</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Graduate Projects</span></p><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/><label class="label-parts" for="toctree-checkbox-32"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/cv/sam-advanced-remote-sensing/index.html">Visual Prompting and Oclusion Handling for Remote Sensing Applications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../projects/robotics/nl-guided-robotics/index.html">Natual Language Guided Robotics</a></li>
</ul></li></ul>
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/pantelis/artificial-intelligence/master?urlpath=tree/artificial_intelligence/aiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/pantelis/artificial-intelligence/blob/master/artificial_intelligence/aiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../../_sources/aiml-common/lectures/nlp/nlp-introduction/word2vec/word2vec_tensorflow_tutorial.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Word2Vec Tensorflow Tutorial</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-and-negative-sampling">Skip-gram and negative sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorize-an-example-sentence">Vectorize an example sentence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-skip-grams-from-one-sentence">Generate skip-grams from one sentence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-sampling-for-one-skip-gram">Negative sampling for one skip-gram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#construct-one-training-example">Construct one training example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compile-all-steps-into-one-function">Compile all steps into one function</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-sampling-table">Skip-gram sampling table</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-training-data">Generate training data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-data-for-word2vec">Prepare training data for word2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-text-corpus">Download text corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorize-sentences-from-the-corpus">Vectorize sentences from the corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#obtain-sequences-from-the-dataset">Obtain sequences from the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-training-examples-from-sequences">Generate training examples from sequences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-the-dataset-for-performance">Configure the dataset for performance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-training">Model and training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subclassed-word2vec-model">Subclassed word2vec model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-loss-function-and-compile-model">Define loss function and compile model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-lookup-and-analysis">Embedding lookup and analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://www.tensorflow.org/tutorials/text/word2vec">
    <img src="https://www.tensorflow.org/images/tf_logo_32px.png" />
    View on TensorFlow.org</a>
  </td>
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb">
    <img src="https://www.tensorflow.org/images/colab_logo_32px.png" />
    Run in Google Colab</a>
  </td>
  <td>
    <a target="_blank" href="https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub</a>
  </td>
  <td>
    <a href="https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/word2vec.ipynb"><img src="https://www.tensorflow.org/images/download_logo_32px.png" />Download notebook</a>
  </td>
</table><section class="tex2jax_ignore mathjax_ignore" id="word2vec-tensorflow-tutorial">
<h1>Word2Vec Tensorflow Tutorial<a class="headerlink" href="#word2vec-tensorflow-tutorial" title="Permalink to this heading">#</a></h1>
<p>word2vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets. Embeddings learned through word2vec have proven to be successful on a variety of downstream natural language processing tasks.</p>
<p>Note: This tutorial is based on <a class="reference external" href="https://arxiv.org/pdf/1301.3781.pdf">Efficient estimation of word representations in vector space</a> and <a class="reference external" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed representations of words and phrases and their compositionality</a>. It is not an exact implementation of the papers. Rather, it is intended to illustrate the key ideas.</p>
<p>These papers proposed two methods for learning representations of words:</p>
<ul class="simple">
<li><p><strong>Continuous bag-of-words model</strong>: predicts the middle word based on surrounding context words. The context consists of a few words before and after the current (middle) word. This architecture is called a bag-of-words model as the order of words in the context is not important.</p></li>
<li><p><strong>Continuous skip-gram model</strong>: predicts words within a certain range before and after the current word in the same sentence. A worked example of this is given below.</p></li>
</ul>
<p>You’ll use the skip-gram approach in this tutorial. First, you’ll explore skip-grams and other concepts using a single sentence for illustration. Next, you’ll train your own word2vec model on a small dataset. This tutorial also contains code to export the trained embeddings and visualize them in the <a class="reference external" href="http://projector.tensorflow.org/">TensorFlow Embedding Projector</a>.</p>
<section id="skip-gram-and-negative-sampling">
<h2>Skip-gram and negative sampling<a class="headerlink" href="#skip-gram-and-negative-sampling" title="Permalink to this heading">#</a></h2>
<p>While a bag-of-words model predicts a word given the neighboring context, a skip-gram model predicts the context (or neighbors) of a word, given the word itself. The model is trained on skip-grams, which are n-grams that allow tokens to be skipped (see the diagram below for an example). The context of a word can be represented through a set of skip-gram pairs of <code class="docutils literal notranslate"><span class="pre">(target_word,</span> <span class="pre">context_word)</span></code> where <code class="docutils literal notranslate"><span class="pre">context_word</span></code> appears in the neighboring context of <code class="docutils literal notranslate"><span class="pre">target_word</span></code>.</p>
<p>Consider the following sentence of eight words:</p>
<blockquote>
<div><p>The wide road shimmered in the hot sun.</p>
</div></blockquote>
<p>The context words for each of the 8 words of this sentence are defined by a window size. The window size determines the span of words on either side of a <code class="docutils literal notranslate"><span class="pre">target_word</span></code> that can be considered a <code class="docutils literal notranslate"><span class="pre">context</span> <span class="pre">word</span></code>. Below is a table of skip-grams for target words based on different window sizes.</p>
<p>Note: For this tutorial, a window size of <code class="docutils literal notranslate"><span class="pre">n</span></code> implies n words on each side with a total window span of 2*n+1 words across a word.</p>
<p><img alt="word2vec_skipgrams" src="https://tensorflow.org/tutorials/text/images/word2vec_skipgram.png" /></p>
<p>The training objective of the skip-gram model is to maximize the probability of predicting context words given the target word. For a sequence of words <em>w<sub>1</sub>, w<sub>2</sub>, … w<sub>T</sub></em>, the objective can be written as the average log probability</p>
<p><img alt="word2vec_skipgram_objective" src="https://tensorflow.org/tutorials/text/images/word2vec_skipgram_objective.png" /></p>
<p>where <code class="docutils literal notranslate"><span class="pre">c</span></code> is the size of the training context. The basic skip-gram formulation defines this probability using the softmax function.</p>
<p><img alt="word2vec_full_softmax" src="https://tensorflow.org/tutorials/text/images/word2vec_full_softmax.png" /></p>
<p>where <em>v</em> and <em>v<sup>’<sup></em> are target and context vector representations of words and <em>W</em> is vocabulary size.</p>
<p>Computing the denominator of this formulation involves performing a full softmax over the entire vocabulary words, which are often large (10<sup>5</sup>-10<sup>7</sup>) terms.</p>
<p>The <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/nn/nce_loss">noise contrastive estimation</a> (NCE) loss function is an efficient approximation for a full softmax. With an objective to learn word embeddings instead of modeling the word distribution, the NCE loss can be <a class="reference external" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">simplified</a> to use negative sampling.</p>
<p>The simplified negative sampling objective for a target word is to distinguish  the context word from <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> negative samples drawn from noise distribution <em>P<sub>n</sub>(w)</em> of words. More precisely, an efficient approximation of full softmax over the vocabulary is, for a skip-gram pair, to pose the loss for a target word as a classification problem between the context word and <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> negative samples.</p>
<p>A negative sample is defined as a <code class="docutils literal notranslate"><span class="pre">(target_word,</span> <span class="pre">context_word)</span></code> pair such that the <code class="docutils literal notranslate"><span class="pre">context_word</span></code> does not appear in the <code class="docutils literal notranslate"><span class="pre">window_size</span></code> neighborhood of the <code class="docutils literal notranslate"><span class="pre">target_word</span></code>. For the example sentence, these are a few potential negative samples (when <code class="docutils literal notranslate"><span class="pre">window_size</span></code> is <code class="docutils literal notranslate"><span class="pre">2</span></code>).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">hot</span><span class="p">,</span> <span class="n">shimmered</span><span class="p">)</span>
<span class="p">(</span><span class="n">wide</span><span class="p">,</span> <span class="n">hot</span><span class="p">)</span>
<span class="p">(</span><span class="n">wide</span><span class="p">,</span> <span class="n">sun</span><span class="p">)</span>
</pre></div>
</div>
<p>In the next section, you’ll generate skip-grams and negative samples for a single sentence. You’ll also learn about subsampling techniques and train a classification model for positive and negative training examples later in the tutorial.</p>
</section>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">import</span> <span class="nn">tqdm</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2023-04-06 14:03:17.815941: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-04-06 14:03:17.845916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-04-06 14:03:19.961250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the TensorBoard notebook extension</span>
<span class="o">%</span><span class="k">load_ext</span> tensorboard
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">AUTOTUNE</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span>
</pre></div>
</div>
</div>
</div>
<section id="vectorize-an-example-sentence">
<h3>Vectorize an example sentence<a class="headerlink" href="#vectorize-an-example-sentence" title="Permalink to this heading">#</a></h3>
<p>Consider the following sentence:</p>
<blockquote>
<div><p>The wide road shimmered in the hot sun.</p>
</div></blockquote>
<p>Tokenize the sentence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;The wide road shimmered in the hot sun&quot;</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8
</pre></div>
</div>
</div>
</div>
<p>Create a vocabulary to save mappings from tokens to integer indices:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="p">{},</span> <span class="mi">1</span>  <span class="c1"># start indexing from 1</span>
<span class="n">vocab</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># add a padding token</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
  <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
    <span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span>
    <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;&lt;pad&gt;&#39;: 0, &#39;the&#39;: 1, &#39;wide&#39;: 2, &#39;road&#39;: 3, &#39;shimmered&#39;: 4, &#39;in&#39;: 5, &#39;hot&#39;: 6, &#39;sun&#39;: 7}
</pre></div>
</div>
</div>
</div>
<p>Create an inverse vocabulary to save mappings from integer indices to tokens:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inverse_vocab</span> <span class="o">=</span> <span class="p">{</span><span class="n">index</span><span class="p">:</span> <span class="n">token</span> <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">vocab</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inverse_vocab</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: &#39;&lt;pad&gt;&#39;, 1: &#39;the&#39;, 2: &#39;wide&#39;, 3: &#39;road&#39;, 4: &#39;shimmered&#39;, 5: &#39;in&#39;, 6: &#39;hot&#39;, 7: &#39;sun&#39;}
</pre></div>
</div>
</div>
</div>
<p>Vectorize your sentence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">example_sequence</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">example_sequence</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1, 2, 3, 4, 5, 1, 6, 7]
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-skip-grams-from-one-sentence">
<h3>Generate skip-grams from one sentence<a class="headerlink" href="#generate-skip-grams-from-one-sentence" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.keras.preprocessing.sequence</span></code> module provides useful functions that simplify data preparation for word2vec. You can use the <code class="docutils literal notranslate"><span class="pre">tf.keras.preprocessing.sequence.skipgrams</span></code> to generate skip-gram pairs from the <code class="docutils literal notranslate"><span class="pre">example_sequence</span></code> with a given <code class="docutils literal notranslate"><span class="pre">window_size</span></code> from tokens in the range <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">vocab_size)</span></code>.</p>
<p>Note: <code class="docutils literal notranslate"><span class="pre">negative_samples</span></code> is set to <code class="docutils literal notranslate"><span class="pre">0</span></code> here, as batching negative samples generated by this function requires a bit of code. You will use another function to perform negative sampling in the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">window_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">positive_skip_grams</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">skipgrams</span><span class="p">(</span>
      <span class="n">example_sequence</span><span class="p">,</span>
      <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
      <span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">,</span>
      <span class="n">negative_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">positive_skip_grams</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>26
</pre></div>
</div>
</div>
</div>
<p>Print a few positive skip-grams:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">target</span><span class="p">,</span> <span class="n">context</span> <span class="ow">in</span> <span class="n">positive_skip_grams</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="s2">): (</span><span class="si">{</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">target</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">context</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, 4): (road, shimmered)
(5, 1): (in, the)
(2, 1): (wide, the)
(5, 3): (in, road)
(4, 2): (shimmered, wide)
</pre></div>
</div>
</div>
</div>
</section>
<section id="negative-sampling-for-one-skip-gram">
<h3>Negative sampling for one skip-gram<a class="headerlink" href="#negative-sampling-for-one-skip-gram" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">skipgrams</span></code> function returns all positive skip-gram pairs by sliding over a given window span. To produce additional skip-gram pairs that would serve as negative samples for training, you need to sample random words from the vocabulary. Use the <code class="docutils literal notranslate"><span class="pre">tf.random.log_uniform_candidate_sampler</span></code> function to sample <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> number of negative samples for a given target word in a window. You can call the function on one skip-grams’s target word and pass the context word as true class to exclude it from being sampled.</p>
<p>Key point: <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> (the number of negative samples per a positive context word) in the <code class="docutils literal notranslate"><span class="pre">[5,</span> <span class="pre">20]</span></code> range is <a class="reference external" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">shown to work</a> best for smaller datasets, while <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> in the <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">5]</span></code> range suffices for larger datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get target and context words for one positive skip-gram.</span>
<span class="n">target_word</span><span class="p">,</span> <span class="n">context_word</span> <span class="o">=</span> <span class="n">positive_skip_grams</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Set the number of negative samples per positive context.</span>
<span class="n">num_ns</span> <span class="o">=</span> <span class="mi">4</span>

<span class="n">context_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">context_word</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int64&quot;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">negative_sampling_candidates</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">log_uniform_candidate_sampler</span><span class="p">(</span>
    <span class="n">true_classes</span><span class="o">=</span><span class="n">context_class</span><span class="p">,</span>  <span class="c1"># class that should be sampled as &#39;positive&#39;</span>
    <span class="n">num_true</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># each positive skip-gram has 1 positive context class</span>
    <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_ns</span><span class="p">,</span>  <span class="c1"># number of negative context words to sample</span>
    <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># all the negative samples should be unique</span>
    <span class="n">range_max</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>  <span class="c1"># pick index of the samples from [0, vocab_size]</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>  <span class="c1"># seed for reproducibility</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;negative_sampling&quot;</span>  <span class="c1"># name of this operation</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">negative_sampling_candidates</span><span class="p">)</span>
<span class="nb">print</span><span class="p">([</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">index</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">negative_sampling_candidates</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)
[&#39;wide&#39;, &#39;the&#39;, &#39;shimmered&#39;, &#39;road&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="construct-one-training-example">
<h3>Construct one training example<a class="headerlink" href="#construct-one-training-example" title="Permalink to this heading">#</a></h3>
<p>For a given positive <code class="docutils literal notranslate"><span class="pre">(target_word,</span> <span class="pre">context_word)</span></code> skip-gram, you now also have <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> negative sampled context words that do not appear in the window size neighborhood of <code class="docutils literal notranslate"><span class="pre">target_word</span></code>. Batch the <code class="docutils literal notranslate"><span class="pre">1</span></code> positive <code class="docutils literal notranslate"><span class="pre">context_word</span></code> and <code class="docutils literal notranslate"><span class="pre">num_ns</span></code> negative context words into one tensor. This produces a set of positive skip-grams (labeled as <code class="docutils literal notranslate"><span class="pre">1</span></code>) and negative samples (labeled as <code class="docutils literal notranslate"><span class="pre">0</span></code>) for each target word.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reduce a dimension so you can use concatenation (in the next step).</span>
<span class="n">squeezed_context_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">context_class</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Concatenate a positive context word with negative sampled words.</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">squeezed_context_class</span><span class="p">,</span> <span class="n">negative_sampling_candidates</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_ns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int64&quot;</span><span class="p">)</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">target_word</span>
</pre></div>
</div>
</div>
</div>
<p>Check out the context and the corresponding labels for the target word from the skip-gram example above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;target_index    : </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;target_word     : </span><span class="si">{</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">target_word</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;context_indices : </span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;context_words   : </span><span class="si">{</span><span class="p">[</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">c</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">context</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;label           : </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target_index    : 3
target_word     : road
context_indices : [4 2 1 4 3]
context_words   : [&#39;shimmered&#39;, &#39;wide&#39;, &#39;the&#39;, &#39;shimmered&#39;, &#39;road&#39;]
label           : [1 0 0 0 0]
</pre></div>
</div>
</div>
</div>
<p>A tuple of <code class="docutils literal notranslate"><span class="pre">(target,</span> <span class="pre">context,</span> <span class="pre">label)</span></code> tensors constitutes one training example for training your skip-gram negative sampling word2vec model. Notice that the target is of shape <code class="docutils literal notranslate"><span class="pre">(1,)</span></code> while the context and label are of shape <code class="docutils literal notranslate"><span class="pre">(1+num_ns,)</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;target  :&quot;</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;context :&quot;</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label   :&quot;</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>target  : 3
context : tf.Tensor([4 2 1 4 3], shape=(5,), dtype=int64)
label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h3>
<p>This diagram summarizes the procedure of generating a training example from a sentence:</p>
<p><img alt="word2vec_negative_sampling" src="https://tensorflow.org/tutorials/text/images/word2vec_negative_sampling.png" /></p>
<p>Notice that the words <code class="docutils literal notranslate"><span class="pre">temperature</span></code> and <code class="docutils literal notranslate"><span class="pre">code</span></code> are not part of the input sentence. They belong to the vocabulary like certain other indices used in the diagram above.</p>
</section>
</section>
<section id="compile-all-steps-into-one-function">
<h2>Compile all steps into one function<a class="headerlink" href="#compile-all-steps-into-one-function" title="Permalink to this heading">#</a></h2>
<section id="skip-gram-sampling-table">
<h3>Skip-gram sampling table<a class="headerlink" href="#skip-gram-sampling-table" title="Permalink to this heading">#</a></h3>
<p>A large dataset means larger vocabulary with higher number of more frequent words such as stopwords. Training examples obtained from sampling commonly occurring words (such as <code class="docutils literal notranslate"><span class="pre">the</span></code>, <code class="docutils literal notranslate"><span class="pre">is</span></code>, <code class="docutils literal notranslate"><span class="pre">on</span></code>) don’t add much useful information  for the model to learn from. <a class="reference external" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Mikolov et al.</a> suggest subsampling of frequent words as a helpful practice to improve embedding quality.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tf.keras.preprocessing.sequence.skipgrams</span></code> function accepts a sampling table argument to encode probabilities of sampling any token. You can use the <code class="docutils literal notranslate"><span class="pre">tf.keras.preprocessing.sequence.make_sampling_table</span></code> to  generate a word-frequency rank based probabilistic sampling table and pass it to the <code class="docutils literal notranslate"><span class="pre">skipgrams</span></code> function. Inspect the sampling probabilities for a <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code> of 10.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sampling_table</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">make_sampling_table</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sampling_table</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435
 0.01212381 0.01347162 0.01474487 0.0159558 ]
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">sampling_table[i]</span></code> denotes the probability of sampling the i-th most common word in a dataset. The function assumes a <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s distribution</a> of the word frequencies for sampling.</p>
<p>Key point: The <code class="docutils literal notranslate"><span class="pre">tf.random.log_uniform_candidate_sampler</span></code> already assumes that the vocabulary frequency follows a log-uniform (Zipf’s) distribution. Using these distribution weighted sampling also helps approximate the Noise Contrastive Estimation (NCE) loss with simpler loss functions for training a negative sampling objective.</p>
</section>
<section id="generate-training-data">
<h3>Generate training data<a class="headerlink" href="#generate-training-data" title="Permalink to this heading">#</a></h3>
<p>Compile all the steps described above into a function that can be called on a list of vectorized sentences obtained from any text dataset. Notice that the sampling table is built before sampling skip-gram word pairs. You will use this function in the later sections.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generates skip-gram pairs with negative sampling for a list of sequences</span>
<span class="c1"># (int-encoded sentences) based on window size, number of negative samples</span>
<span class="c1"># and vocabulary size.</span>
<span class="k">def</span> <span class="nf">generate_training_data</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">window_size</span><span class="p">,</span> <span class="n">num_ns</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
  <span class="c1"># Elements of each training example are appended to these lists.</span>
  <span class="n">targets</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

  <span class="c1"># Build the sampling table for `vocab_size` tokens.</span>
  <span class="n">sampling_table</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">make_sampling_table</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>

  <span class="c1"># Iterate over all sequences (sentences) in the dataset.</span>
  <span class="k">for</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">sequences</span><span class="p">):</span>

    <span class="c1"># Generate positive skip-gram pairs for a sequence (sentence).</span>
    <span class="n">positive_skip_grams</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">skipgrams</span><span class="p">(</span>
          <span class="n">sequence</span><span class="p">,</span>
          <span class="n">vocabulary_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
          <span class="n">sampling_table</span><span class="o">=</span><span class="n">sampling_table</span><span class="p">,</span>
          <span class="n">window_size</span><span class="o">=</span><span class="n">window_size</span><span class="p">,</span>
          <span class="n">negative_samples</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Iterate over each positive skip-gram pair to produce training examples</span>
    <span class="c1"># with a positive context word and negative samples.</span>
    <span class="k">for</span> <span class="n">target_word</span><span class="p">,</span> <span class="n">context_word</span> <span class="ow">in</span> <span class="n">positive_skip_grams</span><span class="p">:</span>
      <span class="n">context_class</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="n">context_word</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int64&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">negative_sampling_candidates</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">log_uniform_candidate_sampler</span><span class="p">(</span>
          <span class="n">true_classes</span><span class="o">=</span><span class="n">context_class</span><span class="p">,</span>
          <span class="n">num_true</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">num_sampled</span><span class="o">=</span><span class="n">num_ns</span><span class="p">,</span>
          <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">range_max</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
          <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="s2">&quot;negative_sampling&quot;</span><span class="p">)</span>

      <span class="c1"># Build context and label vectors (for one target word)</span>
      <span class="n">context</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">context_class</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">negative_sampling_candidates</span><span class="p">],</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">num_ns</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int64&quot;</span><span class="p">)</span>

      <span class="c1"># Append each element from the training example to global lists.</span>
      <span class="n">targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_word</span><span class="p">)</span>
      <span class="n">contexts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
      <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">targets</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">labels</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="prepare-training-data-for-word2vec">
<h2>Prepare training data for word2vec<a class="headerlink" href="#prepare-training-data-for-word2vec" title="Permalink to this heading">#</a></h2>
<p>With an understanding of how to work with one sentence for a skip-gram negative sampling based word2vec model, you can proceed to generate training examples from a larger list of sentences!</p>
<section id="download-text-corpus">
<h3>Download text corpus<a class="headerlink" href="#download-text-corpus" title="Permalink to this heading">#</a></h3>
<p>You will use a text file of Shakespeare’s writing for this tutorial. Change the following line to run this code on your own data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">path_to_file</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;shakespeare.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt

   8192/1115394 [..............................] - ETA: 0s
1115394/1115394 [==============================] - 0s 0us/step
</pre></div>
</div>
</div>
</div>
<p>Read the text from the file and print the first few lines:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path_to_file</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">[:</span><span class="mi">20</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?

All:
Resolved. resolved.

First Citizen:
First, you know Caius Marcius is chief enemy to the people.

All:
We know&#39;t, we know&#39;t.

First Citizen:
Let us kill him, and we&#39;ll have corn at our own price.
</pre></div>
</div>
</div>
</div>
<p>Use the non empty lines to construct a <code class="docutils literal notranslate"><span class="pre">tf.data.TextLineDataset</span></code> object for the next steps:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TextLineDataset</span><span class="p">(</span><span class="n">path_to_file</span><span class="p">)</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">length</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">bool</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089
</pre></div>
</div>
</div>
</div>
</section>
<section id="vectorize-sentences-from-the-corpus">
<h3>Vectorize sentences from the corpus<a class="headerlink" href="#vectorize-sentences-from-the-corpus" title="Permalink to this heading">#</a></h3>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">TextVectorization</span></code> layer to vectorize sentences from the corpus. Learn more about using this layer in this <a class="reference external" href="https://www.tensorflow.org/tutorials/keras/text_classification">Text classification</a> tutorial. Notice from the first few sentences above that the text needs to be in one case and punctuation needs to be removed. To do this, define a <code class="docutils literal notranslate"><span class="pre">custom_standardization</span> <span class="pre">function</span></code> that can be used in the TextVectorization layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now, create a custom standardization function to lowercase the text and</span>
<span class="c1"># remove punctuation.</span>
<span class="k">def</span> <span class="nf">custom_standardization</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
  <span class="n">lowercase</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">regex_replace</span><span class="p">(</span><span class="n">lowercase</span><span class="p">,</span>
                                  <span class="s1">&#39;[</span><span class="si">%s</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">),</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>


<span class="c1"># Define the vocabulary size and the number of words in a sequence.</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">4096</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Use the `TextVectorization` layer to normalize, split, and map strings to</span>
<span class="c1"># integers. Set the `output_sequence_length` length to pad all samples to the</span>
<span class="c1"># same length.</span>
<span class="n">vectorize_layer</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">TextVectorization</span><span class="p">(</span>
    <span class="n">standardize</span><span class="o">=</span><span class="n">custom_standardization</span><span class="p">,</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">output_mode</span><span class="o">=</span><span class="s1">&#39;int&#39;</span><span class="p">,</span>
    <span class="n">output_sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Call <code class="docutils literal notranslate"><span class="pre">TextVectorization.adapt</span></code> on the text dataset to create vocabulary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vectorize_layer</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">text_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1024</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Once the state of the layer has been adapted to represent the text corpus, the vocabulary can be accessed with <code class="docutils literal notranslate"><span class="pre">TextVectorization.get_vocabulary</span></code>. This function returns a list of all vocabulary tokens sorted (descending) by their frequency.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save the created vocabulary for reference.</span>
<span class="n">inverse_vocab</span> <span class="o">=</span> <span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inverse_vocab</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;&#39;, &#39;[UNK]&#39;, &#39;the&#39;, &#39;and&#39;, &#39;to&#39;, &#39;i&#39;, &#39;of&#39;, &#39;you&#39;, &#39;my&#39;, &#39;a&#39;, &#39;that&#39;, &#39;in&#39;, &#39;is&#39;, &#39;not&#39;, &#39;for&#39;, &#39;with&#39;, &#39;me&#39;, &#39;it&#39;, &#39;be&#39;, &#39;your&#39;]
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">vectorize_layer</span></code> can now be used to generate vectors for each element in the <code class="docutils literal notranslate"><span class="pre">text_ds</span></code> (a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code>). Apply <code class="docutils literal notranslate"><span class="pre">Dataset.batch</span></code>, <code class="docutils literal notranslate"><span class="pre">Dataset.prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">Dataset.map</span></code>, and <code class="docutils literal notranslate"><span class="pre">Dataset.unbatch</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Vectorize the data in text_ds.</span>
<span class="n">text_vector_ds</span> <span class="o">=</span> <span class="n">text_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">vectorize_layer</span><span class="p">)</span><span class="o">.</span><span class="n">unbatch</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="obtain-sequences-from-the-dataset">
<h3>Obtain sequences from the dataset<a class="headerlink" href="#obtain-sequences-from-the-dataset" title="Permalink to this heading">#</a></h3>
<p>You now have a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> of integer encoded sentences. To prepare the dataset for training a word2vec model, flatten the dataset into a list of sentence vector sequences. This step is required as you would iterate over each sentence in the dataset to produce positive and negative examples.</p>
<p>Note: Since the <code class="docutils literal notranslate"><span class="pre">generate_training_data()</span></code> defined earlier uses non-TensorFlow Python/NumPy functions, you could also use a <code class="docutils literal notranslate"><span class="pre">tf.py_function</span></code> or <code class="docutils literal notranslate"><span class="pre">tf.numpy_function</span></code> with <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset.map</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sequences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">text_vector_ds</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>32777
</pre></div>
</div>
</div>
</div>
<p>Inspect a few examples from <code class="docutils literal notranslate"><span class="pre">sequences</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">seq</span><span class="si">}</span><span class="s2"> =&gt; </span><span class="si">{</span><span class="p">[</span><span class="n">inverse_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">seq</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 89 270   0   0   0   0   0   0   0   0] =&gt; [&#39;first&#39;, &#39;citizen&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;]
[138  36 982 144 673 125  16 106   0   0] =&gt; [&#39;before&#39;, &#39;we&#39;, &#39;proceed&#39;, &#39;any&#39;, &#39;further&#39;, &#39;hear&#39;, &#39;me&#39;, &#39;speak&#39;, &#39;&#39;, &#39;&#39;]
[34  0  0  0  0  0  0  0  0  0] =&gt; [&#39;all&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;]
[106 106   0   0   0   0   0   0   0   0] =&gt; [&#39;speak&#39;, &#39;speak&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;]
[ 89 270   0   0   0   0   0   0   0   0] =&gt; [&#39;first&#39;, &#39;citizen&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-training-examples-from-sequences">
<h3>Generate training examples from sequences<a class="headerlink" href="#generate-training-examples-from-sequences" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">sequences</span></code> is now a list of int encoded sentences. Just call the <code class="docutils literal notranslate"><span class="pre">generate_training_data</span></code> function defined earlier to generate training examples for the word2vec model. To recap, the function iterates over each word from each sequence to collect positive and negative context words. Length of target, contexts and labels should be the same, representing the total number of training examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">targets</span><span class="p">,</span> <span class="n">contexts</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">generate_training_data</span><span class="p">(</span>
    <span class="n">sequences</span><span class="o">=</span><span class="n">sequences</span><span class="p">,</span>
    <span class="n">window_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_ns</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
<span class="n">contexts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">contexts</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;targets.shape: </span><span class="si">{</span><span class="n">targets</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;contexts.shape: </span><span class="si">{</span><span class="n">contexts</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;labels.shape: </span><span class="si">{</span><span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>targets.shape: (64953,)
contexts.shape: (64953, 5)
labels.shape: (64953, 5)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/32777 [00:00&lt;?, ?it/s]
  0%|          | 76/32777 [00:00&lt;00:43, 746.29it/s]
  0%|          | 151/32777 [00:00&lt;00:48, 667.00it/s]
  1%|          | 219/32777 [00:00&lt;00:50, 641.54it/s]
  1%|          | 284/32777 [00:00&lt;00:53, 602.98it/s]
  1%|          | 389/32777 [00:00&lt;00:43, 748.18it/s]
  1%|▏         | 466/32777 [00:00&lt;00:43, 740.29it/s]
  2%|▏         | 541/32777 [00:00&lt;00:45, 707.15it/s]
  2%|▏         | 643/32777 [00:00&lt;00:40, 792.21it/s]
  2%|▏         | 726/32777 [00:00&lt;00:39, 802.43it/s]
  2%|▏         | 809/32777 [00:01&lt;00:40, 798.58it/s]
  3%|▎         | 890/32777 [00:01&lt;00:41, 760.61it/s]
  3%|▎         | 987/32777 [00:01&lt;00:39, 814.72it/s]
  3%|▎         | 1073/32777 [00:01&lt;00:38, 827.40it/s]
  4%|▎         | 1157/32777 [00:01&lt;00:38, 819.62it/s]
  4%|▍         | 1240/32777 [00:01&lt;00:41, 768.41it/s]
  4%|▍         | 1333/32777 [00:01&lt;00:38, 810.59it/s]
  4%|▍         | 1418/32777 [00:01&lt;00:38, 821.79it/s]
  5%|▍         | 1501/32777 [00:01&lt;00:43, 722.41it/s]
  5%|▍         | 1580/32777 [00:02&lt;00:42, 731.83it/s]
  5%|▌         | 1656/32777 [00:02&lt;00:46, 671.79it/s]
  5%|▌         | 1726/32777 [00:02&lt;00:48, 640.83it/s]
  6%|▌         | 1813/32777 [00:02&lt;00:44, 699.59it/s]
  6%|▌         | 1909/32777 [00:02&lt;00:40, 764.62it/s]
  6%|▌         | 1988/32777 [00:02&lt;00:41, 750.38it/s]
  6%|▋         | 2072/32777 [00:02&lt;00:39, 772.94it/s]
  7%|▋         | 2180/32777 [00:02&lt;00:35, 855.90it/s]
  7%|▋         | 2267/32777 [00:02&lt;00:36, 842.39it/s]
  7%|▋         | 2353/32777 [00:03&lt;00:36, 826.71it/s]
  8%|▊         | 2474/32777 [00:03&lt;00:32, 932.43it/s]
  8%|▊         | 2569/32777 [00:03&lt;00:32, 917.96it/s]
  8%|▊         | 2662/32777 [00:03&lt;00:34, 863.80it/s]
  8%|▊         | 2750/32777 [00:03&lt;00:34, 862.46it/s]
  9%|▊         | 2837/32777 [00:03&lt;00:35, 831.67it/s]
  9%|▉         | 2931/32777 [00:03&lt;00:34, 855.84it/s]
  9%|▉         | 3022/32777 [00:03&lt;00:34, 871.14it/s]
  9%|▉         | 3110/32777 [00:03&lt;00:38, 778.60it/s]
 10%|▉         | 3210/32777 [00:04&lt;00:35, 833.64it/s]
 10%|█         | 3296/32777 [00:04&lt;00:37, 788.15it/s]
 10%|█         | 3414/32777 [00:04&lt;00:32, 893.25it/s]
 11%|█         | 3506/32777 [00:04&lt;00:35, 829.71it/s]
 11%|█         | 3592/32777 [00:04&lt;00:35, 812.04it/s]
 11%|█         | 3675/32777 [00:04&lt;00:39, 743.73it/s]
 12%|█▏        | 3783/32777 [00:04&lt;00:34, 829.78it/s]
 12%|█▏        | 3880/32777 [00:04&lt;00:33, 856.07it/s]
 12%|█▏        | 3968/32777 [00:04&lt;00:34, 831.66it/s]
 12%|█▏        | 4053/32777 [00:05&lt;00:35, 818.04it/s]
 13%|█▎        | 4142/32777 [00:05&lt;00:34, 831.89it/s]
 13%|█▎        | 4226/32777 [00:05&lt;00:39, 714.17it/s]
 13%|█▎        | 4301/32777 [00:05&lt;00:41, 691.88it/s]
 13%|█▎        | 4374/32777 [00:05&lt;00:40, 699.99it/s]
 14%|█▎        | 4446/32777 [00:05&lt;00:44, 634.07it/s]
 14%|█▍        | 4512/32777 [00:05&lt;00:47, 588.97it/s]
 14%|█▍        | 4590/32777 [00:05&lt;00:44, 633.32it/s]
 14%|█▍        | 4681/32777 [00:06&lt;00:39, 704.07it/s]
 15%|█▍        | 4770/32777 [00:06&lt;00:37, 753.46it/s]
 15%|█▍        | 4848/32777 [00:06&lt;00:38, 729.11it/s]
 15%|█▌        | 4923/32777 [00:06&lt;00:40, 680.67it/s]
 15%|█▌        | 4997/32777 [00:06&lt;00:40, 694.14it/s]
 15%|█▌        | 5068/32777 [00:06&lt;00:39, 697.79it/s]
 16%|█▌        | 5139/32777 [00:06&lt;00:43, 638.16it/s]
 16%|█▌        | 5217/32777 [00:06&lt;00:40, 672.88it/s]
 16%|█▌        | 5286/32777 [00:06&lt;00:41, 654.61it/s]
 16%|█▋        | 5386/32777 [00:07&lt;00:36, 749.61it/s]
 17%|█▋        | 5463/32777 [00:07&lt;00:37, 727.80it/s]
 17%|█▋        | 5537/32777 [00:07&lt;00:41, 663.01it/s]
 17%|█▋        | 5629/32777 [00:07&lt;00:37, 729.85it/s]
 17%|█▋        | 5704/32777 [00:07&lt;00:40, 674.43it/s]
 18%|█▊        | 5789/32777 [00:07&lt;00:37, 716.05it/s]
 18%|█▊        | 5869/32777 [00:07&lt;00:36, 735.60it/s]
 18%|█▊        | 5945/32777 [00:07&lt;00:42, 629.73it/s]
 18%|█▊        | 6037/32777 [00:08&lt;00:38, 702.88it/s]
 19%|█▊        | 6113/32777 [00:08&lt;00:37, 716.17it/s]
 19%|█▉        | 6188/32777 [00:08&lt;00:40, 660.06it/s]
 19%|█▉        | 6264/32777 [00:08&lt;00:38, 683.12it/s]
 19%|█▉        | 6340/32777 [00:08&lt;00:37, 703.95it/s]
 20%|█▉        | 6413/32777 [00:08&lt;00:38, 684.20it/s]
 20%|█▉        | 6483/32777 [00:08&lt;00:38, 676.22it/s]
 20%|██        | 6560/32777 [00:08&lt;00:37, 694.19it/s]
 20%|██        | 6631/32777 [00:08&lt;00:41, 636.95it/s]
 20%|██        | 6705/32777 [00:09&lt;00:39, 657.65it/s]
 21%|██        | 6781/32777 [00:09&lt;00:37, 684.25it/s]
 21%|██        | 6851/32777 [00:09&lt;00:39, 662.56it/s]
 21%|██        | 6918/32777 [00:09&lt;00:39, 656.41it/s]
 21%|██▏       | 7028/32777 [00:09&lt;00:32, 781.69it/s]
 22%|██▏       | 7108/32777 [00:09&lt;00:32, 786.00it/s]
 22%|██▏       | 7196/32777 [00:09&lt;00:31, 812.96it/s]
 22%|██▏       | 7278/32777 [00:09&lt;00:31, 803.22it/s]
 22%|██▏       | 7359/32777 [00:09&lt;00:33, 755.75it/s]
 23%|██▎       | 7436/32777 [00:09&lt;00:34, 744.04it/s]
 23%|██▎       | 7524/32777 [00:10&lt;00:32, 771.68it/s]
 23%|██▎       | 7602/32777 [00:10&lt;00:34, 729.47it/s]
 23%|██▎       | 7676/32777 [00:10&lt;00:34, 729.30it/s]
 24%|██▎       | 7750/32777 [00:10&lt;00:34, 732.27it/s]
 24%|██▍       | 7824/32777 [00:10&lt;00:35, 705.62it/s]
 24%|██▍       | 7902/32777 [00:10&lt;00:34, 721.96it/s]
 24%|██▍       | 7975/32777 [00:10&lt;00:36, 672.43it/s]
 25%|██▍       | 8044/32777 [00:10&lt;00:39, 632.17it/s]
 25%|██▍       | 8125/32777 [00:10&lt;00:36, 677.77it/s]
 25%|██▌       | 8212/32777 [00:11&lt;00:33, 730.36it/s]
 25%|██▌       | 8287/32777 [00:11&lt;00:36, 663.58it/s]
 25%|██▌       | 8356/32777 [00:11&lt;00:40, 601.32it/s]
 26%|██▌       | 8419/32777 [00:11&lt;00:45, 530.31it/s]
 26%|██▌       | 8489/32777 [00:11&lt;00:42, 569.22it/s]
 26%|██▌       | 8567/32777 [00:11&lt;00:39, 613.06it/s]
 26%|██▋       | 8647/32777 [00:11&lt;00:36, 661.89it/s]
 27%|██▋       | 8716/32777 [00:11&lt;00:36, 666.47it/s]
 27%|██▋       | 8792/32777 [00:12&lt;00:34, 690.73it/s]
 27%|██▋       | 8876/32777 [00:12&lt;00:32, 730.57it/s]
 27%|██▋       | 8956/32777 [00:12&lt;00:31, 750.22it/s]
 28%|██▊       | 9032/32777 [00:12&lt;00:33, 700.29it/s]
 28%|██▊       | 9104/32777 [00:12&lt;00:36, 656.35it/s]
 28%|██▊       | 9175/32777 [00:12&lt;00:35, 664.23it/s]
 28%|██▊       | 9243/32777 [00:12&lt;00:35, 664.95it/s]
 28%|██▊       | 9311/32777 [00:12&lt;00:36, 650.59it/s]
 29%|██▊       | 9377/32777 [00:12&lt;00:38, 607.40it/s]
 29%|██▉       | 9446/32777 [00:13&lt;00:37, 620.05it/s]
 29%|██▉       | 9509/32777 [00:13&lt;00:37, 621.07it/s]
 29%|██▉       | 9572/32777 [00:13&lt;00:40, 569.51it/s]
 29%|██▉       | 9641/32777 [00:13&lt;00:38, 594.32it/s]
 30%|██▉       | 9702/32777 [00:13&lt;00:38, 594.59it/s]
 30%|██▉       | 9763/32777 [00:13&lt;00:42, 544.53it/s]
 30%|██▉       | 9820/32777 [00:13&lt;00:41, 550.20it/s]
 30%|███       | 9879/32777 [00:13&lt;00:40, 560.98it/s]
 30%|███       | 9936/32777 [00:13&lt;00:41, 549.91it/s]
 30%|███       | 9992/32777 [00:14&lt;00:42, 538.50it/s]
 31%|███       | 10047/32777 [00:14&lt;00:42, 535.79it/s]
 31%|███       | 10101/32777 [00:14&lt;00:43, 525.42it/s]
 31%|███       | 10155/32777 [00:14&lt;00:43, 525.13it/s]
 31%|███       | 10220/32777 [00:14&lt;00:40, 556.43it/s]
 31%|███▏      | 10280/32777 [00:14&lt;00:39, 566.81it/s]
 32%|███▏      | 10337/32777 [00:14&lt;00:44, 500.35it/s]
 32%|███▏      | 10400/32777 [00:14&lt;00:42, 528.81it/s]
 32%|███▏      | 10467/32777 [00:14&lt;00:39, 564.03it/s]
 32%|███▏      | 10528/32777 [00:14&lt;00:38, 576.87it/s]
 32%|███▏      | 10600/32777 [00:15&lt;00:35, 617.30it/s]
 33%|███▎      | 10663/32777 [00:15&lt;00:35, 619.90it/s]
 33%|███▎      | 10731/32777 [00:15&lt;00:34, 630.75it/s]
 33%|███▎      | 10800/32777 [00:15&lt;00:33, 647.57it/s]
 33%|███▎      | 10866/32777 [00:15&lt;00:34, 640.35it/s]
 33%|███▎      | 10947/32777 [00:15&lt;00:31, 689.58it/s]
 34%|███▎      | 11017/32777 [00:15&lt;00:32, 679.48it/s]
 34%|███▍      | 11086/32777 [00:15&lt;00:36, 595.53it/s]
 34%|███▍      | 11148/32777 [00:15&lt;00:37, 569.63it/s]
 34%|███▍      | 11212/32777 [00:16&lt;00:36, 587.69it/s]
 34%|███▍      | 11273/32777 [00:16&lt;00:36, 581.72it/s]
 35%|███▍      | 11333/32777 [00:16&lt;00:39, 547.72it/s]
 35%|███▍      | 11411/32777 [00:16&lt;00:35, 609.34it/s]
 35%|███▌      | 11474/32777 [00:16&lt;00:35, 592.01it/s]
 35%|███▌      | 11539/32777 [00:16&lt;00:35, 605.03it/s]
 35%|███▌      | 11617/32777 [00:16&lt;00:32, 647.12it/s]
 36%|███▌      | 11685/32777 [00:16&lt;00:32, 653.54it/s]
 36%|███▌      | 11751/32777 [00:16&lt;00:34, 605.07it/s]
 36%|███▌      | 11813/32777 [00:17&lt;00:36, 578.19it/s]
 36%|███▋      | 11895/32777 [00:17&lt;00:32, 642.23it/s]
 36%|███▋      | 11961/32777 [00:17&lt;00:32, 645.17it/s]
 37%|███▋      | 12027/32777 [00:17&lt;00:35, 580.42it/s]
 37%|███▋      | 12088/32777 [00:17&lt;00:35, 580.40it/s]
 37%|███▋      | 12155/32777 [00:17&lt;00:34, 600.89it/s]
 37%|███▋      | 12217/32777 [00:17&lt;00:34, 591.25it/s]
 37%|███▋      | 12279/32777 [00:17&lt;00:34, 596.29it/s]
 38%|███▊      | 12361/32777 [00:17&lt;00:31, 657.12it/s]
 38%|███▊      | 12450/32777 [00:18&lt;00:28, 719.08it/s]
 38%|███▊      | 12523/32777 [00:18&lt;00:28, 710.14it/s]
 38%|███▊      | 12595/32777 [00:18&lt;00:29, 686.28it/s]
 39%|███▊      | 12671/32777 [00:18&lt;00:28, 705.19it/s]
 39%|███▉      | 12742/32777 [00:18&lt;00:31, 645.54it/s]
 39%|███▉      | 12808/32777 [00:18&lt;00:32, 616.24it/s]
 39%|███▉      | 12892/32777 [00:18&lt;00:29, 670.30it/s]
 40%|███▉      | 12985/32777 [00:18&lt;00:26, 740.51it/s]
 40%|███▉      | 13061/32777 [00:18&lt;00:28, 695.38it/s]
 40%|████      | 13146/32777 [00:19&lt;00:26, 729.60it/s]
 40%|████      | 13221/32777 [00:19&lt;00:29, 672.83it/s]
 41%|████      | 13301/32777 [00:19&lt;00:27, 702.82it/s]
 41%|████      | 13373/32777 [00:19&lt;00:27, 696.23it/s]
 41%|████      | 13444/32777 [00:19&lt;00:29, 646.38it/s]
 41%|████      | 13510/32777 [00:19&lt;00:29, 649.25it/s]
 41%|████▏     | 13588/32777 [00:19&lt;00:28, 679.09it/s]
 42%|████▏     | 13670/32777 [00:19&lt;00:26, 712.20it/s]
 42%|████▏     | 13742/32777 [00:19&lt;00:26, 713.09it/s]
 42%|████▏     | 13825/32777 [00:20&lt;00:25, 745.54it/s]
 42%|████▏     | 13900/32777 [00:20&lt;00:25, 729.51it/s]
 43%|████▎     | 13979/32777 [00:20&lt;00:25, 741.02it/s]
 43%|████▎     | 14054/32777 [00:20&lt;00:26, 718.15it/s]
 43%|████▎     | 14140/32777 [00:20&lt;00:24, 755.77it/s]
 43%|████▎     | 14216/32777 [00:20&lt;00:28, 649.60it/s]
 44%|████▎     | 14287/32777 [00:20&lt;00:28, 658.12it/s]
 44%|████▍     | 14366/32777 [00:20&lt;00:26, 686.84it/s]
 44%|████▍     | 14464/32777 [00:20&lt;00:23, 765.88it/s]
 44%|████▍     | 14543/32777 [00:21&lt;00:24, 744.26it/s]
 45%|████▍     | 14619/32777 [00:21&lt;00:25, 718.66it/s]
 45%|████▍     | 14694/32777 [00:21&lt;00:24, 727.12it/s]
 45%|████▌     | 14785/32777 [00:21&lt;00:23, 778.88it/s]
 45%|████▌     | 14864/32777 [00:21&lt;00:23, 754.86it/s]
 46%|████▌     | 14941/32777 [00:21&lt;00:26, 669.72it/s]
 46%|████▌     | 15011/32777 [00:21&lt;00:30, 585.70it/s]
 46%|████▌     | 15080/32777 [00:21&lt;00:28, 610.47it/s]
 46%|████▌     | 15148/32777 [00:21&lt;00:28, 624.39it/s]
 46%|████▋     | 15216/32777 [00:22&lt;00:27, 637.86it/s]
 47%|████▋     | 15282/32777 [00:22&lt;00:28, 622.96it/s]
 47%|████▋     | 15346/32777 [00:22&lt;00:29, 592.49it/s]
 47%|████▋     | 15410/32777 [00:22&lt;00:28, 604.30it/s]
 47%|████▋     | 15473/32777 [00:22&lt;00:28, 608.73it/s]
 47%|████▋     | 15552/32777 [00:22&lt;00:26, 657.74it/s]
 48%|████▊     | 15636/32777 [00:22&lt;00:24, 706.78it/s]
 48%|████▊     | 15708/32777 [00:22&lt;00:24, 710.27it/s]
 48%|████▊     | 15780/32777 [00:22&lt;00:24, 701.26it/s]
 48%|████▊     | 15851/32777 [00:23&lt;00:27, 623.74it/s]
 49%|████▊     | 15943/32777 [00:23&lt;00:23, 703.26it/s]
 49%|████▉     | 16016/32777 [00:23&lt;00:26, 637.17it/s]
 49%|████▉     | 16092/32777 [00:23&lt;00:24, 668.54it/s]
 49%|████▉     | 16161/32777 [00:23&lt;00:25, 643.43it/s]
 50%|████▉     | 16250/32777 [00:23&lt;00:23, 709.53it/s]
 50%|████▉     | 16329/32777 [00:23&lt;00:22, 729.11it/s]
 50%|█████     | 16404/32777 [00:23&lt;00:25, 647.50it/s]
 50%|█████     | 16475/32777 [00:23&lt;00:24, 660.86it/s]
 51%|█████     | 16557/32777 [00:24&lt;00:23, 700.09it/s]
 51%|█████     | 16629/32777 [00:24&lt;00:23, 701.78it/s]
 51%|█████     | 16701/32777 [00:24&lt;00:25, 632.10it/s]
 51%|█████     | 16767/32777 [00:24&lt;00:25, 624.36it/s]
 51%|█████▏    | 16831/32777 [00:24&lt;00:26, 594.14it/s]
 52%|█████▏    | 16906/32777 [00:24&lt;00:25, 634.17it/s]
 52%|█████▏    | 16992/32777 [00:24&lt;00:22, 692.45it/s]
 52%|█████▏    | 17086/32777 [00:24&lt;00:20, 758.91it/s]
 52%|█████▏    | 17164/32777 [00:24&lt;00:21, 710.30it/s]
 53%|█████▎    | 17237/32777 [00:25&lt;00:22, 679.82it/s]
 53%|█████▎    | 17308/32777 [00:25&lt;00:22, 687.48it/s]
 53%|█████▎    | 17378/32777 [00:25&lt;00:23, 644.21it/s]
 53%|█████▎    | 17448/32777 [00:25&lt;00:23, 652.13it/s]
 53%|█████▎    | 17514/32777 [00:25&lt;00:23, 650.47it/s]
 54%|█████▎    | 17584/32777 [00:25&lt;00:22, 661.46it/s]
 54%|█████▍    | 17651/32777 [00:25&lt;00:24, 615.93it/s]
 54%|█████▍    | 17714/32777 [00:25&lt;00:27, 550.14it/s]
 54%|█████▍    | 17777/32777 [00:26&lt;00:26, 569.80it/s]
 54%|█████▍    | 17840/32777 [00:26&lt;00:25, 582.25it/s]
 55%|█████▍    | 17912/32777 [00:26&lt;00:23, 619.82it/s]
 55%|█████▍    | 17976/32777 [00:26&lt;00:25, 583.03it/s]
 55%|█████▌    | 18036/32777 [00:26&lt;00:26, 559.63it/s]
 55%|█████▌    | 18094/32777 [00:26&lt;00:26, 556.74it/s]
 55%|█████▌    | 18151/32777 [00:26&lt;00:28, 510.82it/s]
 56%|█████▌    | 18215/32777 [00:26&lt;00:26, 541.61it/s]
 56%|█████▌    | 18271/32777 [00:26&lt;00:28, 501.04it/s]
 56%|█████▌    | 18345/32777 [00:27&lt;00:25, 559.12it/s]
 56%|█████▌    | 18403/32777 [00:27&lt;00:25, 558.96it/s]
 56%|█████▋    | 18464/32777 [00:27&lt;00:25, 568.78it/s]
 57%|█████▋    | 18535/32777 [00:27&lt;00:23, 606.27it/s]
 57%|█████▋    | 18636/32777 [00:27&lt;00:19, 719.79it/s]
 57%|█████▋    | 18709/32777 [00:27&lt;00:20, 693.62it/s]
 57%|█████▋    | 18780/32777 [00:27&lt;00:23, 605.88it/s]
 57%|█████▋    | 18843/32777 [00:27&lt;00:24, 567.90it/s]
 58%|█████▊    | 18915/32777 [00:27&lt;00:23, 602.40it/s]
 58%|█████▊    | 18991/32777 [00:28&lt;00:21, 641.64it/s]
 58%|█████▊    | 19057/32777 [00:28&lt;00:23, 576.57it/s]
 58%|█████▊    | 19117/32777 [00:28&lt;00:23, 581.85it/s]
 59%|█████▊    | 19190/32777 [00:28&lt;00:21, 621.02it/s]
 59%|█████▉    | 19263/32777 [00:28&lt;00:20, 648.94it/s]
 59%|█████▉    | 19330/32777 [00:28&lt;00:20, 641.99it/s]
 59%|█████▉    | 19411/32777 [00:28&lt;00:19, 681.04it/s]
 59%|█████▉    | 19488/32777 [00:28&lt;00:19, 696.17it/s]
 60%|█████▉    | 19559/32777 [00:28&lt;00:21, 606.02it/s]
 60%|█████▉    | 19622/32777 [00:29&lt;00:21, 609.42it/s]
 60%|██████    | 19711/32777 [00:29&lt;00:19, 680.42it/s]
 60%|██████    | 19781/32777 [00:29&lt;00:19, 668.08it/s]
 61%|██████    | 19850/32777 [00:29&lt;00:20, 631.59it/s]
 61%|██████    | 19915/32777 [00:29&lt;00:21, 604.51it/s]
 61%|██████    | 19983/32777 [00:29&lt;00:20, 621.12it/s]
 61%|██████    | 20046/32777 [00:29&lt;00:22, 572.15it/s]
 61%|██████▏   | 20105/32777 [00:29&lt;00:23, 537.26it/s]
 62%|██████▏   | 20182/32777 [00:29&lt;00:21, 592.74it/s]
 62%|██████▏   | 20248/32777 [00:30&lt;00:20, 609.52it/s]
 62%|██████▏   | 20320/32777 [00:30&lt;00:19, 634.79it/s]
 62%|██████▏   | 20385/32777 [00:30&lt;00:20, 615.23it/s]
 62%|██████▏   | 20448/32777 [00:30&lt;00:20, 610.20it/s]
 63%|██████▎   | 20510/32777 [00:30&lt;00:20, 609.77it/s]
 63%|██████▎   | 20595/32777 [00:30&lt;00:17, 678.11it/s]
 63%|██████▎   | 20679/32777 [00:30&lt;00:16, 717.95it/s]
 63%|██████▎   | 20766/32777 [00:30&lt;00:15, 761.26it/s]
 64%|██████▎   | 20843/32777 [00:30&lt;00:15, 754.96it/s]
 64%|██████▍   | 20929/32777 [00:31&lt;00:15, 780.10it/s]
 64%|██████▍   | 21008/32777 [00:31&lt;00:16, 721.63it/s]
 64%|██████▍   | 21095/32777 [00:31&lt;00:15, 757.11it/s]
 65%|██████▍   | 21172/32777 [00:31&lt;00:15, 728.55it/s]
 65%|██████▍   | 21246/32777 [00:31&lt;00:15, 731.69it/s]
 65%|██████▌   | 21320/32777 [00:31&lt;00:15, 733.57it/s]
 65%|██████▌   | 21401/32777 [00:31&lt;00:15, 754.88it/s]
 66%|██████▌   | 21507/32777 [00:31&lt;00:13, 841.31it/s]
 66%|██████▌   | 21592/32777 [00:31&lt;00:13, 832.54it/s]
 66%|██████▌   | 21690/32777 [00:31&lt;00:12, 867.55it/s]
 66%|██████▋   | 21777/32777 [00:32&lt;00:13, 813.34it/s]
 67%|██████▋   | 21860/32777 [00:32&lt;00:19, 553.92it/s]
 67%|██████▋   | 21927/32777 [00:32&lt;00:18, 572.84it/s]
 67%|██████▋   | 21993/32777 [00:32&lt;00:18, 567.62it/s]
 67%|██████▋   | 22070/32777 [00:32&lt;00:17, 612.75it/s]
 68%|██████▊   | 22140/32777 [00:32&lt;00:16, 632.39it/s]
 68%|██████▊   | 22214/32777 [00:32&lt;00:16, 660.18it/s]
 68%|██████▊   | 22284/32777 [00:33&lt;00:16, 650.88it/s]
 68%|██████▊   | 22352/32777 [00:33&lt;00:16, 635.79it/s]
 68%|██████▊   | 22418/32777 [00:33&lt;00:17, 606.45it/s]
 69%|██████▊   | 22480/32777 [00:33&lt;00:18, 571.47it/s]
 69%|██████▉   | 22573/32777 [00:33&lt;00:15, 664.45it/s]
 69%|██████▉   | 22647/32777 [00:33&lt;00:14, 677.87it/s]
 69%|██████▉   | 22717/32777 [00:33&lt;00:14, 680.10it/s]
 70%|██████▉   | 22793/32777 [00:33&lt;00:14, 702.20it/s]
 70%|██████▉   | 22871/32777 [00:33&lt;00:13, 715.95it/s]
 70%|███████   | 22951/32777 [00:33&lt;00:13, 737.68it/s]
 70%|███████   | 23055/32777 [00:34&lt;00:11, 820.94it/s]
 71%|███████   | 23140/32777 [00:34&lt;00:11, 824.00it/s]
 71%|███████   | 23223/32777 [00:34&lt;00:12, 775.81it/s]
 71%|███████   | 23302/32777 [00:34&lt;00:12, 768.80it/s]
 71%|███████▏  | 23380/32777 [00:34&lt;00:13, 721.35it/s]
 72%|███████▏  | 23453/32777 [00:34&lt;00:13, 714.34it/s]
 72%|███████▏  | 23539/32777 [00:34&lt;00:12, 752.90it/s]
 72%|███████▏  | 23650/32777 [00:34&lt;00:10, 852.27it/s]
 72%|███████▏  | 23737/32777 [00:34&lt;00:11, 779.69it/s]
 73%|███████▎  | 23843/32777 [00:35&lt;00:10, 851.60it/s]
 73%|███████▎  | 23933/32777 [00:35&lt;00:10, 851.33it/s]
 73%|███████▎  | 24020/32777 [00:35&lt;00:10, 813.51it/s]
 74%|███████▎  | 24103/32777 [00:35&lt;00:11, 780.76it/s]
 74%|███████▍  | 24182/32777 [00:35&lt;00:11, 751.50it/s]
 74%|███████▍  | 24259/32777 [00:35&lt;00:11, 751.72it/s]
 74%|███████▍  | 24338/32777 [00:35&lt;00:11, 751.00it/s]
 74%|███████▍  | 24414/32777 [00:35&lt;00:11, 731.62it/s]
 75%|███████▍  | 24488/32777 [00:35&lt;00:11, 696.19it/s]
 75%|███████▍  | 24558/32777 [00:36&lt;00:11, 687.40it/s]
 75%|███████▌  | 24654/32777 [00:36&lt;00:10, 759.38it/s]
 76%|███████▌  | 24749/32777 [00:36&lt;00:09, 811.17it/s]
 76%|███████▌  | 24831/32777 [00:36&lt;00:10, 775.74it/s]
 76%|███████▌  | 24910/32777 [00:36&lt;00:10, 745.55it/s]
 76%|███████▋  | 25004/32777 [00:36&lt;00:09, 793.81it/s]
 77%|███████▋  | 25085/32777 [00:36&lt;00:10, 751.29it/s]
 77%|███████▋  | 25161/32777 [00:36&lt;00:10, 749.48it/s]
 77%|███████▋  | 25252/32777 [00:36&lt;00:09, 783.28it/s]
 77%|███████▋  | 25331/32777 [00:37&lt;00:09, 768.33it/s]
 78%|███████▊  | 25409/32777 [00:37&lt;00:10, 736.53it/s]
 78%|███████▊  | 25514/32777 [00:37&lt;00:08, 815.97it/s]
 78%|███████▊  | 25597/32777 [00:37&lt;00:09, 781.08it/s]
 78%|███████▊  | 25676/32777 [00:37&lt;00:09, 769.02it/s]
 79%|███████▊  | 25758/32777 [00:37&lt;00:09, 778.47it/s]
 79%|███████▉  | 25837/32777 [00:37&lt;00:09, 764.30it/s]
 79%|███████▉  | 25928/32777 [00:37&lt;00:08, 796.31it/s]
 79%|███████▉  | 26008/32777 [00:37&lt;00:08, 791.96it/s]
 80%|███████▉  | 26088/32777 [00:38&lt;00:09, 686.75it/s]
 80%|███████▉  | 26177/32777 [00:38&lt;00:08, 740.15it/s]
 80%|████████  | 26254/32777 [00:38&lt;00:08, 741.22it/s]
 80%|████████  | 26330/32777 [00:38&lt;00:08, 721.49it/s]
 81%|████████  | 26404/32777 [00:38&lt;00:09, 686.57it/s]
 81%|████████  | 26474/32777 [00:38&lt;00:10, 618.17it/s]
 81%|████████  | 26556/32777 [00:38&lt;00:09, 669.08it/s]
 81%|████████▏ | 26648/32777 [00:38&lt;00:08, 734.66it/s]
 82%|████████▏ | 26724/32777 [00:38&lt;00:08, 739.92it/s]
 82%|████████▏ | 26803/32777 [00:39&lt;00:07, 749.74it/s]
 82%|████████▏ | 26893/32777 [00:39&lt;00:07, 789.17it/s]
 82%|████████▏ | 27001/32777 [00:39&lt;00:06, 866.83it/s]
 83%|████████▎ | 27089/32777 [00:39&lt;00:06, 861.69it/s]
 83%|████████▎ | 27176/32777 [00:39&lt;00:06, 822.57it/s]
 83%|████████▎ | 27279/32777 [00:39&lt;00:06, 877.09it/s]
 83%|████████▎ | 27368/32777 [00:39&lt;00:07, 738.12it/s]
 84%|████████▎ | 27446/32777 [00:39&lt;00:07, 737.37it/s]
 84%|████████▍ | 27523/32777 [00:39&lt;00:07, 725.51it/s]
 84%|████████▍ | 27607/32777 [00:40&lt;00:06, 751.02it/s]
 85%|████████▍ | 27698/32777 [00:40&lt;00:06, 793.42it/s]
 85%|████████▍ | 27779/32777 [00:40&lt;00:06, 789.34it/s]
 85%|████████▌ | 27864/32777 [00:40&lt;00:06, 804.03it/s]
 85%|████████▌ | 27961/32777 [00:40&lt;00:05, 851.61it/s]
 86%|████████▌ | 28047/32777 [00:40&lt;00:05, 824.42it/s]
 86%|████████▌ | 28131/32777 [00:40&lt;00:05, 800.87it/s]
 86%|████████▌ | 28212/32777 [00:40&lt;00:06, 717.42it/s]
 86%|████████▋ | 28286/32777 [00:40&lt;00:06, 708.28it/s]
 87%|████████▋ | 28359/32777 [00:41&lt;00:06, 641.77it/s]
 87%|████████▋ | 28425/32777 [00:41&lt;00:06, 626.61it/s]
 87%|████████▋ | 28511/32777 [00:41&lt;00:06, 687.75it/s]
 87%|████████▋ | 28583/32777 [00:41&lt;00:06, 692.66it/s]
 87%|████████▋ | 28665/32777 [00:41&lt;00:05, 718.37it/s]
 88%|████████▊ | 28738/32777 [00:41&lt;00:06, 655.23it/s]
 88%|████████▊ | 28810/32777 [00:41&lt;00:05, 663.11it/s]
 88%|████████▊ | 28888/32777 [00:41&lt;00:05, 694.69it/s]
 88%|████████▊ | 28977/32777 [00:41&lt;00:05, 732.41it/s]
 89%|████████▊ | 29067/32777 [00:42&lt;00:04, 774.02it/s]
 89%|████████▉ | 29146/32777 [00:42&lt;00:04, 754.43it/s]
 89%|████████▉ | 29223/32777 [00:42&lt;00:04, 726.24it/s]
 89%|████████▉ | 29300/32777 [00:42&lt;00:04, 738.29it/s]
 90%|████████▉ | 29375/32777 [00:42&lt;00:04, 734.18it/s]
 90%|████████▉ | 29449/32777 [00:42&lt;00:04, 703.19it/s]
 90%|█████████ | 29543/32777 [00:42&lt;00:04, 766.19it/s]
 90%|█████████ | 29621/32777 [00:42&lt;00:04, 724.18it/s]
 91%|█████████ | 29701/32777 [00:42&lt;00:04, 741.34it/s]
 91%|█████████ | 29776/32777 [00:43&lt;00:04, 725.80it/s]
 91%|█████████ | 29850/32777 [00:43&lt;00:04, 698.84it/s]
 91%|█████████▏| 29930/32777 [00:43&lt;00:03, 725.59it/s]
 92%|█████████▏| 30007/32777 [00:43&lt;00:03, 726.15it/s]
 92%|█████████▏| 30083/32777 [00:43&lt;00:03, 735.58it/s]
 92%|█████████▏| 30166/32777 [00:43&lt;00:03, 752.46it/s]
 92%|█████████▏| 30242/32777 [00:43&lt;00:03, 706.27it/s]
 93%|█████████▎| 30326/32777 [00:43&lt;00:03, 743.09it/s]
 93%|█████████▎| 30411/32777 [00:43&lt;00:03, 769.29it/s]
 93%|█████████▎| 30497/32777 [00:44&lt;00:02, 792.43it/s]
 93%|█████████▎| 30588/32777 [00:44&lt;00:02, 825.01it/s]
 94%|█████████▎| 30671/32777 [00:44&lt;00:02, 776.57it/s]
 94%|█████████▍| 30756/32777 [00:44&lt;00:02, 794.37it/s]
 94%|█████████▍| 30853/32777 [00:44&lt;00:02, 842.18it/s]
 94%|█████████▍| 30938/32777 [00:44&lt;00:02, 813.28it/s]
 95%|█████████▍| 31020/32777 [00:44&lt;00:02, 800.53it/s]
 95%|█████████▍| 31101/32777 [00:44&lt;00:02, 736.31it/s]
 95%|█████████▌| 31185/32777 [00:44&lt;00:02, 762.33it/s]
 95%|█████████▌| 31285/32777 [00:44&lt;00:01, 813.56it/s]
 96%|█████████▌| 31368/32777 [00:45&lt;00:01, 807.72it/s]
 96%|█████████▌| 31488/32777 [00:45&lt;00:01, 914.50it/s]
 96%|█████████▋| 31581/32777 [00:45&lt;00:01, 832.43it/s]
 97%|█████████▋| 31667/32777 [00:45&lt;00:01, 774.80it/s]
 97%|█████████▋| 31747/32777 [00:45&lt;00:01, 766.03it/s]
 97%|█████████▋| 31825/32777 [00:45&lt;00:01, 702.23it/s]
 97%|█████████▋| 31897/32777 [00:45&lt;00:01, 664.19it/s]
 98%|█████████▊| 31968/32777 [00:45&lt;00:01, 673.72it/s]
 98%|█████████▊| 32037/32777 [00:46&lt;00:01, 658.81it/s]
 98%|█████████▊| 32106/32777 [00:46&lt;00:01, 663.28it/s]
 98%|█████████▊| 32173/32777 [00:46&lt;00:00, 660.54it/s]
 98%|█████████▊| 32240/32777 [00:46&lt;00:00, 591.43it/s]
 99%|█████████▊| 32307/32777 [00:46&lt;00:00, 605.93it/s]
 99%|█████████▉| 32389/32777 [00:46&lt;00:00, 656.98it/s]
 99%|█████████▉| 32493/32777 [00:46&lt;00:00, 762.33it/s]
 99%|█████████▉| 32573/32777 [00:46&lt;00:00, 766.54it/s]
100%|█████████▉| 32667/32777 [00:46&lt;00:00, 810.79it/s]
100%|█████████▉| 32755/32777 [00:47&lt;00:00, 830.28it/s]
100%|██████████| 32777/32777 [00:47&lt;00:00, 696.80it/s]
</pre></div>
</div>
</div>
</div>
</section>
<section id="configure-the-dataset-for-performance">
<h3>Configure the dataset for performance<a class="headerlink" href="#configure-the-dataset-for-performance" title="Permalink to this heading">#</a></h3>
<p>To perform efficient batching for the potentially large number of training examples, use the <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> API. After this step, you would have a <code class="docutils literal notranslate"><span class="pre">tf.data.Dataset</span></code> object of <code class="docutils literal notranslate"><span class="pre">(target_word,</span> <span class="pre">context_word),</span> <span class="pre">(label)</span></code> elements to train your word2vec model!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="n">BUFFER_SIZE</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(((</span><span class="n">targets</span><span class="p">,</span> <span class="n">contexts</span><span class="p">),</span> <span class="n">labels</span><span class="p">))</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">BUFFER_SIZE</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">drop_remainder</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))&gt;
</pre></div>
</div>
</div>
</div>
<p>Apply <code class="docutils literal notranslate"><span class="pre">Dataset.cache</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataset.prefetch</span></code> to improve performance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">AUTOTUNE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="model-and-training">
<h2>Model and training<a class="headerlink" href="#model-and-training" title="Permalink to this heading">#</a></h2>
<p>The word2vec model can be implemented as a classifier to distinguish between true context words from skip-grams and false context words obtained through negative sampling. You can perform a dot product multiplication between the embeddings of target and context words to obtain predictions for labels and compute the loss function against true labels in the dataset.</p>
<section id="subclassed-word2vec-model">
<h3>Subclassed word2vec model<a class="headerlink" href="#subclassed-word2vec-model" title="Permalink to this heading">#</a></h3>
<p>Use the <a class="reference external" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models">Keras Subclassing API</a> to define your word2vec model with the following layers:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">target_embedding</span></code>: A <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Embedding</span></code> layer, which looks up the embedding of a word when it appears as a target word. The number of parameters in this layer are <code class="docutils literal notranslate"><span class="pre">(vocab_size</span> <span class="pre">*</span> <span class="pre">embedding_dim)</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">context_embedding</span></code>: Another <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Embedding</span></code> layer, which looks up the embedding of a word when it appears as a context word. The number of parameters in this layer are the same as those in <code class="docutils literal notranslate"><span class="pre">target_embedding</span></code>, i.e. <code class="docutils literal notranslate"><span class="pre">(vocab_size</span> <span class="pre">*</span> <span class="pre">embedding_dim)</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dots</span></code>: A <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Dot</span></code> layer that computes the dot product of target and context embeddings from a training pair.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flatten</span></code>: A <code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Flatten</span></code> layer to flatten the results of <code class="docutils literal notranslate"><span class="pre">dots</span></code> layer into logits.</p></li>
</ul>
<p>With the subclassed model, you can define the <code class="docutils literal notranslate"><span class="pre">call()</span></code> function that accepts <code class="docutils literal notranslate"><span class="pre">(target,</span> <span class="pre">context)</span></code> pairs which can then be passed into their corresponding embedding layer. Reshape the <code class="docutils literal notranslate"><span class="pre">context_embedding</span></code> to perform a dot product with <code class="docutils literal notranslate"><span class="pre">target_embedding</span></code> and return the flattened result.</p>
<p>Key point: The <code class="docutils literal notranslate"><span class="pre">target_embedding</span></code> and <code class="docutils literal notranslate"><span class="pre">context_embedding</span></code> layers can be shared as well. You could also use a concatenation of both embeddings as the final word2vec embedding.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Word2Vec</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Word2Vec</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target_embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span>
                                      <span class="n">embedding_dim</span><span class="p">,</span>
                                      <span class="n">input_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                      <span class="n">name</span><span class="o">=</span><span class="s2">&quot;w2v_embedding&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">context_embedding</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span>
                                       <span class="n">embedding_dim</span><span class="p">,</span>
                                       <span class="n">input_length</span><span class="o">=</span><span class="n">num_ns</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pair</span><span class="p">):</span>
    <span class="n">target</span><span class="p">,</span> <span class="n">context</span> <span class="o">=</span> <span class="n">pair</span>
    <span class="c1"># target: (batch, dummy?)  # The dummy axis doesn&#39;t exist in TF2.7+</span>
    <span class="c1"># context: (batch, context)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># target: (batch,)</span>
    <span class="n">word_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_embedding</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="c1"># word_emb: (batch, embed)</span>
    <span class="n">context_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_embedding</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="c1"># context_emb: (batch, context, embed)</span>
    <span class="n">dots</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;be,bce-&gt;bc&#39;</span><span class="p">,</span> <span class="n">word_emb</span><span class="p">,</span> <span class="n">context_emb</span><span class="p">)</span>
    <span class="c1"># dots: (batch, context)</span>
    <span class="k">return</span> <span class="n">dots</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-loss-function-and-compile-model">
<h3>Define loss function and compile model<a class="headerlink" href="#define-loss-function-and-compile-model" title="Permalink to this heading">#</a></h3>
<p>For simplicity, you can use <code class="docutils literal notranslate"><span class="pre">tf.keras.losses.CategoricalCrossEntropy</span></code> as an alternative to the negative sampling loss. If you would like to write your own custom loss function, you can also do so as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">custom_loss</span><span class="p">(</span><span class="n">x_logit</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">x_logit</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y_true</span><span class="p">)</span>
</pre></div>
</div>
<p>It’s time to build your model! Instantiate your word2vec class with an embedding dimension of 128 (you could experiment with different values). Compile the model with the <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adam</span></code> optimizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">word2vec</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
<span class="n">word2vec</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
                 <span class="n">loss</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                 <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Also define a callback to log training statistics for TensorBoard:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tensorboard_callback</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;logs&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Train the model on the <code class="docutils literal notranslate"><span class="pre">dataset</span></code> for some number of epochs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">word2vec</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard_callback</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20

 1/63 [..............................] - ETA: 1:09 - loss: 1.6090 - accuracy: 0.1924
 2/63 [..............................] - ETA: 9s - loss: 1.6092 - accuracy: 0.1997  
 3/63 [&gt;.............................] - ETA: 8s - loss: 1.6092 - accuracy: 0.2002
 4/63 [&gt;.............................] - ETA: 8s - loss: 1.6092 - accuracy: 0.2000
 5/63 [=&gt;............................] - ETA: 8s - loss: 1.6092 - accuracy: 0.1980
 6/63 [=&gt;............................] - ETA: 8s - loss: 1.6092 - accuracy: 0.2021
 7/63 [==&gt;...........................] - ETA: 8s - loss: 1.6092 - accuracy: 0.2020
 8/63 [==&gt;...........................] - ETA: 8s - loss: 1.6092 - accuracy: 0.2029
 9/63 [===&gt;..........................] - ETA: 7s - loss: 1.6093 - accuracy: 0.2040
10/63 [===&gt;..........................] - ETA: 7s - loss: 1.6093 - accuracy: 0.2039
11/63 [====&gt;.........................] - ETA: 7s - loss: 1.6092 - accuracy: 0.2067
12/63 [====&gt;.........................] - ETA: 7s - loss: 1.6092 - accuracy: 0.2091
13/63 [=====&gt;........................] - ETA: 7s - loss: 1.6092 - accuracy: 0.2078
14/63 [=====&gt;........................] - ETA: 7s - loss: 1.6092 - accuracy: 0.2081
15/63 [======&gt;.......................] - ETA: 6s - loss: 1.6092 - accuracy: 0.2083
16/63 [======&gt;.......................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2097
17/63 [=======&gt;......................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2105
18/63 [=======&gt;......................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2115
19/63 [========&gt;.....................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2117
20/63 [========&gt;.....................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2124
21/63 [=========&gt;....................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2122
22/63 [=========&gt;....................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2133
23/63 [=========&gt;....................] - ETA: 6s - loss: 1.6091 - accuracy: 0.2145
24/63 [==========&gt;...................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2149
25/63 [==========&gt;...................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2146
26/63 [===========&gt;..................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2145
27/63 [===========&gt;..................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2146
28/63 [============&gt;.................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2160
29/63 [============&gt;.................] - ETA: 5s - loss: 1.6090 - accuracy: 0.2167
31/63 [=============&gt;................] - ETA: 4s - loss: 1.6089 - accuracy: 0.2177
32/63 [==============&gt;...............] - ETA: 4s - loss: 1.6089 - accuracy: 0.2181
33/63 [==============&gt;...............] - ETA: 4s - loss: 1.6089 - accuracy: 0.2182
34/63 [===============&gt;..............] - ETA: 4s - loss: 1.6088 - accuracy: 0.2188
37/63 [================&gt;.............] - ETA: 3s - loss: 1.6088 - accuracy: 0.2199
38/63 [=================&gt;............] - ETA: 3s - loss: 1.6088 - accuracy: 0.2199
39/63 [=================&gt;............] - ETA: 3s - loss: 1.6087 - accuracy: 0.2202
40/63 [==================&gt;...........] - ETA: 3s - loss: 1.6087 - accuracy: 0.2207
41/63 [==================&gt;...........] - ETA: 3s - loss: 1.6087 - accuracy: 0.2214
42/63 [===================&gt;..........] - ETA: 2s - loss: 1.6087 - accuracy: 0.2216
43/63 [===================&gt;..........] - ETA: 2s - loss: 1.6087 - accuracy: 0.2219
44/63 [===================&gt;..........] - ETA: 2s - loss: 1.6086 - accuracy: 0.2227
47/63 [=====================&gt;........] - ETA: 2s - loss: 1.6086 - accuracy: 0.2233
48/63 [=====================&gt;........] - ETA: 1s - loss: 1.6086 - accuracy: 0.2237
55/63 [=========================&gt;....] - ETA: 0s - loss: 1.6084 - accuracy: 0.2268
56/63 [=========================&gt;....] - ETA: 0s - loss: 1.6084 - accuracy: 0.2273
60/63 [===========================&gt;..] - ETA: 0s - loss: 1.6083 - accuracy: 0.2295
62/63 [============================&gt;.] - ETA: 0s - loss: 1.6082 - accuracy: 0.2307
63/63 [==============================] - ETA: 0s - loss: 1.6082 - accuracy: 0.2314
63/63 [==============================] - 8s 112ms/step - loss: 1.6082 - accuracy: 0.2314
Epoch 2/20

 1/63 [..............................] - ETA: 0s - loss: 1.5901 - accuracy: 0.7510
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.5938 - accuracy: 0.5989
39/63 [=================&gt;............] - ETA: 0s - loss: 1.5920 - accuracy: 0.5735
58/63 [==========================&gt;...] - ETA: 0s - loss: 1.5894 - accuracy: 0.5599
63/63 [==============================] - 0s 3ms/step - loss: 1.5886 - accuracy: 0.5562
Epoch 3/20

 1/63 [..............................] - ETA: 0s - loss: 1.5586 - accuracy: 0.7285
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.5575 - accuracy: 0.6493
39/63 [=================&gt;............] - ETA: 0s - loss: 1.5507 - accuracy: 0.6189
57/63 [==========================&gt;...] - ETA: 0s - loss: 1.5431 - accuracy: 0.6033
63/63 [==============================] - 0s 3ms/step - loss: 1.5403 - accuracy: 0.5982
Epoch 4/20

 1/63 [..............................] - ETA: 0s - loss: 1.4883 - accuracy: 0.6328
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.4820 - accuracy: 0.5963
39/63 [=================&gt;............] - ETA: 0s - loss: 1.4721 - accuracy: 0.5783
58/63 [==========================&gt;...] - ETA: 0s - loss: 1.4603 - accuracy: 0.5749
63/63 [==============================] - 0s 3ms/step - loss: 1.4573 - accuracy: 0.5730
Epoch 5/20

 1/63 [..............................] - ETA: 0s - loss: 1.3923 - accuracy: 0.6006
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.3834 - accuracy: 0.5872
39/63 [=================&gt;............] - ETA: 0s - loss: 1.3744 - accuracy: 0.5778
57/63 [==========================&gt;...] - ETA: 0s - loss: 1.3623 - accuracy: 0.5815
63/63 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.5810
Epoch 6/20

 1/63 [..............................] - ETA: 0s - loss: 1.2932 - accuracy: 0.6055
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.2829 - accuracy: 0.6085
39/63 [=================&gt;............] - ETA: 0s - loss: 1.2760 - accuracy: 0.6043
58/63 [==========================&gt;...] - ETA: 0s - loss: 1.2639 - accuracy: 0.6096
63/63 [==============================] - 0s 3ms/step - loss: 1.2615 - accuracy: 0.6101
Epoch 7/20

 1/63 [..............................] - ETA: 0s - loss: 1.2011 - accuracy: 0.6357
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.1888 - accuracy: 0.6427
39/63 [=================&gt;............] - ETA: 0s - loss: 1.1835 - accuracy: 0.6400
58/63 [==========================&gt;...] - ETA: 0s - loss: 1.1723 - accuracy: 0.6448
63/63 [==============================] - 0s 3ms/step - loss: 1.1704 - accuracy: 0.6450
Epoch 8/20

 1/63 [..............................] - ETA: 0s - loss: 1.1166 - accuracy: 0.6689
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.1020 - accuracy: 0.6766
39/63 [=================&gt;............] - ETA: 0s - loss: 1.0978 - accuracy: 0.6744
58/63 [==========================&gt;...] - ETA: 0s - loss: 1.0874 - accuracy: 0.6791
63/63 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.6794
Epoch 9/20

 1/63 [..............................] - ETA: 0s - loss: 1.0387 - accuracy: 0.6982
20/63 [========&gt;.....................] - ETA: 0s - loss: 1.0220 - accuracy: 0.7100
40/63 [==================&gt;...........] - ETA: 0s - loss: 1.0179 - accuracy: 0.7067
59/63 [===========================&gt;..] - ETA: 0s - loss: 1.0084 - accuracy: 0.7106
63/63 [==============================] - 0s 3ms/step - loss: 1.0075 - accuracy: 0.7106
Epoch 10/20

 1/63 [..............................] - ETA: 0s - loss: 0.9666 - accuracy: 0.7324
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.9481 - accuracy: 0.7414
39/63 [=================&gt;............] - ETA: 0s - loss: 0.9445 - accuracy: 0.7384
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.9357 - accuracy: 0.7414
63/63 [==============================] - 0s 3ms/step - loss: 0.9348 - accuracy: 0.7413
Epoch 11/20

 1/63 [..............................] - ETA: 0s - loss: 0.8997 - accuracy: 0.7549
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.8798 - accuracy: 0.7657
39/63 [=================&gt;............] - ETA: 0s - loss: 0.8763 - accuracy: 0.7638
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.8683 - accuracy: 0.7661
63/63 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.7657
Epoch 12/20

 1/63 [..............................] - ETA: 0s - loss: 0.8376 - accuracy: 0.7764
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.8170 - accuracy: 0.7875
39/63 [=================&gt;............] - ETA: 0s - loss: 0.8133 - accuracy: 0.7856
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.8060 - accuracy: 0.7874
63/63 [==============================] - 0s 3ms/step - loss: 0.8056 - accuracy: 0.7871
Epoch 13/20

 1/63 [..............................] - ETA: 0s - loss: 0.7802 - accuracy: 0.7910
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.7592 - accuracy: 0.8057
39/63 [=================&gt;............] - ETA: 0s - loss: 0.7554 - accuracy: 0.8050
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.7488 - accuracy: 0.8070
63/63 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.8069
Epoch 14/20

 1/63 [..............................] - ETA: 0s - loss: 0.7272 - accuracy: 0.8105
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.7063 - accuracy: 0.8236
39/63 [=================&gt;............] - ETA: 0s - loss: 0.7022 - accuracy: 0.8241
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.6964 - accuracy: 0.8260
63/63 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.8258
Epoch 15/20

 1/63 [..............................] - ETA: 0s - loss: 0.6785 - accuracy: 0.8242
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.6579 - accuracy: 0.8401
39/63 [=================&gt;............] - ETA: 0s - loss: 0.6536 - accuracy: 0.8408
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.6484 - accuracy: 0.8417
63/63 [==============================] - 0s 3ms/step - loss: 0.6484 - accuracy: 0.8415
Epoch 16/20

 1/63 [..............................] - ETA: 0s - loss: 0.6337 - accuracy: 0.8428
21/63 [=========&gt;....................] - ETA: 0s - loss: 0.6139 - accuracy: 0.8523
41/63 [==================&gt;...........] - ETA: 0s - loss: 0.6092 - accuracy: 0.8538
61/63 [============================&gt;.] - ETA: 0s - loss: 0.6049 - accuracy: 0.8548
63/63 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.8549
Epoch 17/20

 1/63 [..............................] - ETA: 0s - loss: 0.5926 - accuracy: 0.8555
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.5735 - accuracy: 0.8662
39/63 [=================&gt;............] - ETA: 0s - loss: 0.5689 - accuracy: 0.8665
57/63 [==========================&gt;...] - ETA: 0s - loss: 0.5648 - accuracy: 0.8673
63/63 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.8671
Epoch 18/20

 1/63 [..............................] - ETA: 0s - loss: 0.5551 - accuracy: 0.8662
21/63 [=========&gt;....................] - ETA: 0s - loss: 0.5367 - accuracy: 0.8756
41/63 [==================&gt;...........] - ETA: 0s - loss: 0.5321 - accuracy: 0.8769
60/63 [===========================&gt;..] - ETA: 0s - loss: 0.5288 - accuracy: 0.8773
63/63 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.8775
Epoch 19/20

 1/63 [..............................] - ETA: 0s - loss: 0.5209 - accuracy: 0.8770
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.5035 - accuracy: 0.8837
39/63 [=================&gt;............] - ETA: 0s - loss: 0.4988 - accuracy: 0.8851
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.4955 - accuracy: 0.8863
63/63 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.8864
Epoch 20/20

 1/63 [..............................] - ETA: 0s - loss: 0.4896 - accuracy: 0.8828
20/63 [========&gt;.....................] - ETA: 0s - loss: 0.4731 - accuracy: 0.8933
39/63 [=================&gt;............] - ETA: 0s - loss: 0.4684 - accuracy: 0.8950
58/63 [==========================&gt;...] - ETA: 0s - loss: 0.4655 - accuracy: 0.8959
63/63 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.8959
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;keras.callbacks.History at 0x7f6bd0344f70&gt;
</pre></div>
</div>
</div>
</div>
<p>TensorBoard now shows the word2vec model’s accuracy and loss:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#docs_infra: no_execute</span>
<span class="o">%</span><span class="k">tensorboard</span> --logdir logs
</pre></div>
</div>
</div>
</div>
<!-- <img class="tfo-display-only-on-site" src="images/word2vec_tensorboard.png"/> --></section>
</section>
<section id="embedding-lookup-and-analysis">
<h2>Embedding lookup and analysis<a class="headerlink" href="#embedding-lookup-and-analysis" title="Permalink to this heading">#</a></h2>
<p>Obtain the weights from the model using <code class="docutils literal notranslate"><span class="pre">Model.get_layer</span></code> and <code class="docutils literal notranslate"><span class="pre">Layer.get_weights</span></code>. The <code class="docutils literal notranslate"><span class="pre">TextVectorization.get_vocabulary</span></code> function provides the vocabulary to build a metadata file with one token per line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">word2vec</span><span class="o">.</span><span class="n">get_layer</span><span class="p">(</span><span class="s1">&#39;w2v_embedding&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="n">vectorize_layer</span><span class="o">.</span><span class="n">get_vocabulary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Create and save the vectors and metadata files:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out_v</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;vectors.tsv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">out_m</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;metadata.tsv&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vocab</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">continue</span>  <span class="c1"># skip 0, it&#39;s padding.</span>
  <span class="n">vec</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
  <span class="n">out_v</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">out_m</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">word</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">out_v</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">out_m</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Download the <code class="docutils literal notranslate"><span class="pre">vectors.tsv</span></code> and <code class="docutils literal notranslate"><span class="pre">metadata.tsv</span></code> to analyze the obtained embeddings in the <a class="reference external" href="https://projector.tensorflow.org/">Embedding Projector</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
  <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
  <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;vectors.tsv&#39;</span><span class="p">)</span>
  <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;metadata.tsv&#39;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
  <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h2>
<p>This tutorial has shown you how to implement a skip-gram word2vec model with negative sampling from scratch and visualize the obtained word embeddings.</p>
<ul class="simple">
<li><p>To learn more about word vectors and their mathematical representations, refer to these <a class="reference external" href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf">notes</a>.</p></li>
<li><p>To learn more about advanced text processing, read the <a class="reference external" href="https://www.tensorflow.org/tutorials/text/transformer">Transformer model for language understanding</a> tutorial.</p></li>
<li><p>If you’re interested in pre-trained embedding models, you may also be interested in <a class="reference external" href="https://www.tensorflow.org/hub/tutorials/cord_19_embeddings_keras">Exploring the TF-Hub CORD-19 Swivel Embeddings</a>, or the <a class="reference external" href="https://www.tensorflow.org/hub/tutorials/cross_lingual_similarity_with_tf_hub_multilingual_universal_encoder">Multilingual Universal Sentence Encoder</a>.</p></li>
<li><p>You may also like to train the model on a new dataset (there are many available in <a class="reference external" href="https://www.tensorflow.org/datasets">TensorFlow Datasets</a>).</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/artificial-intelligence",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/nlp/nlp-introduction/word2vec"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="word2vec_from_scratch.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Word2Vec from scratch</p>
      </div>
    </a>
    <a class="right-next"
       href="../../language-models/_index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Language Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-and-negative-sampling">Skip-gram and negative sampling</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorize-an-example-sentence">Vectorize an example sentence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-skip-grams-from-one-sentence">Generate skip-grams from one sentence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-sampling-for-one-skip-gram">Negative sampling for one skip-gram</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#construct-one-training-example">Construct one training example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compile-all-steps-into-one-function">Compile all steps into one function</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#skip-gram-sampling-table">Skip-gram sampling table</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-training-data">Generate training data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-data-for-word2vec">Prepare training data for word2vec</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#download-text-corpus">Download text corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectorize-sentences-from-the-corpus">Vectorize sentences from the corpus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#obtain-sequences-from-the-dataset">Obtain sequences from the dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-training-examples-from-sequences">Generate training examples from sequences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-the-dataset-for-performance">Configure the dataset for performance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-training">Model and training</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subclassed-word2vec-model">Subclassed word2vec model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-loss-function-and-compile-model">Define loss function and compile model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedding-lookup-and-analysis">Embedding lookup and analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>