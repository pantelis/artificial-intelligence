
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Single-head self-attention &#8212; Introduction to Artificial Intelligence</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'aiml-common/lectures/nlp/transformers/singlehead-self-attention';</script>
    <link rel="canonical" href="https://pantelis.github.io/artificial-intelligence/aiml-common/lectures/nlp/transformers/singlehead-self-attention.html" />
    <link rel="icon" href="../../../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Multi-head self-attention" href="multihead-self-attention.html" />
    <link rel="prev" title="Transformers and Self-Attention" href="transformers-intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo.png" class="logo__image only-light" alt="Introduction to Artificial Intelligence - Home"/>
    <script>document.write(`<img src="../../../../_static/logo.png" class="logo__image only-dark" alt="Introduction to Artificial Intelligence - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="list-caption"><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to AI</span></p><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="label-parts" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/course-introduction/index.html">Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/systems-approach/index.html">The four approaches towards AI</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../ai-intro/agents/index.html">Agent-Environment Interface</a></li>



</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-1</span></p><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="label-parts" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../learning-problem/index.html">The Supervised (Inductive) Learning Problem Statement</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/sgd/index.html">Gradient Descent</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../entropy/index.html">Entropy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/marginal_maximum_likelihood.html">Maximum Likelihood Estimation of a marginal model</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/mle-gaussian-parameters.html">Maximum Likelihood Estimation of Gaussian Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/maximum-likelihood/conditional_maximum_likelihood.html">Maximum Likelihood (ML) Estimation of conditional models</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning-2</span></p><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="label-parts" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/classification-intro/index.html">Introduction to Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../classification/logistic-regression/index.html">Logistic Regression</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="label-parts" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../classification/perceptron/index.html">The Neuron (Perceptron)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/dnn-intro/index.html">Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-intro/index.html">Introduction to Backpropagation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn/index.html">Backpropagation in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/backprop-dnn-exercises/index.html">Backpropagation DNN exercises</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dnn/fashion-mnist-case-study.html">Fashion MNIST Case Study</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/index.html">Regularization in Deep Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimization/regularization/regularization-workshop-1.html">Regularization Workshop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../information-theory-dnn/index.html">Fusion of Statistical Learning Theory, Information Theory and Stochastic Optimization</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Convolutional Neural Networks</span></p><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="label-parts" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-intro/index.html">Introduction to Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-layers/index.html">CNN Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/index.html">CNN Example Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/using_convnets_with_small_datasets.html">Using convnets with small datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cnn/cnn-example-architectures/visualizing-what-convnets-learn.html">Visualizing what convnets learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/feature-extraction-resnet/index.html">Feature Extraction via Residual Networks</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Scene Understanding</span></p><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="label-parts" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../scene-understanding/scene-understanding-intro/index.html">Introduction to Scene Understanding</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/object-detection/object-detection-intro/index.html">Object Detection</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/detection-metrics/index.html">Object Detection and Semantic Segmentation Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/rcnn-object-detection/index.html">Region-CNN (RCNN) Object Detection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/object-detection/faster-rcnn-object-detection/index.html">Fast and Faster RCNN Object Detection</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/index.html">Object Det. &amp; Semantic Segm. Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/index.html">Mask R-CNN Semantic Segmentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/demo.html">Mask R-CNN Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_data.html">Mask R-CNN - Inspect Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_model.html">Mask R-CNN - Inspect Trained Model</a></li>










<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/inspect_weights.html">Mask R-CNN - Inspect Weights of a Trained Model</a></li>





<li class="toctree-l2"><a class="reference internal" href="../../scene-understanding/semantic-segmentation/maskrcnn-semantic-segmentation/detectron2_tutorial.html">Detectron2 Beginner’s Tutorial</a></li>





</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Transfer Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="label-parts" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer-learning-introduction.html">Introduction to Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../transfer-learning/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Probabilistic Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="label-parts" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rse/recursive-state-estimation/index.html">Recursive State Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rse/discrete-bayesian-filter/discrete-bayesian-filter.html">Discrete Bayes Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rse/hmm-localization/index.html">Localization and Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rse/kalman-filters/one-dimensional-kalman-filters.html">Kalman Filters</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Logical Reasoning</span></p><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="label-parts" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/automated-reasoning/index.html">Automated Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/propositional-logic/index.html">World Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/logical-inference/index.html">Logical Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logical-reasoning/logical-agents/index.html">Logical Agents</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Planning without Interactions</span></p><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="label-parts" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../planning/index.html">Automated Planning</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../planning/pddl/index.html">PDDL</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/blocksworld/up_blocksworld_demo.html">The Unified Planning Library</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/logistics/index.html">Logistics Planning in PDDL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/pddl/manufacturing/index.html">Manufacrturing Robot Planning in PDDL</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../planning/search/index.html">Search Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../planning/search/a-star/index.html">The A* Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../planning/search/search-alg-demo/index.html">Interactive Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../motion-planning-cars/index.html">Motion Planning for Autonomous Cars</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Markov Decision Processes</span></p><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="label-parts" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../mdp/index.html">Markov Decision Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/mdp-intro/mdp_intro.html">Introduction to MDP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-expectation-backup/index.html">Bellman Expectation Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/policy-evaluation/index.html">Policy Evaluation (Prediction)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/bellman-optimality-backup/index.html">Bellman Optimality Backup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mdp/policy-improvement/index.html">Policy Improvement (Control)</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/index.html">Dynamic Programming Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/policy-iteration/index.html">Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/dynamic-programming-algorithms/value-iteration/index.html">Value Iteration</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../mdp/mdp-workshop/index.html">MDP Workshop</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/cleaning-robot/deterministic_mdp.html">Cleaning Robot - Deterministic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/cleaning-robot/stochastic_mdp.html">Cleaning Robot - Stochastic MDP</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mdp/mdp-workshop/recycling-robot/index.html">The recycling robot.</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="label-parts" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/index.html">Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/monte-carlo.html">Monte-Carlo Prediction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reinforcement-learning/prediction/temporal-difference.html">Temporal Difference (TD) Prediction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../reinforcement-learning/model-free-control/index.html">Model-free Control</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/generalized-policy-iteration/index.html">Generalized Policy Iteration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/greedy-monte-carlo/index.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy Monte-Carlo (MC) Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/sarsa/index.html">The SARSA Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../reinforcement-learning/model-free-control/sarsa/gridworld/sarsa_gridworld.html">SARSA Gridworld Example</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Sequences and RNNs</span></p><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="label-parts" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../rnn/introduction/index.html">Introduction to Recurrent Neural Networks (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/simple-rnn/index.html">Simple RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/lstm/index.html">The Long Short-Term Memory (LSTM) Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rnn/time_series_using_simple_rnn_lstm.html">Time Series Prediction using RNNs</a></li>





</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Natural Language Processing</span></p><input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="label-parts" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../nlp-introduction/nlp-pipelines/index.html">Introduction to NLP Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../nlp-introduction/tokenization/index.html">Tokenization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp-introduction/word2vec/index.html">Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp-introduction/word2vec/word2vec_from_scratch.html">Word2Vec from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp-introduction/word2vec/word2vec_tensorflow_tutorial.html">Word2Vec Tensorflow Tutorial</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../language-models/index.html">Language Models</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../language-models/cnn-language-model/index.html">CNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../language-models/simple-rnn-language-model/index.html">Simple RNN Language Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../language-models/lstm-language-model/index.html">LSTM Language Model from scratch</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nmt/nmt-intro/index.html">Neural Machine Translation</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nmt/nmt-metrics/index.html">NMT Metrics  - BLEU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nmt/rnn-nmt-attention/index.html">Attention in RNN-based NMT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nmt/rnn-attention-workshop/seq2seq_and_attention.html">Attention in RNN NMT Workshop</a></li>




</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="transformers-intro.html">Transformers and Self-attention</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-25"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Single-head self-attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="multihead-self-attention.html">Multi-head self-attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="positional_embeddings.html">Positional Embeddings</a></li>
</ul>
</li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Math Background</span></p><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/><label class="label-parts" for="toctree-checkbox-26"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/index.html">Math for ML Textbook</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/probability/index.html">Probability Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/linear-algebra/index.html">Linear Algebra for Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml-math/calculus/index.html">Calculus</a></li>
</ul></li><li class="toctree-l0 has-children"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/><label class="label-parts" for="toctree-checkbox-27"><i class="fa-solid fa-chevron-down"></i></label><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/index.html">Your Programming Environment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/slurm-keras-example.html">Training Keras with the SLURM Scheduler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/nyu-jupyterhub-envs.html">NYU JupyrterHub Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/assignment-submission.html">Submitting Your Assignment / Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python/index.html">Learn Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/environment/notebook-status.html">Notebook execution status</a></li>
</ul></li></ul>
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pantelis/artificial-intelligence/issues/new?title=Issue%20on%20page%20%2Faiml-common/lectures/nlp/transformers/singlehead-self-attention.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/aiml-common/lectures/nlp/transformers/singlehead-self-attention.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Single-head self-attention</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-dot-product-self-attention">Scaled dot-product self-attention</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-transformation-of-the-input-embeddings">Linear transformation of the input embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-of-the-attention-scores">Computation of the attention scores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scaling">Scaling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#masking">Masking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax">Softmax</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighting-the-values">Weighting the values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensioning-the-attention-mechanism">Dimensioning the Attention Mechanism</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-attention-mechanisms">Other attention mechanisms</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="single-head-self-attention">
<h1>Single-head self-attention<a class="headerlink" href="#single-head-self-attention" title="Link to this heading">#</a></h1>
<section id="scaled-dot-product-self-attention">
<h2>Scaled dot-product self-attention<a class="headerlink" href="#scaled-dot-product-self-attention" title="Link to this heading">#</a></h2>
<p>In the simple attention mechanism, the attention weights are computed <em>deterministically</em> from the input context. We call the combination of context-free embedding (eg word2vec) and positional embedding, the input embedding. What we would like to do is to Given the input embedding,  the output embedding has no information about the <em>data distribution</em> that the input token is part of outside the context.</p>
<p>Lets look at the grammatical structure of the following sentences:</p>
<ol class="arabic simple">
<li><p>“I love <em>bears</em>”</p>
<ul class="simple">
<li><p>Subject: I</p></li>
<li><p>Verb: love</p></li>
<li><p>Object: bears</p></li>
</ul>
</li>
<li><p>“She <em>bears</em> the pain”</p>
<ul class="simple">
<li><p>Subject: She</p></li>
<li><p>Verb: bears</p></li>
<li><p>Object: the pain</p></li>
</ul>
</li>
<li><p>“<em>Bears</em> won the game”</p>
<ul class="simple">
<li><p>Subject: Bears</p></li>
<li><p>Verb: won</p></li>
<li><p>Object: the game</p></li>
</ul>
</li>
</ol>
<p>Each sentence above follows a subject-verb-object structure, where the subject performs the action expressed by the verb on the object. You can notice that <code class="docutils literal notranslate"><span class="pre">bears</span></code> plays a different function in each sentence: as an object, as a verb, and as a subject. In addition, we have other and more complicated language patterns, such as this:</p>
<ol class="arabic simple" start="4">
<li><p>“The hiking trail led us through <em>bear</em> country.”</p>
<ul class="simple">
<li><p><strong>Subject</strong>: “The hiking trail”</p></li>
<li><p><strong>Verb</strong>: “led”</p></li>
<li><p><strong>Object</strong>: “us”</p></li>
<li><p><strong>Prepositional Phrase</strong>: “through bear country”</p></li>
<li><p><strong>Preposition</strong>: “through”</p></li>
<li><p><strong>Object of the Preposition</strong>: “bear country”</p>
<ul>
<li><p><strong>Noun</strong>: “country”</p></li>
<li><p><strong>Adjective</strong>: “bear” (modifying “country”)</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Here, “bear” serves as an adjective describing the type of country.</p>
<p>The central question that one can pose now is this: <strong>Since the location of the token seems highly correlated with its function, as captured by the language patterns above, how can we help the embedding mapping become location aware and function aware ?</strong></p>
<!-- Can we encode the function of the token `bear` is playing?  

As we will see such additional patterns can be captured by having multiple attention _heads_ each head broadly speaking responsible for modifying the input embedding from tokens that belong to different functions. Such modification is done at a space that is different than the input emdedding space.  -->
<section id="linear-transformation-of-the-input-embeddings">
<h3>Linear transformation of the input embeddings<a class="headerlink" href="#linear-transformation-of-the-input-embeddings" title="Link to this heading">#</a></h3>
<p>This is done by projecting  the input embeddings using a projection matrix <span class="math notranslate nohighlight">\(W\)</span> obtaining a new coordinate system whose <code class="docutils literal notranslate"><span class="pre">axes</span></code> can be associated with object, verb, subject, adjective etc.  The semantic meaning of such new coordinate system is not necessary to be explicitly defined but it helps understand what this projection may achieve.</p>
<p>We define three such trainable matrices <span class="math notranslate nohighlight">\(W^q, W^k, W^v\)</span> and ask each token (or equivalently the matrix <span class="math notranslate nohighlight">\(X\)</span>) to project itself to the three different spaces.</p>
<div class="math notranslate nohighlight">
\[Q = XW^q\]</div>
<div class="math notranslate nohighlight">
\[K = XW^k\]</div>
<div class="math notranslate nohighlight">
\[V = XW^v\]</div>
<p>where <span class="math notranslate nohighlight">\(X\)</span> is the input embedding matrix of size <span class="math notranslate nohighlight">\(T \times d\)</span> where <span class="math notranslate nohighlight">\(T\)</span> is the input sequence length and <span class="math notranslate nohighlight">\(d\)</span> is the embedding dimension. <span class="math notranslate nohighlight">\(Q, K, V\)</span> are the query, keys and values respectively and the dimensions of the <span class="math notranslate nohighlight">\(W^q, W^k, W^v\)</span> matrices are <span class="math notranslate nohighlight">\(d \times d_q, d \times d_k, d \times d_v\)</span> respectively. Queries and keys occupy typically the same dimensional space (<span class="math notranslate nohighlight">\(d_k\)</span>).</p>
<p>Each token is undertaking three roles, lets focus here on the first two:</p>
<p>In a <strong>query role</strong> the current token effectively seeks to find other functions eg ‘adjective’
In a <strong>key role</strong> the current token effectively expresses its own function eg ‘noun’.</p>
<p>For example: <strong>‘I am key=noun’ and I am seeking for a earlier query=adjective’.</strong></p>
<p>The premise that that <strong>after training, the attention mechanism will be able to reveal the keys of the input context that can best respond to the query.</strong></p>
<p>Let us now recall what we saw already during the <code class="docutils literal notranslate"><span class="pre">word2vec</span></code> construction: we trained a network that will take one-hot vectors of semantically similar tokens that were orthonormal and projected them to vectors that are close to each other in the embedding space.  So we have seen evidence that a projection with proper weights can cause all sorts of interesting mappings to happen from a large dimensional space to a lower space. By analogy, the multiplication of the matrix <span class="math notranslate nohighlight">\(W^q\)</span> with the input token embedding will create a vector (a point) in the d_k dimensional space that will represent the query. Similarly the multiplication of the matrix <span class="math notranslate nohighlight">\(W^k\)</span> with each and every input token embedding will create vectors (a point) in the d_k dimensional space that will represent the keys. <strong>After training the keys that can best respond to the query will end up close to it</strong>.</p>
</section>
<section id="computation-of-the-attention-scores">
<h3>Computation of the attention scores<a class="headerlink" href="#computation-of-the-attention-scores" title="Link to this heading">#</a></h3>
<p>Lets see an example of the projection of the input embeddings to the query and key spaces for the input context.<br />
Given matrices <span class="math notranslate nohighlight">\( X \)</span> and <span class="math notranslate nohighlight">\( W^{(q)} \)</span> (the key parameter matrix is analogous) where:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X = \begin{bmatrix} x_{1,1} &amp; x_{1,2} &amp; x_{1,3} &amp; x_{1,4} &amp; x_{1,5} &amp; x_{1,6} &amp; x_{1,7} &amp; x_{1,8} \\ x_{2,1} &amp; x_{2,2} &amp; x_{2,3} &amp; x_{2,4} &amp; x_{2,5} &amp; x_{2,6} &amp; x_{2,7} &amp; x_{2,8} \\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\ x_{16,1} &amp; x_{16,2} &amp; x_{16,3} &amp; x_{16,4} &amp; x_{16,5} &amp; x_{16,6} &amp; x_{16,7} &amp; x_{16,8} \end{bmatrix} 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split} 
W^{(q)} = \begin{bmatrix} w_{1,1} &amp; w_{1,2} &amp; w_{1,3} &amp; w_{1,4} \\ w_{2,1} &amp; w_{2,2} &amp; w_{2,3} &amp; w_{2,4} \\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\ w_{8,1} &amp; w_{8,2} &amp; w_{8,3} &amp; w_{8,4} \end{bmatrix} 
\end{split}\]</div>
<p>The resulting matrix <span class="math notranslate nohighlight">\( Q \)</span>, where <span class="math notranslate nohighlight">\( Q = X \times W^{(q)} \)</span>, will have dimensions <span class="math notranslate nohighlight">\( 16 \times 8 \)</span>. Each element <span class="math notranslate nohighlight">\( q_{i,j} \)</span> of <span class="math notranslate nohighlight">\( Q \)</span> is computed as:</p>
<div class="math notranslate nohighlight">
\[ q_{i,j} = x_{i,1} \cdot w_{1,j} + x_{i,2} \cdot w_{2,j} + x_{i,3} \cdot w_{3,j} + x_{i,4} \cdot w_{4,j} \]</div>
<p>Notice something not obvious earlier: <strong>the matrix <span class="math notranslate nohighlight">\(W^{(q)}\)</span> allows to weigh differently some features of the input embedding (across the <span class="math notranslate nohighlight">\(d\)</span> dimensions) than others when it calculates the query and key vectors.</strong></p>
<p>Lets now proceed with the evolved dot product that now is done at the query-key <span class="math notranslate nohighlight">\(d_q = d_k\)</span> space.</p>
<p>“The hiking trail led us through <em>bear</em> country.” where <span class="math notranslate nohighlight">\(T=8\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{cccccccc}
 &amp; q_1 &amp; q_2 &amp; q_3 &amp; q_4 &amp; q_5 &amp; q_6 &amp; q_7 &amp; q_8 \\
k_1 &amp; {q_1^T k_1} &amp; {q_2^T k_1} &amp; {q_3^T k_1} &amp; {q_4^T k_1} &amp; {q_5^T k_1} &amp; {q_6^T k_1} &amp; {q_7^T k_1} &amp; {q_8^T k_1} \\
k_2 &amp; {q_1^T k_2} &amp; {q_2^T k_2} &amp; {q_3^T k_2} &amp; {q_4^T k_2} &amp; {q_5^T k_2} &amp; {q_6^T k_2} &amp; {q_7^T k_2} &amp; {q_8^T k_2} \\
k_3 &amp; {q_1^T k_3} &amp; {q_2^T k_3} &amp; {q_3^T k_3} &amp; {q_4^T k_3} &amp; {q_5^T k_3} &amp; {q_6^T k_3} &amp; {q_7^T k_3} &amp; {q_8^T k_3} \\
k_4 &amp; {q_1^T k_4} &amp; {q_2^T k_4} &amp; {q_3^T k_4} &amp; {q_4^T k_4} &amp; {q_5^T k_4} &amp; {q_6^T k_4} &amp; {q_7^T k_4} &amp; {q_8^T k_4} \\
k_5 &amp; {q_1^T k_5} &amp; {q_2^T k_5} &amp; {q_3^T k_5} &amp; {q_4^T k_5} &amp; {q_5^T k_5} &amp; {q_6^T k_5} &amp; {q_7^T k_5} &amp; {q_8^T k_5} \\
k_6 &amp; {q_1^T k_6} &amp; {q_2^T k_6} &amp; {q_3^T k_6} &amp; {q_4^T k_6} &amp; {q_5^T k_6} &amp; {q_6^T k_6} &amp; {q_7^T k_6} &amp; {q_8^T k_6} \\
k_7 &amp; {q_1^T k_7} &amp; {q_2^T k_7} &amp; {q_3^T k_7} &amp; {q_4^T k_7} &amp; {q_5^T k_7} &amp; {q_6^T k_7} &amp; {q_7^T k_7} &amp; {q_8^T k_7} \\
k_8 &amp; {q_1^T k_8} &amp; {q_2^T k_8} &amp; {q_3^T k_8} &amp; {q_4^T k_8} &amp; {q_5^T k_8} &amp; {q_6^T k_8} &amp; {q_7^T k_8} &amp; {q_8^T k_8} \\
\end{array}
\end{split}\]</div>
<p>Now that we have projected the tokens in their new space we can form the generalized dot product</p>
<div class="math notranslate nohighlight">
\[(W^qx_i)^TW^kx_j = x_i^T (W^q)^TW^kx_j=x_i^TWx_j\]</div>
<p>Geometrically you can visualize this as shown below:</p>
<p><img alt="" src="../../../../_images/self-attention-vectors.png" />
<em>After training the keys that can the most to change the query will end up close to it</em>. The actual change of the query is done by the values.</p>
<p>The scores are then given in matrix form by:</p>
<div class="math notranslate nohighlight">
\[S = QK^T\]</div>
</section>
<section id="scaling">
<h3>Scaling<a class="headerlink" href="#scaling" title="Link to this heading">#</a></h3>
<p>We divide the scores by the square root of the dimension of the key vector (<span class="math notranslate nohighlight">\(d_k\)</span>). This is done in to prevent the softmax from saturating on the higher attention score elements and severely attenuating the attention weights that correspond to the lower attention scores.</p>
<p>We can do an experiment to see the behavior of softmax.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Creating an 8-element numpy vector with random gaussian values</span>
<span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Softmax function</span>
<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">e_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># Stability improvement by subtracting the max</span>
    <span class="k">return</span> <span class="n">e_x</span> <span class="o">/</span> <span class="n">e_x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Applying softmax to the vector</span>
<span class="n">softmax_vector</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">vector</span><span class="p">)</span>
<span class="n">softmax_vector</span>
</pre></div>
</div>
<p>Lets plot the two results - the first case is when for the original vector and the second case is when the original vector is element-wise multiplied by 100.</p>
<p><img alt="" src="../../../../_images/scaling-1.png" /></p>
<p><img alt="" src="../../../../_images/scaling-2.png" /></p>
<p>Multiply the attention scores by 100 and then pass them through a softmax. You will see that the softmax will output a vector of values that are either very close to 0 or 1.</p>
<p>The division by the <span class="math notranslate nohighlight">\(\sqrt{d_k}\)</span> prevents this behavior.</p>
<p>The code for the scaled dot product attention is shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scaled_dot_product_attention</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
    <span class="n">dim_k</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">dim_k</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="masking">
<h3>Masking<a class="headerlink" href="#masking" title="Link to this heading">#</a></h3>
<p>When we decode we do not want to use the attention scores of the future tokens since we dont want to train the tranformer using ground truth that will simply wont be available during inference.</p>
<p>To prevent this from happening we <em>mask</em> the attention scores of the future tokens by setting them to <span class="math notranslate nohighlight">\(-\infty\)</span> before passing them through the softmax. This will cause the softmax to output a vector of values that are very close to 0 for the future tokens.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{cccccccc}
 &amp; q_1 &amp; q_2 &amp; q_3 &amp; q_4 &amp; q_5 &amp; q_6 &amp; q_7 &amp; q_8 \\
k_1 &amp; {q_1^T k_1} &amp; {q_2^T k_1} &amp; {q_3^T k_1} &amp; {q_4^T k_1} &amp; {q_5^T k_1} &amp; {q_6^T k_1} &amp; {q_7^T k_1} &amp; {q_8^T k_1} \\
k_2 &amp; -\infty &amp; {q_2^T k_2} &amp; {q_3^T k_2} &amp; {q_4^T k_2} &amp; {q_5^T k_2} &amp; {q_6^T k_2} &amp; {q_7^T k_2} &amp; {q_8^T k_2} \\
k_3 &amp; -\infty &amp; -\infty &amp; {q_3^T k_3} &amp; {q_4^T k_3} &amp; {q_5^T k_3} &amp; {q_6^T k_3} &amp; {q_7^T k_3} &amp; {q_8^T k_3} \\
k_4 &amp; -\infty &amp; -\infty &amp; -\infty &amp; {q_4^T k_4} &amp; {q_5^T k_4} &amp; {q_6^T k_4} &amp; {q_7^T k_4} &amp; {q_8^T k_4} \\
k_5 &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; {q_5^T k_5} &amp; {q_6^T k_5} &amp; {q_7^T k_5} &amp; {q_8^T k_5} \\
k_6 &amp; -\infty &amp; -\infty &amp; -\infty &amp; {q_4^T k_6} &amp; {q_5^T k_6} &amp; {q_6^T k_6} &amp; {q_7^T k_6} &amp; {q_8^T k_6} \\
k_7 &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; {q_7^T k_7} &amp; {q_8^T k_7} \\
k_8 &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; -\infty &amp; {q_8^T k_8} \\
\end{array}
\end{split}\]</div>
</section>
<section id="softmax">
<h3>Softmax<a class="headerlink" href="#softmax" title="Link to this heading">#</a></h3>
<p>The dot-product terms will be positive or negative numbers and as also in the case of the simpler version of the attention mechanism, we will pass them through a softmax function column-wise to obtain the attention weights <span class="math notranslate nohighlight">\(\alpha_{ij}\)</span> for each of the tokens.</p>
</section>
</section>
<section id="weighting-the-values">
<h2>Weighting the values<a class="headerlink" href="#weighting-the-values" title="Link to this heading">#</a></h2>
<p>We then use the attention weights to create a weighted sum of each of the values to obtain the output embedding.</p>
<div class="math notranslate nohighlight">
\[\hat v_i = \sum_{j=1}^T \alpha_{ij} v_j\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha_{ij}\)</span> is the attention weight of the <span class="math notranslate nohighlight">\(j-th\)</span> token of the input sequence for the <span class="math notranslate nohighlight">\(i-th\)</span> value of the input sequence of length T.</p>
<p>What purpose the values play though and why the <span class="math notranslate nohighlight">\(W^v\)</span> matrix ?</p>
<p>The values are the actual information that the input token will use to update its embedding. The <span class="math notranslate nohighlight">\(W^v\)</span> matrix is used to project the input tokens to values (points) in a <span class="math notranslate nohighlight">\(d_v\)</span> dimensional space. There is no reason to make the dimensionality of the value space the same as the dimensionality of the key space but typically they are the same.  <strong>We use the value projection (<span class="math notranslate nohighlight">\(V\)</span>) as a way to decouple the determination of the attention weights from the actual adjustment of their specific embeddings.</strong></p>
<p><img alt="" src="../../../../_images/bear-country.jpg" /></p>
<p>As an example, in the context “The hiking trail led us through <em>bear</em> country”, if the key represents the adjective of an input token that responded to a noun query, the value will represent the specific adjective (<code class="docutils literal notranslate"><span class="pre">bear</span></code>) that adjusts the specific noun (<code class="docutils literal notranslate"><span class="pre">country</span></code>) and makes it a <code class="docutils literal notranslate"><span class="pre">bear</span> <span class="pre">country</span></code> vector.</p>
<p><img alt="Single Attention Head" src="../../../../_images/scaled-dot-product-self-attention.png" />
<em>Note that masking is not shown in this figure. Also vector subspaces maintain the same dimensions throughout.</em></p>
<p>Closing, the overall equation for the scaled self-attention can be formulated as:</p>
<div class="math notranslate nohighlight">
\[\hat X = \mathtt{Attention}(Q, K, V) = \mathtt{softmax}(\frac{QK^T}{\sqrt{d_k}})V\]</div>
<p>and the output has dimension <span class="math notranslate nohighlight">\(c \times d_v\)</span> where <span class="math notranslate nohighlight">\(c\)</span> is the number of tokens in the input sequence and <span class="math notranslate nohighlight">\(d_v\)</span> is the dimension of the value vectors.</p>
<p>The dimensions of the tensors can also be extended to accommodate the batch dimension.</p>
<div class="admonition-dense-layers-and-self-attention admonition">
<p class="admonition-title">Dense Layers and Self-Attention</p>
<p>Its worthwhile highlighting the difference between a dense layer and the self-attention mechanism. In a dense layer, if the layer learns to apply eg a very small weight at the input, it does so for all data that are fed into the layer.  In the self-attention mechanism if one of the attention weights is for example very small, this is purely due to the specific data being present.</p>
</div>
</section>
<section id="example">
<h2>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h2>
<p>An example of the output of the scaled dot-product self-attention is shown below using the <code class="docutils literal notranslate"><span class="pre">bertviz</span></code> library.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bertviz</span> <span class="kn">import</span> <span class="n">head_view</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModel</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_ckpt</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">sentence_a</span> <span class="o">=</span> <span class="s2">&quot;time flies like an arrow&quot;</span>
<span class="n">sentence_b</span> <span class="o">=</span> <span class="s2">&quot;fruit flies like a banana&quot;</span>

<span class="n">viz_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence_a</span><span class="p">,</span> <span class="n">sentence_b</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span>
<span class="n">attention</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">viz_inputs</span><span class="p">)</span><span class="o">.</span><span class="n">attentions</span>
<span class="n">sentence_b_start</span> <span class="o">=</span> <span class="p">(</span><span class="n">viz_inputs</span><span class="o">.</span><span class="n">token_type_ids</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">viz_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">head_view</span><span class="p">(</span><span class="n">attention</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">sentence_b_start</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
<p><img alt="Bertiviz example" src="../../../../_images/bertviz-1.png" /></p>
<p>This visualization shows the attention weights as lines connecting the token whose embedding is getting updated (left) with every word that is being attended to (right). The intensity of the lines indicates the strength of the attention weights, with dark lines representing values close to 1, and faint lines representing values close to 0.</p>
<p>The end result is that the token ‘flies’ will receive the context of ‘soars’ in one sentence and the context of ‘insect’ in the other sentence.</p>
<p><img alt="contextual embeddings" src="../../../../_images/contextual-embeddings.png" /></p>
</section>
<section id="dimensioning-the-attention-mechanism">
<h2>Dimensioning the Attention Mechanism<a class="headerlink" href="#dimensioning-the-attention-mechanism" title="Link to this heading">#</a></h2>
</section>
<section id="other-attention-mechanisms">
<h2>Other attention mechanisms<a class="headerlink" href="#other-attention-mechanisms" title="Link to this heading">#</a></h2>
<p>There are multiple more advanced attention mechanisms that try in addition to solve the scalability issues from having to manage a <span class="math notranslate nohighlight">\(T \times T\)</span> matrix of attention weights.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "pantelis/artificial-intelligence",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./aiml-common/lectures/nlp/transformers"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="transformers-intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Transformers and Self-Attention</p>
      </div>
    </a>
    <a class="right-next"
       href="multihead-self-attention.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Multi-head self-attention</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scaled-dot-product-self-attention">Scaled dot-product self-attention</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-transformation-of-the-input-embeddings">Linear transformation of the input embeddings</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computation-of-the-attention-scores">Computation of the attention scores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scaling">Scaling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#masking">Masking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#softmax">Softmax</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#weighting-the-values">Weighting the values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensioning-the-attention-mechanism">Dimensioning the Attention Mechanism</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#other-attention-mechanisms">Other attention mechanisms</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pantelis Monogioudis, Ph.D
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>